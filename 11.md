**1. Основные понятия: области, термины, задачи машинного обучения.**

**Области:**

*   **Искусственный интеллект (ИИ):** широкая область, охватывающая создание интеллектуальных агентов, способных рассуждать, обучаться и действовать автономно.
*   **Машинное обучение (МО):** подобласть ИИ, фокусирующаяся на разработке алгоритмов, позволяющих компьютерам обучаться на данных без явного программирования.
*   **Глубокое обучение (ГО):** подраздел МО, использующий искусственные нейронные сети с множеством слоев для изучения сложных закономерностей в данных.
*   **Нейронные сети:** вычислительные модели, вдохновленные биологическими нейронными сетями, состоящие из взаимосвязанных узлов (нейронов), обрабатывающих информацию.

**Термины:**

*   **Данные:** информация, используемая для обучения модели.
*   **Признаки:** измеримые характеристики объектов, используемые для их описания.
*   **Модель:** математическое представление, описывающее взаимосвязь между признаками и целевой переменной.
*   **Обучение:** процесс настройки параметров модели на основе данных.
*   **Тестирование:** оценка производительности модели на новых данных.
*   **Переобучение:** ситуация, когда модель слишком хорошо запоминает обучающие данные и плохо обобщает на новые данные.
*   **Недообучение:** ситуация, когда модель недостаточно сложна, чтобы уловить закономерности в данных.
*   **Целевая переменная:** переменная, которую модель пытается предсказать.
*   **Алгоритм:** набор правил или инструкций, определяющих, как модель должна обучаться.
*   **Гиперпараметры:** параметры алгоритма обучения, которые не обучаются на данных, а устанавливаются перед началом обучения.

**Задачи машинного обучения:**

*   **Классификация:** отнесение объектов к определенным категориям.
*   **Регрессия:** предсказание числового значения.
*   **Кластеризация:** группировка объектов по схожести.
*   **Уменьшение размерности:** снижение количества признаков с сохранением важной информации.
*   **Поиск аномалий:** выявление объектов, сильно отличающихся от остальных.
*   **Обучение с подкреплением:** обучение агентов взаимодействию с окружающей средой для максимизации вознаграждения.

**Ссылки:**

*   [Machine Learning - Wikipedia](https://en.wikipedia.org/wiki/Machine_learning)
*   [Deep Learning - Wikipedia](https://en.wikipedia.org/wiki/Deep_learning)
*   [Neural Network - Wikipedia](https://en.wikipedia.org/wiki/Artificial_neural_network)

**2. Схема процесса машинного обучения. Анализ инструментария для решения задач машинного обучения.**

**Схема процесса машинного обучения:**

1. **Постановка задачи:** Определение цели и типа задачи машинного обучения.
2. **Сбор данных:** Получение данных из различных источников.
3. **Подготовка данных:** Очистка, преобразование и форматирование данных.
4. **Разделение данных:** Разделение данных на обучающую, валидационную и тестовую выборки.
5. **Выбор модели:** Выбор подходящего алгоритма машинного обучения.
6. **Обучение модели:** Настройка параметров модели на обучающих данных.
7. **Оценка модели:** Оценка производительности модели на валидационных данных.
8. **Настройка гиперпараметров:** Оптимизация гиперпараметров модели.
9. **Тестирование модели:** Оценка производительности модели на тестовых данных.
10. **Развертывание модели:** Интеграция модели в реальную систему.
11. **Мониторинг и обслуживание:** Отслеживание производительности модели и ее обновление при необходимости.

**Инструментарий:**

*   **Языки программирования:**
    *   **Python:** наиболее популярный язык для машинного обучения, благодаря наличию множества библиотек, таких как Scikit-learn, TensorFlow, Keras, PyTorch.
    *   **R:** язык, ориентированный на статистический анализ данных, с обширными возможностями для машинного обучения.
    *   **Java:** подходит для разработки высокопроизводительных и масштабируемых систем машинного обучения.
*   **Библиотеки:**
    *   **Scikit-learn:** библиотека для классического машинного обучения, предоставляет инструменты для классификации, регрессии, кластеризации, уменьшения размерности и др. ([https://scikit-learn.org/](https://scikit-learn.org/))
    *   **TensorFlow:** библиотека для глубокого обучения, разработанная Google, позволяет создавать и обучать нейронные сети. ([https://www.tensorflow.org/](https://www.tensorflow.org/))
    *   **Keras:** высокоуровневый API для работы с TensorFlow, упрощает создание и обучение нейронных сетей. ([https://keras.io/](https://keras.io/))
    *   **PyTorch:** библиотека для глубокого обучения, разработанная Facebook, отличается динамическими вычислительными графами. ([https://pytorch.org/](https://pytorch.org/))
    *   **Pandas:** библиотека для работы с табличными данными, предоставляет удобные структуры данных и функции для анализа и обработки данных. ([https://pandas.pydata.org/](https://pandas.pydata.org/))
    *   **NumPy:** библиотека для работы с многомерными массивами, предоставляет базовые математические функции для машинного обучения. ([https://numpy.org/](https://numpy.org/))
    *   **Matplotlib:** библиотека для визуализации данных, позволяет строить различные графики и диаграммы. ([https://matplotlib.org/](https://matplotlib.org/))
*   **Фреймворки:**
    *   **Apache Spark:** фреймворк для распределенной обработки больших данных, включает библиотеку MLlib для машинного обучения. ([https://spark.apache.org/](https://spark.apache.org/))
    *   **Hadoop:** еще один фреймворк для распределенной обработки данных, часто используется в связке со Spark. ([https://hadoop.apache.org/](https://hadoop.apache.org/))
*   **Облачные платформы:**
    *   **Google Cloud AI Platform:** предоставляет сервисы для машинного обучения, включая обучение моделей, развертывание и управление ими. ([https://cloud.google.com/ai-platform](https://cloud.google.com/ai-platform))
    *   **Amazon SageMaker:** аналогичный сервис от Amazon. ([https://aws.amazon.com/sagemaker/](https://aws.amazon.com/sagemaker/))
    *   **Microsoft Azure Machine Learning:** сервис от Microsoft. ([https://azure.microsoft.com/en-us/services/machine-learning/](https://azure.microsoft.com/en-us/services/machine-learning/))

**3. Основные задачи машинного обучения: обучение с учителем – классификация, прогнозирование, регрессия; примеры алгоритмов.**

**Обучение с учителем (Supervised Learning):** модели обучаются на размеченных данных, где для каждого объекта известен правильный ответ (метка).

*   **Классификация (Classification):** отнесение объектов к определенным категориям.

    *   **Примеры:** определение спама в электронной почте, распознавание изображений, диагностика заболеваний.
    *   **Алгоритмы:**
        *   **Логистическая регрессия (Logistic Regression):**  ([https://en.wikipedia.org/wiki/Logistic_regression](https://en.wikipedia.org/wiki/Logistic_regression))
        *   **Метод опорных векторов (Support Vector Machines, SVM):** ([https://en.wikipedia.org/wiki/Support-vector_machine](https://en.wikipedia.org/wiki/Support-vector_machine))
        *   **Наивный байесовский классификатор (Naive Bayes):** ([https://en.wikipedia.org/wiki/Naive_Bayes_classifier](https://en.wikipedia.org/wiki/Naive_Bayes_classifier))
        *   **Деревья решений (Decision Trees):** ([https://en.wikipedia.org/wiki/Decision_tree](https://en.wikipedia.org/wiki/Decision_tree))
        *   **Случайный лес (Random Forest):** ([https://en.wikipedia.org/wiki/Random_forest](https://en.wikipedia.org/wiki/Random_forest))
        *   **k-ближайших соседей (k-Nearest Neighbors, k-NN):** ([https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm))
        *   **Нейронные сети (Neural Networks):** ([https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network))

*   **Прогнозирование:**  Предсказание будущих значений на основе исторических данных.
    *   **Примеры:** Прогнозирование цен на акции, прогнозирование спроса на товары.
    *   **Алгоритмы:**
        *   **Линейная регрессия (Linear Regression)**
        *   **Полиномиальная регрессия (Polynomial Regression)**
        *   **Метод опорных векторов для регрессии (Support Vector Regression, SVR)**
        *   **Деревья решений (Decision Trees)**
        *   **Случайный лес (Random Forest)**
        *   **Градиентный бустинг (Gradient Boosting)**
        *   **Рекуррентные нейронные сети (Recurrent Neural Networks, RNNs) - LSTM, GRU**

*   **Регрессия (Regression):** предсказание числового значения.

    *   **Примеры:** оценка стоимости недвижимости, прогнозирование температуры.
    *   **Алгоритмы:**
        *   **Линейная регрессия (Linear Regression):** ([https://en.wikipedia.org/wiki/Linear_regression](https://en.wikipedia.org/wiki/Linear_regression))
        *   **Полиномиальная регрессия (Polynomial Regression):** ([https://en.wikipedia.org/wiki/Polynomial_regression](https://en.wikipedia.org/wiki/Polynomial_regression))
        *   **Метод опорных векторов для регрессии (Support Vector Regression, SVR):** ([https://en.wikipedia.org/wiki/Support-vector_machine#Regression](https://en.wikipedia.org/wiki/Support-vector_machine#Regression))
        *   **Деревья решений (Decision Trees):** ([https://en.wikipedia.org/wiki/Decision_tree_learning](https://en.wikipedia.org/wiki/Decision_tree_learning))
        *   **Случайный лес (Random Forest):** ([https://en.wikipedia.org/wiki/Random_forest](https://en.wikipedia.org/wiki/Random_forest))
        *   **Градиентный бустинг (Gradient Boosting):** ([https://en.wikipedia.org/wiki/Gradient_boosting](https://en.wikipedia.org/wiki/Gradient_boosting))
        *   **Нейронные сети (Neural Networks):** ([https://en.wikipedia.org/wiki/Artificial_neural_network](https://en.wikipedia.org/wiki/Artificial_neural_network))

**4. Основные задачи машинного обучения : обучение без учителя – кластеризация, поиск аномалий, уменьшение размерности; обучение с подкреплением. Примеры алгоритмов. Сферы применения машинного обучения.**

**Обучение без учителя (Unsupervised Learning):** модели обучаются на неразмеченных данных, где нет правильных ответов.

*   **Кластеризация (Clustering):** группировка объектов по схожести.

    *   **Примеры:** сегментация клиентов, группировка похожих документов, сжатие изображений.
    *   **Алгоритмы:**
        *   **k-средних (k-Means):** ([https://en.wikipedia.org/wiki/K-means_clustering](https://en.wikipedia.org/wiki/K-means_clustering))
        *   **Иерархическая кластеризация (Hierarchical Clustering):** ([https://en.wikipedia.org/wiki/Hierarchical_clustering](https://en.wikipedia.org/wiki/Hierarchical_clustering))
        *   **DBSCAN:** ([https://en.wikipedia.org/wiki/DBSCAN](https://en.wikipedia.org/wiki/DBSCAN))
        *   **Спектральная кластеризация (Spectral Clustering):** ([https://en.wikipedia.org/wiki/Spectral_clustering](https://en.wikipedia.org/wiki/Spectral_clustering))

*   **Поиск аномалий (Anomaly Detection):** выявление объектов, сильно отличающихся от остальных.

    *   **Примеры:** обнаружение мошеннических транзакций, выявление бракованных изделий, диагностика неисправностей оборудования.
    *   **Алгоритмы:**
        *   **Метод k-ближайших соседей (k-Nearest Neighbors):** ([https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm))
        *   **Изолирующий лес (Isolation Forest):** ([https://en.wikipedia.org/wiki/Isolation_forest](https://en.wikipedia.org/wiki/Isolation_forest))
        *   **Одноклассовый SVM (One-Class SVM):** ([https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html](https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html))
        *   **Автоэнкодеры (Autoencoders):** ([https://en.wikipedia.org/wiki/Autoencoder](https://en.wikipedia.org/wiki/Autoencoder))

*   **Уменьшение размерности (Dimensionality Reduction):** снижение количества признаков с сохранением важной информации.

    *   **Примеры:** визуализация многомерных данных, ускорение обучения моделей, устранение избыточности данных.
    *   **Алгоритмы:**
        *   **Метод главных компонент (Principal Component Analysis, PCA):** ([https://en.wikipedia.org/wiki/Principal_component_analysis](https://en.wikipedia.org/wiki/Principal_component_analysis))
        *   **t-SNE:** ([https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding](https://en.wikipedia.org/wiki/T-distributed_stochastic_neighbor_embedding))
        *   **Линейный дискриминантный анализ (Linear Discriminant Analysis, LDA):** ([https://en.wikipedia.org/wiki/Linear_discriminant_analysis](https://en.wikipedia.org/wiki/Linear_discriminant_analysis))
        *   **Автоэнкодеры (Autoencoders):** ([https://en.wikipedia.org/wiki/Autoencoder](https://en.wikipedia.org/wiki/Autoencoder))

**Обучение с подкреплением (Reinforcement Learning):** обучение агентов взаимодействию с окружающей средой для максимизации вознаграждения.

*   **Примеры:** обучение роботов, игры, управление ресурсами, оптимизация процессов.
*   **Алгоритмы:**
    *   **Q-обучение (Q-Learning):** ([https://en.wikipedia.org/wiki/Q-learning](https://en.wikipedia.org/wiki/Q-learning))
    *   **SARSA:** ([https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action](https://en.wikipedia.org/wiki/State%E2%80%93action%E2%80%93reward%E2%80%93state%E2%80%93action))
    *   **Deep Q-Network (DQN):** ([https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf](https://www.cs.toronto.edu/~vmnih/docs/dqn.pdf))
    *   **Actor-Critic:** ([https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method](https://en.wikipedia.org/wiki/Actor%E2%80%93critic_method))

**Сферы применения машинного обучения:**

*   **Медицина:** диагностика заболеваний, разработка лекарств, персонализированная медицина.
*   **Финансы:** оценка кредитных рисков, обнаружение мошенничества, алгоритмический трейдинг.
*   **Ритейл:** рекомендательные системы, прогнозирование спроса, оптимизация цен.
*   **Производство:** контроль качества, предиктивное обслуживание, оптимизация цепочек поставок.
*   **Транспорт:** беспилотные автомобили, оптимизация маршрутов, прогнозирование трафика.
*   **Маркетинг:** таргетированная реклама, анализ настроений, сегментация клиентов.
*   **Безопасность:** распознавание лиц, обнаружение вторжений, кибербезопасность.
*   **Игры:** искусственный интеллект для игровых персонажей, процедурная генерация контента.
*   **Обработка естественного языка:** машинный перевод, анализ текста, чат-боты.
*   **Компьютерное зрение:** распознавание изображений, видеоаналитика, дополненная реальность.

**5. Методы предподготовки экспериментальных данных. Задача фильтрации выбросов – обнаружение в обучающей выборке нетипичных объектов.**

**Методы предподготовки экспериментальных данных:**

*   **Очистка данных (Data Cleaning):**
    *   **Обработка пропущенных значений (Missing Data Imputation):** удаление объектов с пропусками, заполнение пропусков средним, медианой, модой или с помощью более сложных алгоритмов.
    *   **Устранение выбросов (Outlier Removal):** обнаружение и удаление аномальных значений, которые могут искажать результаты обучения.
    *   **Обработка дубликатов (Duplicate Handling):** удаление повторяющихся записей.
    *   **Исправление ошибок (Error Correction):** исправление неверных значений, например, опечаток.
*   **Преобразование данных (Data Transformation):**
    *   **Нормализация (Normalization):** приведение значений признаков к определенному диапазону, например, от 0 до 1.
    *   **Стандартизация (Standardization):** приведение значений признаков к нулевому среднему и единичному стандартному отклонению.
    *   **Логарифмирование (Log Transformation):** применяется для уменьшения влияния больших значений и приведения данных к более нормальному распределению.
    *   **Создание новых признаков (Feature Engineering):** создание новых признаков на основе существующих, например, вычисление отношения двух признаков.
*   **Уменьшение размерности (Dimensionality Reduction):**
    *   **Отбор признаков (Feature Selection):** выбор наиболее информативных признаков.
    *   **Извлечение признаков (Feature Extraction):** создание новых признаков, являющихся комбинацией исходных, например, с помощью PCA.
*   **Кодирование категориальных признаков (Categorical Encoding):**
    *   **One-Hot Encoding:** создание бинарных признаков для каждой категории.
    *   **Label Encoding:** присвоение каждой категории числового кода.
*   **Разделение данных (Data Splitting):**
    *   **Train/Validation/Test Split:** разделение данных на обучающую, валидационную и тестовую выборки.
    *   **Кросс-валидация (Cross-Validation):** многократное разделение данных на обучающую и тестовую выборки для более надежной оценки модели.

**Задача фильтрации выбросов – обнаружение в обучающей выборке нетипичных объектов.**

**Выбросы (Outliers)** - это значения, которые существенно отличаются от остальных значений в наборе данных. Они могут быть вызваны ошибками измерения, некорректными данными или являться реальными, но редкими событиями.

**Методы обнаружения выбросов:**

*   **Статистические методы:**
    *   **Правило трех сигм (3-sigma rule):** значения, выходящие за пределы трех стандартных отклонений от среднего, считаются выбросами. ([https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule](https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule))
    *   **Межквартильный размах (Interquartile Range, IQR):** значения, выходящие за пределы 1.5\*IQR от первого и третьего квартилей, считаются выбросами. ([https://en.wikipedia.org/wiki/Interquartile_range](https://en.wikipedia.org/wiki/Interquartile_range))
    *   **Z-оценка (Z-score):** мера того, насколько далеко значение находится от среднего в единицах стандартного отклонения. ([https://en.wikipedia.org/wiki/Standard_score](https://en.wikipedia.org/wiki/Standard_score))
    *   **Модифицированная Z-оценка (Modified Z-score):** более устойчивая к выбросам версия Z-оценки. ([https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm](https://www.itl.nist.gov/div898/handbook/eda/section3/eda35h.htm))
*   **Методы машинного обучения:**
    *   **Метод k-ближайших соседей (k-Nearest Neighbors):** объекты, находящиеся далеко от своих соседей, считаются выбросами.
    *   **Изолирующий лес (Isolation Forest):** алгоритм, который изолирует аномалии, вместо того чтобы профилировать нормальные точки.
    *   **Одноклассовый SVM (One-Class SVM):** строит границу вокруг нормальных данных, а объекты за пределами границы считаются выбросами.
    *   **Автоэнкодеры (Autoencoders):** нейронные сети, которые пытаются реконструировать входные данные, большие ошибки реконструкции указывают на выбросы.
*   **Визуальные методы:**
    *   **Ящик с усами (Box Plot):** графическое представление распределения данных, на котором видны выбросы. ([https://en.wikipedia.org/wiki/Box_plot](https://en.wikipedia.org/wiki/Box_plot))
    *   **Диаграмма рассеяния (Scatter Plot):** график, на котором каждая точка представляет собой объект, выбросы видны как точки, удаленные от основного облака точек. ([https://en.wikipedia.org/wiki/Scatter_plot](https://en.wikipedia.org/wiki/Scatter_plot))
    *   **Гистограмма (Histogram):** графическое представление распределения данных, выбросы могут быть видны как редкие значения. ([https://en.wikipedia.org/wiki/Histogram](https://en.wikipedia.org/wiki/Histogram))

**Обработка выбросов:**

*   **Удаление (Removal):** выбросы удаляются из данных.
*   **Замена (Replacement):** выбросы заменяются на другие значения, например, на среднее, медиану или на значение, предсказанное моделью.
*   **Трансформация (Transformation):** применение математических преобразований, таких как логарифмирование, для уменьшения влияния выбросов.
*   **Винзоризация (Winsorization):** замена экстремальных значений на ближайшие не экстремальные значения.

**Ссылки:**

*   [Outlier - Wikipedia](https://en.wikipedia.org/wiki/Outlier)
*   [Anomaly Detection - Wikipedia](https://en.wikipedia.org/wiki/Anomaly_detection)
*   [5 Ways to Detect Outliers/Anomalies That Every Data Scientist Should Know](https://towardsdatascience.com/5-ways-to-detect-outliers-that-every-data-scientist-should-know-python-code-70a54335a623)

**6. Задача заполнения пропущенных значений. Алгоритмы заполнения пропусков. Методы Барлетта и resampling.**

**Задача заполнения пропущенных значений (Missing Data Imputation):**

Пропущенные значения - это отсутствующие данные в наборе данных. Они могут возникать по разным причинам, таким как ошибки при сборе данных, неполные ответы респондентов или потеря данных. Пропущенные значения могут негативно влиять на результаты обучения моделей машинного обучения, поэтому их необходимо обрабатывать.

**Алгоритмы заполнения пропусков:**

*   **Удаление (Deletion):**
    *   **Listwise Deletion (Complete Case Analysis):** удаление всех объектов, у которых есть хотя бы одно пропущенное значение. Просто, но может привести к значительной потере данных.
    *   **Pairwise Deletion (Available Case Analysis):** использование всех доступных данных для каждой операции. Может приводить к несогласованности результатов.
*   **Простое заполнение (Single Imputation):**
    *   **Mean/Median/Mode Imputation:** замена пропущенных значений средним, медианой или модой соответствующего признака. Просто, но может искажать распределение данных и занижать стандартное отклонение.
    *   **Regression Imputation:** предсказание пропущенных значений с помощью регрессионной модели, обученной на полных данных. Более точно, чем mean/median/mode imputation, но может привести к переобучению.
    *   **Stochastic Regression Imputation:**  добавление случайного шума к предсказанным значениям в Regression Imputation, чтобы сохранить изменчивость данных.
    *   **K-Nearest Neighbors (KNN) Imputation:** поиск k ближайших соседей для объекта с пропущенным значением и заполнение пропуска на основе значений этого признака у соседей. Учитывает взаимосвязи между признаками, но может быть вычислительно дорогим.
*   **Множественное заполнение (Multiple Imputation):**
    *   **MICE (Multiple Imputation by Chained Equations):** создание нескольких заполненных наборов данных путем итеративного моделирования каждого признака с пропущенными значениями с использованием других признаков. Учитывает неопределенность, связанную с заполнением пропусков, но может быть сложным в реализации.

**Методы Барлетта и Resampling:**

*   **Тест Барлетта (Bartlett's Test):** используется для проверки равенства дисперсий в нескольких группах. В контексте заполнения пропусков может использоваться для сравнения дисперсий признака до и после заполнения, чтобы оценить, насколько сильно заполнение исказило данные.

* **Resampling:**

    *   **Бутстрап (Bootstrap):** метод многократного создания выборок с возвращением из исходного набора данных. В контексте заполнения пропусков может использоваться для оценки неопределенности, связанной с заполнением, путем создания нескольких заполненных наборов данных с помощью бутстрапа и анализа разброса результатов.
    *   **Джекнайф (Jackknife):** метод последовательного удаления по одному объекту из исходного набора данных и оценки статистики на оставшихся данных. Может использоваться для оценки смещения и дисперсии оценок, полученных после заполнения пропусков.

**Ссылки:**

*   [Missing data - Wikipedia](https://en.wikipedia.org/wiki/Missing_data)
*   [Imputation (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Imputation_(statistics))
*   [A practical guide to multiple imputation in Stata](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4778887/)
*   [Multiple Imputation by Chained Equations: What is it and how does it work?](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3074241/)
*   [Bartlett's test - Wikipedia](https://en.wikipedia.org/wiki/Bartlett%27s_test)
*   [Resampling (statistics) - Wikipedia](https://en.wikipedia.org/wiki/Resampling_(statistics))

**7. Метод восстановления пропущенного значения на основе Zet - алгоритма.**

**Zet-алгоритм** - это итеративный алгоритм заполнения пропущенных значений, основанный на минимизации корреляции между признаками. Он относится к классу алгоритмов, использующих матричные вычисления для восстановления пропущенных данных.

**Основные шаги Zet-алгоритма:**

1. **Инициализация:** пропущенные значения заполняются случайными числами или средними значениями соответствующих признаков.
2. **Итерации:**
    *   Для каждого признака с пропущенными значениями строится линейная регрессионная модель, предсказывающая этот признак на основе других признаков.
    *   Пропущенные значения этого признака заполняются предсказанными значениями.
    *   Шаги повторяются до тех пор, пока изменения в заполненных значениях не станут незначительными или не будет достигнуто максимальное количество итераций.

**Преимущества:**

*   Учитывает корреляционные связи между признаками.
*   Позволяет восстанавливать пропущенные значения даже при большом количестве пропусков.

**Недостатки:**

*   Вычислительно затратный, особенно при большом количестве признаков.
*   Может приводить к переобучению, если данных мало.
*   Предполагает линейную зависимость между признаками.

**Ссылки:**

*   [Imputation of missing values using iterative local least squares](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.30.3264&rep=rep1&type=pdf)

**8. Методы максимального правдоподобия. МП алгоритм. Цели и особенности применения.**

**Метод максимального правдоподобия (Maximum Likelihood Estimation, MLE):**  это метод оценки параметров статистической модели, при котором выбираются такие значения параметров, которые максимизируют функцию правдоподобия. Функция правдоподобия показывает, насколько вероятно получить наблюдаемые данные при данных значениях параметров модели.

**Основные понятия:**

*   **Параметры модели:** неизвестные величины, характеризующие распределение данных.
*   **Функция правдоподобия (Likelihood Function):** функция, которая показывает вероятность получения наблюдаемых данных при заданных значениях параметров.
*   **Оценка максимального правдоподобия (Maximum Likelihood Estimate, MLE):** значения параметров, при которых функция правдоподобия достигает максимума.

**МП-алгоритм (Maximum Likelihood Algorithm):** общий алгоритм для нахождения оценок максимального правдоподобия. Он может быть реализован различными способами, в зависимости от конкретной модели и функции правдоподобия.

**Цели применения:**

*   Оценка параметров статистических моделей.
*   Построение доверительных интервалов для параметров.
*   Проверка статистических гипотез.

**Особенности применения:**

*   Требует знания функции правдоподобия, которая зависит от предполагаемого распределения данных.
*   Может быть вычислительно сложным для некоторых моделей.
*   При достаточно большом объеме данных оценки максимального правдоподобия обычно являются состоятельными (сходятся к истинным значениям параметров), несмещенными (не имеют систематической ошибки) и эффективными (имеют наименьшую дисперсию среди всех несмещенных оценок).
*   Может быть чувствителен к выбросам.

**Примеры:**

*   Оценка параметров нормального распределения (среднего и дисперсии).
*   Оценка параметров линейной регрессии.
*   Оценка параметров логистической регрессии.

**Ссылки:**

*   [Maximum likelihood estimation - Wikipedia](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation)
*   [Maximum Likelihood Estimation (MLE) Explained](https://towardsdatascience.com/maximum-likelihood-estimation-mle-explained-a7d3c8dd9b6)
*   [Maximum Likelihood Estimation (MLE) | Brilliant Math & Science Wiki](https://brilliant.org/wiki/maximum-likelihood-estimation-mle/)

**9. ЕМ алгоритм. Цели и особенности применения.**

**EM-алгоритм (Expectation-Maximization algorithm):** итеративный алгоритм для нахождения оценок максимального правдоподобия в моделях со скрытыми переменными. Он чередует два шага:

1. **E-шаг (Expectation):** вычисление ожидаемого значения логарифма функции правдоподобия по скрытым переменным при текущих оценках параметров.
2. **M-шаг (Maximization):** нахождение значений параметров, максимизирующих ожидаемое значение логарифма функции правдоподобия, вычисленное на E-шаге.

**Цели применения:**

*   Оценка параметров моделей со скрытыми переменными.
*   Кластеризация данных (например, в смеси гауссовских распределений).
*   Заполнение пропущенных значений.
*   Обучение скрытых марковских моделей.

**Особенности применения:**

*   Гарантирует монотонное увеличение функции правдоподобия на каждой итерации.
*   Сходится к локальному максимуму функции правдоподобия.
*   Может быть медленным, особенно при большом количестве скрытых переменных.
*   Чувствителен к выбору начальных значений параметров.

**Пример:**

*   **Кластеризация данных с помощью смеси гауссовских распределений:**
    *   Скрытые переменные: принадлежность объектов к кластерам.
    *   Параметры: средние и ковариационные матрицы гауссовских распределений.
    *   E-шаг: вычисление вероятности принадлежности каждого объекта к каждому кластеру.
    *   M-шаг: переоценка средних и ковариационных матриц гауссовских распределений на основе вычисленных вероятностей.

**Ссылки:**

*   [Expectation–maximization algorithm - Wikipedia](https://en.wikipedia.org/wiki/Expectation%E2%80%93maximization_algorithm)
*   [The EM Algorithm - Stanford CS229 Lecture Notes](https://cs229.stanford.edu/notes2021fall/cs229-notes8.pdf)
*   [A Gentle Introduction to the EM Algorithm](https://towardsdatascience.com/a-gentle-introduction-to-the-em-algorithm-6dd7d3b3cc9)

**10. Понижение размерности. Метод главных компонент. Цели и особенности применения.**

**Понижение размерности (Dimensionality Reduction):** это процесс уменьшения количества признаков в наборе данных с сохранением как можно большей информации.
**Цели понижения размерности:**

*   **Упрощение данных:** сделать данные более компактными и удобными для анализа.
*   **Ускорение обучения моделей:** уменьшение количества признаков может значительно ускорить обучение моделей машинного обучения.
*   **Устранение избыточности:** удаление коррелированных признаков, которые не несут дополнительной информации.
*   **Визуализация данных:** представление многомерных данных в двумерном или трехмерном пространстве для удобства визуализации.
*   **Борьба с "проклятием размерности":** при большом количестве признаков данные становятся разреженными, что может негативно влиять на производительность моделей.
*   **Снижение шума:** удаление признаков, содержащих много шума, может улучшить качество моделей.

**Метод главных компонент (Principal Component Analysis, PCA):** один из наиболее популярных методов понижения размерности. Он основан на линейном преобразовании данных, при котором исходные признаки заменяются на новые, некоррелированные признаки, называемые главными компонентами. Главные компоненты упорядочены по убыванию дисперсии, то есть первая главная компонента объясняет наибольшую долю дисперсии данных, вторая - следующую по величине долю и т.д.

**Основные шаги PCA:**

1. **Центрирование данных:** вычитание среднего значения из каждого признака.
2. **Вычисление ковариационной матрицы:** матрица, описывающая взаимосвязь между признаками.
3. **Вычисление собственных векторов и собственных значений ковариационной матрицы:** собственные векторы определяют направления главных компонент, а собственные значения - величину дисперсии вдоль этих направлений.
4. **Выбор главных компонент:** выбор такого количества главных компонент, которое объясняет достаточно большую долю дисперсии данных (например, 95% или 99%).
5. **Проецирование данных на пространство главных компонент:** преобразование исходных данных в новое пространство, где координаты объектов соответствуют значениям главных компонент.

**Цели применения PCA:**

*   **Уменьшение размерности данных.**
*   **Визуализация многомерных данных.**
*   **Сжатие данных.**
*   **Устранение шума.**
*   **Подготовка данных для других алгоритмов машинного обучения.**

**Особенности применения PCA:**

*   Предполагает линейную зависимость между признаками.
*   Чувствителен к масштабированию признаков.
*   Интерпретация главных компонент может быть затруднена.
*   Не учитывает метки классов, поэтому может не подходить для задач классификации.

**Ссылки:**

*   [Principal component analysis - Wikipedia](https://en.wikipedia.org/wiki/Principal_component_analysis)
*   [A Step-by-Step Explanation of PCA](https://towardsdatascience.com/a-step-by-step-explanation-of-pca-b836fb9c97e2)
*   [Principal Component Analysis (PCA) explained visually with zero math](https://www.youtube.com/watch?v=FgakZw6K1QQ)

**11. Понижение размерности. Селекция признаков.**

**Селекция признаков (Feature Selection):** это процесс отбора наиболее важных признаков из исходного набора данных. В отличие от методов извлечения признаков (Feature Extraction), таких как PCA, селекция признаков не создает новые признаки, а выбирает подмножество из существующих.

**Цели селекции признаков:**

*   **Улучшение производительности моделей:** удаление неинформативных и избыточных признаков может улучшить точность и обобщающую способность моделей.
*   **Сокращение времени обучения:** меньшее количество признаков требует меньше времени на обучение моделей.
*   **Улучшение интерпретируемости моделей:** модели с меньшим количеством признаков легче интерпретировать.
*   **Борьба с переобучением:** удаление признаков, которые не несут полезной информации, может помочь избежать переобучения.

**Методы селекции признаков:**

*   **Фильтрация (Filter Methods):**
    *   **Оценка корреляции:** отбор признаков, имеющих сильную корреляцию с целевой переменной. Примеры: коэффициент корреляции Пирсона, коэффициент корреляции Спирмена.
    *   **Информационный прирост (Information Gain):** мера того, насколько уменьшается неопределенность целевой переменной при знании значения признака.
    *   **Хи-квадрат (Chi-Squared):** статистический тест, используемый для оценки зависимости между категориальными признаками и целевой переменной.
    *   **ANOVA F-value:** статистический тест, используемый для оценки различий между средними значениями целевой переменной в разных группах, определенных значениями признака.

*   **Обертывание (Wrapper Methods):**
    *   **Прямой поиск (Forward Selection):** итеративный процесс, начинающийся с пустого множества признаков и добавляющий на каждом шаге признак, который дает наибольший прирост производительности модели.
    *   **Обратный поиск (Backward Elimination):** итеративный процесс, начинающийся с полного набора признаков и удаляющий на каждом шаге признак, удаление которого приводит к наименьшему ухудшению производительности модели.
    *   **Рекурсивное исключение признаков (Recursive Feature Elimination, RFE):** итеративный процесс, который обучает модель на всех признаках, ранжирует признаки по важности, удаляет наименее важный признак и повторяет процесс до тех пор, пока не останется заданное количество признаков.

*   **Встраивание (Embedded Methods):**
    *   **L1-регуляризация (LASSO):** метод регуляризации, который штрафует модель за большие веса признаков, что приводит к занулению весов некоторых признаков и, таким образом, к их исключению из модели.
    *   **Деревья решений:** деревья решений могут использоваться для оценки важности признаков на основе того, насколько часто они используются для разделения данных.
    *   **Случайный лес:** ансамбль деревьев решений, который может использоваться для оценки важности признаков на основе усредненной важности признаков в отдельных деревьях.

**Ссылки:**

*   [Feature selection - Wikipedia](https://en.wikipedia.org/wiki/Feature_selection)
*   [Feature Selection Techniques in Machine Learning](https://towardsdatascience.com/feature-selection-techniques-in-machine-learning-with-python-f24e7da3f36e)
*   [A Comprehensive Guide to Feature Selection](https://www.kdnuggets.com/2021/06/comprehensive-guide-feature-selection.html)

**12. Метод независимых компонент.**

**Метод независимых компонент (Independent Component Analysis, ICA):** это метод разделения многомерного сигнала на независимые компоненты. В отличие от PCA, который ищет некоррелированные компоненты, ICA ищет статистически независимые компоненты.

**Основные понятия:**

*   **Независимость:** два случайных величины статистически независимы, если знание одной из них не дает никакой информации о другой.
*   **Некоррелированность:** два случайных величины некоррелированы, если их ковариация равна нулю. Независимость влечет за собой некоррелированность, но обратное не всегда верно.
*   **Смешанный сигнал:** сигнал, который является линейной комбинацией нескольких независимых источников.
*   **Разделяющая матрица:** матрица, которая преобразует смешанный сигнал в независимые компоненты.

**Цели применения ICA:**

*   **Разделение смешанных сигналов:** например, разделение аудиозаписей нескольких говорящих людей, записанных одним микрофоном.
*   **Анализ данных в нейробиологии:** разделение сигналов ЭЭГ и МЭГ на независимые источники мозговой активности.
*   **Обработка изображений:** удаление шума, выделение объектов.
*   **Финансовый анализ:** выявление скрытых факторов, влияющих на рынок.

**Алгоритмы ICA:**

*   **FastICA:** один из наиболее популярных алгоритмов ICA, основанный на максимизации негоауссовости компонент.
*   **Infomax:** алгоритм, основанный на максимизации взаимной информации между входными и выходными данными.
*   **JADE:** алгоритм, основанный на совместной диагонализации матриц кумулянтов четвертого порядка.

**Особенности применения ICA:**

*   Предполагает, что смешанные сигналы являются линейной комбинацией независимых источников.
*   Не может определить порядок и масштаб независимых компонент.
*   Требует, чтобы количество независимых источников было не больше, чем количество наблюдаемых сигналов.
*   Чувствителен к шуму.

**Отличия от PCA:**

*   **PCA** ищет **некоррелированные** компоненты, **ICA** ищет **независимые** компоненты.
*   **PCA** упорядочивает компоненты по убыванию дисперсии, **ICA** не имеет такого упорядочения.
*   **PCA** предполагает ортогональность главных компонент, **ICA** не делает таких предположений.

**Ссылки:**

*   [Independent component analysis - Wikipedia](https://en.wikipedia.org/wiki/Independent_component_analysis)
*   [Independent Component Analysis (ICA)](https://www.youtube.com/watch?v=D_f-AKFpeDg)
*   [A Tutorial on Independent Component Analysis](https://www.cs.helsinki.fi/u/ahyvarin/papers/NN00new.pdf)

**13. Метрические методы. Кластеризация. Иерархические методы кластерного анализа.**

**Метрические методы:** это методы машинного обучения, основанные на вычислении расстояний между объектами. Расстояние - это мера сходства или различия между объектами.

**Кластеризация:** это задача группировки объектов по схожести. Объекты в одном кластере должны быть похожи друг на друга, а объекты в разных кластерах - отличаться.

**Иерархические методы кластерного анализа:** это методы кластеризации, которые строят иерархию кластеров. Иерархия может быть построена двумя способами:

*   **Агломеративные (снизу вверх):** каждый объект изначально рассматривается как отдельный кластер, затем на каждом шаге объединяются два ближайших кластера, пока все объекты не будут объединены в один кластер.
*   **Дивизивные (сверху вниз):** все объекты изначально рассматриваются как один кластер, затем на каждом шаге кластер разделяется на два подкластера, пока каждый объект не окажется в отдельном кластере.

**Основные шаги агломеративного иерархического алгоритма:**

1. Вычислить матрицу расстояний между всеми объектами.
2. Каждый объект рассматривается как отдельный кластер.
3. Найти два ближайших кластера и объединить их в один кластер.
4. Пересчитать расстояния между новым кластером и остальными кластерами.
5. Повторять шаги 3 и 4, пока все объекты не будут объединены в один кластер.

**Ссылки:**

*   [Cluster analysis - Wikipedia](https://en.wikipedia.org/wiki/Cluster_analysis)
*   [Hierarchical clustering - Wikipedia](https://en.wikipedia.org/wiki/Hierarchical_clustering)
*   [Hierarchical Clustering Essentials](https://www.datanovia.com/en/lessons/agglomerative-hierarchical-clustering/)

**14. Метрические методы. Кластеризация. Дендрограмма. Меры сходства. Расстояния между объектами данных.**

**Дендрограмма:** это древовидный график, который показывает иерархическую структуру кластеров, полученную в результате иерархического кластерного анализа. По горизонтальной оси откладываются объекты, а по вертикальной - расстояние между кластерами. Высота ветвей дерева соответствует расстоянию между объединяемыми кластерами.

**Меры сходства:** это функции, которые определяют, насколько два объекта похожи друг на друга. Меры сходства обычно принимают значения от 0 до 1, где 0 означает отсутствие сходства, а 1 - полное сходство.

**Расстояния между объектами данных:** это функции, которые определяют, насколько два объекта отличаются друг от друга. Расстояния обычно принимают неотрицательные значения, где 0 означает, что объекты идентичны, а большие значения означают большее различие.

**Примеры мер сходства и расстояний:**

*   **Евклидово расстояние:** наиболее распространенное расстояние, вычисляется как корень из суммы квадратов разностей координат объектов. Подходит для числовых признаков.
    $$d(x, y) = \sqrt{\sum_{i=1}^{n}(x_i - y_i)^2}$$
*   **Манхэттенское расстояние (расстояние городских кварталов):** вычисляется как сумма модулей разностей координат объектов. Менее чувствительно к выбросам, чем евклидово расстояние.
    $$d(x, y) = \sum_{i=1}^{n}|x_i - y_i|$$
*   **Расстояние Чебышева:** вычисляется как максимум модуля разности координат объектов.
    $$d(x, y) = \max_{i=1}^{n}|x_i - y_i|$$
*   **Косинусное расстояние:** вычисляется как 1 минус косинус угла между векторами объектов. Используется для измерения сходства текстов и других объектов, представленных векторами.
    $$d(x, y) = 1 - \frac{\sum_{i=1}^{n}x_i y_i}{\sqrt{\sum_{i=1}^{n}x_i^2} \sqrt{\sum_{i=1}^{n}y_i^2}}$$
*   **Коэффициент Жаккара:** мера сходства, используемая для бинарных данных. Вычисляется как отношение мощности пересечения множеств к мощности их объединения.
    $$J(A, B) = \frac{|A \cap B|}{|A \cup B|}$$
*   **Расстояние Хэмминга:** мера различия, используемая для бинарных данных. Вычисляется как количество позиций, в которых значения признаков различаются.
    $$d(x, y) = \sum_{i=1}^{n} \mathbb{1}(x_i \neq y_i)$$

**Выбор меры сходства/расстояния зависит от:**

*   **Типа данных:** числовые, категориальные, бинарные, текстовые.
*   **Цели кластеризации:** что важнее - форма или масштаб.
*   **Наличия выбросов:** некоторые расстояния более чувствительны к выбросам, чем другие.

**Ссылки:**

*   [Дендрограмма](https://ru.wikipedia.org/wiki/%D0%94%D0%B5%D0%BD%D0%B4%D1%80%D0%BE%D0%B3%D1%80%D0%B0%D0%BC%D0%BC%D0%B0)
*   [Similarity measure - Wikipedia](https://en.wikipedia.org/wiki/Similarity_measure)
*   [Euclidean distance - Wikipedia](https://en.wikipedia.org/wiki/Euclidean_distance)
*   [Taxicab geometry - Wikipedia](https://en.wikipedia.org/wiki/Taxicab_geometry)
*   [Chebyshev distance - Wikipedia](https://en.wikipedia.org/wiki/Chebyshev_distance)
*   [Cosine similarity - Wikipedia](https://en.wikipedia.org/wiki/Cosine_similarity)
*   [Jaccard index - Wikipedia](https://en.wikipedia.org/wiki/Jaccard_index)
*   [Hamming distance - Wikipedia](https://en.wikipedia.org/wiki/Hamming_distance)

**15. Метрические методы. Кластеризация. Методы объединения.**

**Методы объединения (Linkage Methods):** определяют, как рассчитывается расстояние между кластерами в агломеративном иерархическом кластерном анализе.

**Основные методы объединения:**

*   **Метод одиночной связи (Single Linkage), метод ближайшего соседа:** расстояние между двумя кластерами определяется как минимальное расстояние между объектами из этих кластеров.
    $$d(C_1, C_2) = \min_{x \in C_1, y \in C_2} d(x, y)$$
    *   **Склонно к образованию цепочек (chaining effect),** когда кластеры вытягиваются в длинные цепочки.

*   **Метод полной связи (Complete Linkage), метод дальнего соседа:** расстояние между двумя кластерами определяется как максимальное расстояние между объектами из этих кластеров.
    $$d(C_1, C_2) = \max_{x \in C_1, y \in C_2} d(x, y)$$
    *   **Склонно к образованию компактных, сферических кластеров.**

*   **Метод средней связи (Average Linkage):** расстояние между двумя кластерами определяется как среднее расстояние между всеми парами объектов из этих кластеров.
    $$d(C_1, C_2) = \frac{1}{|C_1||C_2|} \sum_{x \in C_1} \sum_{y \in C_2} d(x, y)$$
    *   **Компромисс между методами одиночной и полной связи.**

*   **Метод центроидов (Centroid Method):** расстояние между двумя кластерами определяется как расстояние между их центроидами (средними значениями признаков).
    $$d(C_1, C_2) = d(\mu_1, \mu_2),$$
    где $\mu_1$ и $\mu_2$ - центроиды кластеров $C_1$ и $C_2$.
    *   **Может приводить к инверсиям (inversions),** когда расстояние между кластерами на более высоком уровне иерархии меньше, чем на более низком.

*   **Метод Уорда (Ward's Method):** на каждом шаге объединяются те два кластера, которые приводят к минимальному увеличению within-cluster variance (внутрикластерной дисперсии).
    *   **Склонно к образованию кластеров примерно одинакового размера.**
    *   **Часто считается наиболее предпочтительным методом объединения.**

**Выбор метода объединения зависит от:**

*   **Цели кластеризации:** какую форму кластеров мы ожидаем получить.
*   **Свойств данных:** наличие выбросов, распределение данных.

**Ссылки:**

*   [Hierarchical clustering - Wikipedia#Cluster_Linkage](https://en.wikipedia.org/wiki/Hierarchical_clustering#Cluster_Linkage)
*   [Linkage Methods - an overview](https://www.statisticshowto.com/linkage-methods-hierarchical-clustering/)
*   [Understanding Linkage Methods for Hierarchical Clustering](https://towardsdatascience.com/understanding-the-concept-of-hierarchical-clustering-technique-c6e8243758ec)

**16. Метод ближнего соседа. Цели и особенности применения.**

**Метод ближнего соседа (Nearest Neighbor):** это простейший метрический алгоритм классификации и регрессии. В задаче классификации он относит объект к тому классу, к которому принадлежит его ближайший сосед. В задаче регрессии он предсказывает значение целевой переменной как значение целевой переменной у ближайшего соседа.

**Цели применения:**

*   **Классификация:** отнесение объектов к определенным категориям.
*   **Регрессия:** предсказание числового значения целевой переменной.
*   **Поиск аномалий:** объекты, которые находятся далеко от своих соседей, могут считаться аномалиями.
*   **Рекомендательные системы:** поиск объектов, похожих на те, которые понравились пользователю.

**Особенности применения:**

*   **Простота реализации.**
*   **Не требует обучения модели:** все вычисления производятся во время предсказания.
*   **Высокая вычислительная сложность при большом количестве данных:** необходимо вычислять расстояния до всех объектов обучающей выборки.
*   **Чувствительность к выбору метрики.**
*   **Чувствительность к выбросам.**
*   **Не дает вероятностных оценок принадлежности к классам.**
*   **Хорошо работает, когда данные хорошо разделимы в пространстве признаков.**

**Ссылки:**

*   [k-nearest neighbors algorithm - Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
*   [Nearest neighbor search - Wikipedia](https://en.wikipedia.org/wiki/Nearest_neighbor_search)

**17. Метод k-ближайшего соседа. Специфика применения.**

**Метод k-ближайших соседей (k-Nearest Neighbors, k-NN):** это обобщение метода ближнего соседа. В задаче классификации он относит объект к тому классу, который наиболее представлен среди его k ближайших соседей. В задаче регрессии он предсказывает значение целевой переменной как среднее (или взвешенное среднее) значений целевой переменной у k ближайших соседей.

**Специфика применения:**

*   **Параметр k:** количество соседей, которое учитывается при принятии решения.
    *   **Маленькие значения k:** модель чувствительна к шуму и выбросам, может переобучаться.
    *   **Большие значения k:** модель более устойчива к шуму, но может не улавливать локальные особенности данных.
    *   **Выбор k обычно осуществляется с помощью кросс-валидации.**
*   **Взвешенное голосование:** соседи могут вносить разный вклад в предсказание в зависимости от расстояния до объекта. Чем ближе сосед, тем больше его вес.
    *   **Веса могут вычисляться различными способами, например, обратно пропорционально расстоянию.**
*   **Выбор метрики:** как и в методе ближнего соседа, выбор метрики имеет большое значение.
*   **Вычислительная сложность:** все еще высокая, но существуют методы для ускорения поиска k ближайших соседей, такие как KD-деревья и Ball-деревья.
*   **Лучше работает, чем метод 1-ближайшего соседа, когда данные зашумлены или имеются выбросы.**

**Преимущества k-NN:**

*   **Простота реализации.**
*   **Непараметрический метод:** не делает предположений о распределении данных.
*   **Может использоваться как для классификации, так и для регрессии.**

**Недостатки k-NN:**

*   **Высокая вычислительная сложность при большом количестве данных.**
*   **Чувствительность к выбору k и метрики.**
*   **Необходимость хранения всей обучающей выборки.**
*   **Плохо работает при несбалансированных классах (если объектов одного класса намного больше, чем объектов другого класса).**

**Ссылки:**

*   [k-nearest neighbors algorithm - Wikipedia](https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)
*   [K-Nearest Neighbors (KNN) Algorithm for Machine Learning](https://towardsdatascience.com/k-nearest-neighbors-knn-algorithm-for-machine-learning-d63c1e54c16)
*   [Introduction to k-Nearest Neighbors](https://www.datacamp.com/community/tutorials/k-nearest-neighbor-classification-scikit-learn)

**18. Метод наиболее удаленных соседей. Специфика применения.**

**Метод наиболее удаленных соседей (Farthest-Point Heuristic, Farthest Neighbor):** это алгоритм кластеризации, который используется для поиска начального приближения для алгоритма k-средних или как самостоятельный алгоритм кластеризации. Он выбирает наиболее удаленные друг от друга точки в качестве начальных центроидов.

**Специфика применения:**

*   **Инициализация алгоритма k-средних:** выбор хорошего начального приближения может существенно повлиять на качество кластеризации, получаемой с помощью k-средних. Метод наиболее удаленных соседей позволяет выбрать начальные центроиды, которые расположены далеко друг от друга и, следовательно, с большей вероятностью окажутся в разных кластерах.
*   **Кластеризация:** может использоваться как самостоятельный алгоритм кластеризации, особенно когда данные имеют четко выраженную кластерную структуру и кластеры хорошо разделимы.
*   **Поиск аномалий:** наиболее удаленные точки могут рассматриваться как потенциальные аномалии.

**Алгоритм:**

1. Выбрать случайную точку в качестве первого центроида.
2. Найти точку, наиболее удаленную от первого центроида, и выбрать ее в качестве второго центроида.
3. Найти точку, наиболее удаленную от всех существующих центроидов, и выбрать ее в качестве следующего центроида.
4. Повторять шаг 3, пока не будет выбрано заданное количество центроидов (k).

**Преимущества:**

*   **Простота реализации.**
*   **Вычислительно эффективен.**
*   **Позволяет выбрать начальные центроиды, которые расположены далеко друг от друга.**

**Недостатки:**

*   **Чувствительность к выбросам:** выбросы могут быть выбраны в качестве центроидов, что приведет к плохой кластеризации.
*   **Не гарантирует оптимального решения.**
*   **Результат зависит от выбора первой случайной точки.**

**Ссылки:**

*   [Farthest-point clustering](https://dl.acm.org/doi/10.5555/95889.95914)
*   [Farthest Point Heuristic for Initializing the k-means Algorithm](https://core.ac.uk/download/pdf/82789344.pdf)

**19. Метод Варда. Условия применения.**

**Метод Варда (Ward's Method):** это метод объединения в агломеративном иерархическом кластерном анализе. На каждом шаге он объединяет те два кластера, которые приводят к минимальному увеличению within-cluster variance (внутрикластерной дисперсии).

**Формула:**

Увеличение within-cluster variance при объединении кластеров $C_1$ и $C_2$ вычисляется по формуле:

$$\Delta(C_1, C_2) = \frac{|C_1||C_2|}{|C_1| + |C_2|}||\mu_1 - \mu_2||^2,$$

где $|C_i|$ - количество объектов в кластере $C_i$, $\mu_i$ - центроид кластера $C_i$, $||\cdot||^2$ - квадрат евклидова расстояния.

**Условия применения:**

*   **Числовые признаки:** метод Варда использует евклидово расстояние, поэтому он подходит только для данных с числовыми признаками.
*   **Сферические кластеры:** метод Варда лучше всего работает, когда кластеры имеют сферическую форму и примерно одинаковый размер.
*   **Иерархическая кластеризация:** метод Варда является методом объединения в агломеративном иерархическом кластерном анализе.

**Преимущества:**

*   **Склонно к образованию кластеров примерно одинакового размера.**
*   **Часто считается наиболее предпочтительным методом объединения.**
*   **Менее чувствителен к выбросам, чем методы одиночной и полной связи.**

**Недостатки:**

*   **Вычислительно более затратный, чем другие методы объединения.**
*   **Может плохо работать, если кластеры имеют сильно различающуюся форму или размер.**

**Ссылки:**

*   [Ward's method - Wikipedia](https://en.wikipedia.org/wiki/Ward%27s_method)
*   [Ward's Minimum Variance Method - an overview](https://www.statisticshowto.com/wards-minimum-variance-method/)
*   [Hierarchical Clustering - Ward's Method](https://www.youtube.com/watch?v=OcoE7JlbXvY)

**20. Неиерархические методы кластерного анализа, в том числе алгоритмы k-средних и k-медианы. Отличительные особенности методов.**

**Неиерархические методы кластерного анализа:** это методы кластеризации, которые не строят иерархию кластеров, а сразу разбивают данные на заданное количество кластеров.

**Алгоритм k-средних (k-Means):** один из наиболее популярных алгоритмов кластеризации. Он итеративно разбивает данные на k кластеров, минимизируя within-cluster variance (внутрикластерную дисперсию).

**Основные шаги алгоритма k-средних:**

1. Выбрать k случайных точек в качестве начальных центроидов.
2. Отнести каждый объект к ближайшему центроиду.
3. Пересчитать центроиды как среднее значение объектов в каждом кластере.
4. Повторять шаги 2 и 3, пока центроиды не перестанут изменяться или не будет достигнуто максимальное количество итераций.

**Алгоритм k-медиан (k-Medians):** похож на алгоритм k-средних, но вместо средних значений для вычисления центроидов используются медианы.

**Основные шаги алгоритма k-медиан:**

1. Выбрать k случайных точек в качестве начальных центроидов.
2. Отнести каждый объект к ближайшему центроиду.
3. Пересчитать центроиды как медиану значений объектов в каждом кластере.
4. Повторять шаги 2 и 3, пока центроиды не перестанут изменяться или не будет достигнуто максимальное количество итераций.

**Отличительные особенности методов:**

| Признак             | k-средних                                      | k-медиан                                         |
| --------------------- | ----------------------------------------------- | ------------------------------------------------ |
| **Центроид**         | Среднее значение                             | Медиана                                          |
| **Метрика**          | Евклидово расстояние                           | Манхэттенское расстояние или другое                |
| **Чувствительность к выбросам** | Высокая                                           | Низкая                                            |
| **Форма кластеров**   | Сферические                                    | Менее строгие требования к форме                    |
| **Вычислительная сложность** | Относительно низкая                        | Выше, чем у k-средних                             |

**Преимущества неиерархических методов:**

*   **Относительно высокая скорость работы.**
*   **Простота реализации.**
*   **Подходят для больших наборов данных.**

**Недостатки неиерархических методов:**

*   **Необходимо заранее знать количество кластеров (k).**
*   **Чувствительность к выбору начальных центроидов.**
*   **Могут попадать в локальные минимумы.**
*   **k-средних чувствителен к выбросам**

**Ссылки:**

*   [k-means clustering - Wikipedia](https://en.wikipedia.org/wiki/K-means_clustering)
*   [k-medians clustering - Wikipedia](https://en.wikipedia.org/wiki/K-medians_clustering)
*   [K-Means vs. K-Medians: Which One to Choose?](https://medium.com/@corymaklin/k-means-vs-k-medians-which-one-to-choose-e9ff8d69a41b)

**21. Алгоритм PAM (partitioning around Medoids).**

**Алгоритм PAM (Partitioning Around Medoids):** это неиерархический алгоритм кластеризации, похожий на k-средних, но вместо центроидов (средних значений) использующий медоиды. **Медоид** - это объект в кластере, который имеет минимальную сумму расстояний до всех остальных объектов в этом кластере.

**Основные шаги алгоритма PAM:**

1. Выбрать k случайных объектов в качестве начальных медоидов.
2. Отнести каждый объект к ближайшему медоиду.
3. Для каждого кластера:
    *   Для каждого объекта в кластере:
        *   Рассмотреть этот объект как потенциальный медоид.
        *   Вычислить сумму расстояний от этого объекта до всех остальных объектов в кластере.
    *   Выбрать объект с минимальной суммой расстояний в качестве нового медоида кластера.
4. Повторять шаги 2 и 3, пока медоиды не перестанут изменяться или не будет достигнуто максимальное количество итераций.

**Преимущества PAM:**

*   **Менее чувствителен к выбросам, чем k-средних,** так как использует медоиды, а не средние значения.
*   **Может использоваться с произвольными метриками,** а не только с евклидовым расстоянием.
*   **Более устойчив к шуму, чем k-средних.**

**Недостатки PAM:**

*   **Вычислительно более затратный, чем k-средних,** так как требует вычисления расстояний между всеми парами объектов в каждом кластере.
*   **Необходимо заранее знать количество кластеров (k).**
*   **Чувствительность к выбору начальных медоидов.**

**Сравнение с k-means и k-medians:**

*   **k-means:** использует средние значения, чувствителен к выбросам, работает только с евклидовым расстоянием.
*   **k-medians:** использует медианы, менее чувствителен к выбросам, чем k-means, может работать с другими метриками, но обычно используется с манхэттенским расстоянием.
*   **PAM:** использует медоиды, наименее чувствителен к выбросам, может работать с произвольными метриками, но вычислительно более затратный.

**Ссылки:**

*   [k-medoids - Wikipedia](https://en.wikipedia.org/wiki/K-medoids)
*   [Partitioning Around Medoids (PAM) Clustering](https://www.datanovia.com/en/lessons/pam-partitioning-around-medoids-in-r/)
*   [PAM (Partitioning Around Medoids) Algorithm](https://towardsdatascience.com/clustering-algorithms-pam-partitioning-around-medoids-algorithm-22689e425493)

**22. Анализ и проверка качества кластеризации.**

**Анализ и проверка качества кластеризации** - это важный этап, позволяющий оценить, насколько хорошо алгоритм кластеризации разделил данные на группы.

**Методы оценки качества кластеризации:**

**Внутренние меры (Internal measures):** оценивают качество кластеризации, основываясь только на данных и результатах кластеризации.
    *   **Индекс силуэта (Silhouette index):** измеряет, насколько объект похож на свой кластер по сравнению с другими кластерами. Значения варьируются от -1 до 1, где высокое значение указывает, что объект хорошо соответствует своему кластеру и плохо - соседним.
        $$s(i) = \frac{b(i) - a(i)}{\max\{a(i), b(i)\}},$$
        где $a(i)$ - среднее расстояние от объекта $i$ до других объектов в его кластере, $b(i)$ - среднее расстояние от объекта $i$ до объектов в ближайшем кластере.
    *   **Индекс Дэвиса-Болдуина (Davies-Bouldin index):** измеряет отношение within-cluster distances (внутрикластерных расстояний) к between-cluster distances (межкластерным расстояниям). Более низкие значения указывают на лучшую кластеризацию.
        $$DB = \frac{1}{k} \sum_{i=1}^{k} \max_{j \neq i} \left( \frac{\sigma_i + \sigma_j}{d(c_i, c_j)} \right),$$
        где $k$ - количество кластеров, $\sigma_i$ - среднее расстояние от объектов кластера $i$ до центроида $c_i$, $d(c_i, c_j)$ - расстояние между центроидами $c_i$ и $c_j$.
    *   **Индекс Данна (Dunn index):** измеряет отношение минимального межкластерного расстояния к максимальному внутрикластерному расстоянию. Более высокие значения указывают на лучшую кластеризацию.
        $$D = \frac{\min_{1 \leq i < j \leq k} d(i, j)}{\max_{1 \leq l \leq k} d'(l)},$$
        где $d(i, j)$ - межкластерное расстояние между кластерами $i$ и $j$, $d'(l)$ - внутрикластерное расстояние кластера $l$.
    *   **Сумма квадратов ошибок (Sum of Squared Errors, SSE):** измеряет сумму квадратов расстояний от объектов до центроидов их кластеров. Меньшие значения указывают на лучшую кластеризацию.
        $$SSE = \sum_{i=1}^{k} \sum_{x \in C_i} ||x - \mu_i||^2,$$
        где $k$ - количество кластеров, $C_i$ - кластер $i$, $\mu_i$ - центроид кластера $i$.

*   **Внешние меры (External measures):** оценивают качество кластеризации, сравнивая результаты кластеризации с априори известной разметкой (ground truth).
    *   **Rand index:** измеряет сходство между двумя разбиениями данных. Значения варьируются от 0 до 1, где 1 означает полное совпадение.
    *   **Adjusted Rand index:** скорректированная версия Rand index, учитывающая случайное совпадение.
    *   **F-мера (F-measure):** среднее гармоническое точности и полноты.
    *   **Взаимная информация (Mutual Information):** измеряет количество информации, которое одно разбиение сообщает о другом.
    *   **Adjusted Mutual Information:** скорректированная версия взаимной информации.

**Выбор метода оценки зависит от:**

*   **Наличия априори известной разметки:** если есть разметка, можно использовать внешние меры, иначе - только внутренние.
*   **Цели кластеризации:** что важнее - компактность кластеров или их отделимость друг от друга.

**Ссылки:**

*   [Cluster analysis - Wikipedia#Evaluation_and_assessment](https://en.wikipedia.org/wiki/Cluster_analysis#Evaluation_and_assessment)
*   [Clustering: Evaluation Metrics](https://towardsdatascience.com/clustering-evaluation-metrics-d9e31e772019)
*   [Evaluation of Clustering - Stanford University](https://nlp.stanford.edu/IR-book/html/htmledition/evaluation-of-clustering-1.html)

**23. Методы вейвлет анализа. Виды матричной функции.**

**Вейвлет-анализ:** это метод анализа сигналов, который использует вейвлеты - функции, локализованные как во временной, так и в частотной области. Вейвлет-анализ позволяет разложить сигнал на различные частотные компоненты и изучить их временную локализацию.

**Основные понятия:**

*   **Вейвлет:** функция, которая удовлетворяет определенным математическим свойствам, таким как нулевое среднее значение и ограниченная длительность.
*   **Материнский вейвлет:** базовый вейвлет, из которого генерируются другие вейвлеты путем масштабирования и сдвига.
*   **Масштабирование:** изменение ширины вейвлета, что соответствует изменению частоты анализируемого сигнала.
*   **Сдвиг:** перемещение вейвлета во времени, что позволяет анализировать сигнал в разных временных точках.
*   **Вейвлет-коэффициенты:** коэффициенты разложения сигнала по вейвлетам, которые показывают, насколько сильно вейвлет присутствует в сигнале в определенный момент времени и на определенной частоте.
*   **Вейвлет-преобразование:** процесс разложения сигнала на вейвлет-коэффициенты.

**Виды вейвлет-преобразований:**

*   **Непрерывное вейвлет-преобразование (Continuous Wavelet Transform, CWT):** вычисляет вейвлет-коэффициенты для всех возможных масштабов и сдвигов.
*   **Дискретное вейвлет-преобразование (Discrete Wavelet Transform, DWT):** вычисляет вейвлет-коэффициенты только для дискретного набора масштабов и сдвигов. DWT является более эффективным с вычислительной точки зрения и часто используется в приложениях.

**Виды вейвлетов (материнских функций):**

*   **Вейвлет Хаара (Haar wavelet):** простейший вейвлет, имеет прямоугольную форму.
*   **Вейвлеты Добеши (Daubechies wavelets):** семейство ортогональных вейвлетов с компактным носителем.
*   **Вейвлет Морле (Morlet wavelet):** комплексный вейвлет, используемый для анализа частотно-временных характеристик сигнала.
*   **Мексиканская шляпа (Mexican hat wavelet):** вейвлет, имеющий форму второй производной гауссовой функции.
*   **Symlets:** семейство почти симметричных ортогональных вейвлетов.
*   **Coiflets:** семейство ортогональных вейвлетов с большим количеством нулевых моментов.

**Выбор вейвлета зависит от:**

*   **Свойств сигнала:** для анализа сигналов с резкими изменениями лучше подходят вейвлеты с компактным носителем, такие как вейвлеты Добеши. Для анализа периодических сигналов лучше подходят вейвлеты, такие как Морле.
*   **Цели анализа:** для каких целей используется вейвлет-анализ - для сжатия данных, шумоподавления, обнаружения особенностей и т.д.

**Ссылки:**

*   [Wavelet - Wikipedia](https://en.wikipedia.org/wiki/Wavelet)
*   [Wavelet transform - Wikipedia](https://en.wikipedia.org/wiki/Wavelet_transform)
*   [A Really Friendly Guide to Wavelets](https://www.youtube.com/watch?v=pUbA0cnpkMI)
*   [Wavelets: a mathematical microscope - YouTube](https://www.youtube.com/watch?v=KXw6CRv_zzE)

**24. Скалограмма и скейлограмма.**

**Скалограмма (Scalogram):** это графическое представление непрерывного вейвлет-преобразования (CWT). Она показывает распределение энергии сигнала по различным масштабам (частотам) и времени.

*   **По горизонтальной оси:** откладывается время.
*   **По вертикальной оси:** откладывается масштаб (или частота, которая обратно пропорциональна масштабу).
*   **Цвет:** показывает величину вейвлет-коэффициентов (амплитуду). Обычно используется цветовая шкала, где яркие цвета соответствуют большим значениям амплитуды, а темные - малым.

**Скейлограмма (Scaleogram):** это графическое представление энергии вейвлет-коэффициентов для каждого масштаба. Она показывает, как энергия сигнала распределена по различным масштабам (частотам).

*   **По горизонтальной оси:** откладывается масштаб (или частота).
*   **По вертикальной оси:** откладывается энергия вейвлет-коэффициентов для данного масштаба.

**Различия между скалограммой и скейлограммой:**

*   **Скалограмма** показывает **время-частотное** распределение энергии сигнала, а **скейлограмма** - только **частотное** распределение.
*   **Скалограмма** является **2D** представлением, а **скейлограмма** - **1D**.
*   **Скейлограмма** может быть получена из **скалограммы** путем усреднения энергии вейвлет-коэффициентов по времени для каждого масштаба.

**Применение:**

*   **Анализ нестационарных сигналов:** сигналов, частотные характеристики которых изменяются со временем.
*   **Обнаружение особенностей:** скалограмма позволяет выявлять особенности сигнала, такие как резкие изменения, всплески, периодические компоненты.
*   **Анализ временных рядов:** изучение трендов, сезонности, цикличности.
*   **Обработка изображений:** вейвлет-анализ используется для сжатия изображений, шумоподавления, выделения границ.

**Ссылки:**

*   [Scalogram - Wikipedia](https://en.wikipedia.org/wiki/Scalogram)
*   [A Practical Guide to Time-Frequency Analysis](https://www.researchgate.net/figure/Scalogram-a-and-scaleogram-b-of-a-time-series-with-a-sampling-frequency-of-250-Hz_fig2_333464586)
*   [Time-Frequency Analysis using the Continuous Wavelet Transform](https://www.mathworks.com/help/wavelet/ug/time-frequency-analysis-using-the-continuous-wavelet-transform.html)

**25. Методы классификации. Статистические. Разделяющие (Discriminative models).**

**Методы классификации:** это методы машинного обучения, которые используются для отнесения объектов к определенным категориям (классам).

**Типы методов классификации:**

*   **Статистические методы:** основаны на статистических моделях данных.
    *   **Генеративные (Generative models):** моделируют совместное распределение признаков и классов  $P(X, Y)$. Они могут генерировать новые объекты, а также оценивать $P(Y|X)$.
        *   **Наивный байесовский классификатор (Naive Bayes):** предполагает независимость признаков.
        *   **Линейный дискриминантный анализ (Linear Discriminant Analysis, LDA):** предполагает, что данные в каждом классе имеют нормальное распределение с одинаковой ковариационной матрицей.
        *   **Смеси гауссовских распределений (Gaussian Mixture Models, GMM):** предполагает, что данные в каждом классе являются смесью нескольких гауссовских распределений.
    *   **Разделяющие (Discriminative models):** моделируют условное распределение классов при заданных признаках $P(Y|X)$. Они не могут генерировать новые объекты, но обычно имеют более высокую точность классификации, чем генеративные модели.
        *   **Логистическая регрессия (Logistic Regression):** моделирует вероятность принадлежности объекта к классу с помощью логистической функции.
        *   **Метод опорных векторов (Support Vector Machines, SVM):** строит гиперплоскость, разделяющую объекты разных классов с максимальным зазором.
        *   **Деревья решений (Decision Trees):** строят дерево решений, которое последовательно разделяет данные на подмножества на основе значений признаков.
        *   **Случайный лес (Random Forest):** ансамбль деревьев решений.
        *   **Градиентный бустинг (Gradient Boosting):** последовательное построение ансамбля моделей, каждая из которых исправляет ошибки предыдущих.

**Преимущества разделяющих моделей:**

*   **Более высокая точность классификации** по сравнению с генеративными моделями, особенно при большом количестве признаков.
*   **Меньше вычислительных затрат**, так как не требуется моделировать совместное распределение признаков и классов.

**Недостатки разделяющих моделей:**

*   **Не могут генерировать новые объекты.**
*   **Сложнее интерпретировать**, чем генеративные модели.

**Ссылки:**

*   [Generative model - Wikipedia](https://en.wikipedia.org/wiki/Generative_model)
*   [Discriminative model - Wikipedia](https://en.wikipedia.org/wiki/Discriminative_model)
*   [Generative vs. Discriminative Models - KDnuggets](https://www.kdnuggets.com/2020/12/generative-vs-discriminative-models.html)
*   [What is the difference between a Generative and Discriminative Algorithm?](https://www.youtube.com/watch?v=Tpe-TujqWjM)

**26. Метод опорных векторов (SVM), преимущества и недостатки метода.**

**Метод опорных векторов (Support Vector Machine, SVM):** это алгоритм обучения с учителем, используемый для классификации и регрессии. В задаче классификации SVM строит гиперплоскость, которая наилучшим образом разделяет объекты разных классов.

**Основные понятия:**

*   **Гиперплоскость:** в n-мерном пространстве гиперплоскость - это подпространство размерности n-1.
*   **Разделяющая гиперплоскость:** гиперплоскость, которая разделяет объекты разных классов.
*   **Опорные векторы:** объекты, которые лежат ближе всего к разделяющей гиперплоскости.
*   **Зазор (Margin):** расстояние от разделяющей гиперплоскости до ближайшего объекта. SVM строит гиперплоскость с максимальным зазором.

**Преимущества SVM:**

*   **Эффективен в пространствах высокой размерности.**
*   **Работает хорошо, даже если количество признаков больше, чем количество объектов.**
*   **Использует только подмножество обучающих данных (опорные векторы), что делает его эффективным с точки зрения памяти.**
*   **Высокая точность классификации.**
*   **Возможность использования различных ядер (kernel trick),** что позволяет строить нелинейные разделяющие поверхности.

**Недостатки SVM:**

*   **Чувствительность к выбору параметров (параметр регуляризации C и параметры ядра).**
*   **Не предоставляет вероятностные оценки принадлежности к классам.**
*   **Долгое время обучения на больших наборах данных.**
*   **Сложность интерпретации модели.**

**Ядра (Kernel Trick):**

Ядра позволяют SVM строить нелинейные разделяющие поверхности путем неявного отображения данных в пространство более высокой размерности.

*   **Линейное ядро:**  $K(x_i, x_j) = x_i^T x_j$
*   **Полиномиальное ядро:** $K(x_i, x_j) = (\gamma x_i^T x_j + r)^d$
*   **Радиально-базисная функция (RBF):** $K(x_i, x_j) = \exp(-\gamma ||x_i - x_j||^2)$
*   **Сигмоидальное ядро:** $K(x_i, x_j) = \tanh(\gamma x_i^T x_j + r)$

**Ссылки:**

*   [Support-vector machine - Wikipedia](https://en.wikipedia.org/wiki/Support-vector_machine)
*   [Understanding Support Vector Machine(SVM) algorithm from examples](https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/)
*   [Support Vector Machines - A Simple Explanation](https://www.youtube.com/watch?v=efR1C6CvhmE)

**27. Метод RVM.**

**RVM (Relevance Vector Machine):** это вероятностный разреженный метод, основанный на ядре, для классификации и регрессии. Он похож на SVM, но вместо опорных векторов использует релевантные векторы. RVM обычно приводит к более разреженным моделям, чем SVM, что означает, что он использует меньше обучающих примеров для построения модели.

**Основные идеи:**

*   **Вероятностная модель:** RVM строит вероятностную модель, которая позволяет оценивать апостериорные вероятности принадлежности объектов к классам.
*   **Разреженность:** RVM использует априорное распределение, которое поощряет разреженность весов, что приводит к тому, что большинство весов становятся равными нулю.
*   **Релевантные векторы:** объекты, соответствующие ненулевым весам, называются релевантными векторами. Они играют ту же роль, что и опорные векторы в SVM.
*   **Автоматическое определение сложности модели:** RVM автоматически определяет количество релевантных векторов, что избавляет от необходимости подбирать параметры модели с помощью кросс-валидации.

**Преимущества RVM:**

*   **Разреженность:** RVM обычно использует меньше релевантных векторов, чем SVM использует опорных векторов, что приводит к более компактным моделям.
*   **Вероятностные оценки:** RVM предоставляет вероятностные оценки принадлежности объектов к классам.
*   **Автоматическое определение сложности модели.**
*   **Меньшая чувствительность к выбору параметров ядра, чем у SVM.**

**Недостатки RVM:**

*   **Вычислительно более затратный, чем SVM,** особенно на этапе обучения.
*   **Сходимость алгоритма обучения не гарантируется.**
*   **Менее изучен, чем SVM.**

**Сравнение с SVM:**

| Признак             | RVM                                  | SVM                                        |
| --------------------- | --------------------------------------- | ------------------------------------------- |
| **Модель**           | Вероятностная                         | Геометрическая                               |
| **Разреженность**    | Высокая                                 | Ниже, чем у RVM                             |
| **Вероятностные оценки** | Да                                     | Нет                                         |
| **Сложность модели**  | Определяется автоматически             | Задается пользователем (параметр регуляризации) |
| **Вычислительная сложность** | Выше                                   | Ниже                                        |

**Ссылки:**

*   [Relevance vector machine - Wikipedia](https://en.wikipedia.org/wiki/Relevance_vector_machine)
*   [The Relevance Vector Machine (RVM)](https://www.microsoft.com/en-us/research/uploads/prod/2006/01/bishop-rvm-nips.pdf)
*   [Relevance Vector Machines Explained](https://www.youtube.com/watch?v=sIM078hhGzk)

**28. Метрические (Similarity-based models) методы классификации.**

**Метрические методы классификации (Similarity-based models):** это методы, которые основываются на вычислении сходства (или расстояния) между объектами. Классификация нового объекта осуществляется на основе его сходства с объектами обучающей выборки.

**Основные принципы:**

*   **Гипотеза компактности:** объекты одного класса расположены близко друг к другу в пространстве признаков.
*   **Меры сходства/расстояния:** используются для определения близости между объектами.
*   **Правило классификации:** новый объект относится к тому классу, к которому он наиболее близок (или к которому относится большинство его ближайших соседей).

**Примеры метрических методов:**

*   **Метод k-ближайших соседей (k-Nearest Neighbors, k-NN):** классифицирует объект на основе большинства среди его k ближайших соседей.
*   **Метод взвешенных k-ближайших соседей (Weighted k-NN):** учитывает расстояние до соседей при голосовании.
*   **Метод потенциальных функций (Potential Function Method):** строит потенциальную функцию, которая достигает максимума в точках, соответствующих объектам обучающей выборки, и убывает по мере удаления от них.
*   **Метод парзеновского окна (Parzen Window):** оценивает плотность распределения каждого класса в точке, где находится новый объект, и относит объект к классу с наибольшей плотностью.

**Преимущества метрических методов:**

*   **Простота реализации.**
*   **Непараметрические методы:** не делают предположений о распределении данных.
*   **Могут работать с данными произвольной природы,** если определена подходящая мера сходства.

**Недостатки метрических методов:**

*   **Высокая вычислительная сложность при большом количестве данных,** так как требуется вычислять расстояния до всех объектов обучающей выборки.
*   **Чувствительность к выбору метрики и параметров (например, k в k-NN).**
*   **Необходимость хранения всей обучающей выборки.**
*   **Проблема "проклятия размерности":** в пространствах высокой размерности расстояния между объектами становятся менее информативными.

**Ссылки:**

*   [Similarity-based classification](https://www.sciencedirect.com/topics/computer-science/similarity-based-classification)
*   [Metric Methods for Classification](https://www.researchgate.net/publication/312975053_Metric_Methods_for_Classification)

**29. **Алгоритм STOLP (Selection by পরস্প (Selection by Training on Ordered কাছের к объектам другого класса.**

**Основные шаги алгоритма STOLP:**

1. **Инициализация:** выбирается начальное множество эталонов, например, случайным образом.
2. **Обучение:** для каждого объекта обучающей выборки определяется его ближайший эталон.
3. **Оценка ошибки:** вычисляется количество ошибок классификации на обучающей выборке с использованием текущего множества эталонов.
4. **Модификация:**
    *   Если объект классифицирован неверно, он добавляется в множество эталонов.
    *   Если объект классифицирован верно, но его ближайший эталон принадлежит другому классу, то этот эталон удаляется из множества.
5. **Повторение:** шаги 2-4 повторяются, пока количество ошибок не стабилизируется или не будет достигнуто максимальное количество итераций.

**Цели применения:**

*   **Сокращение объема хранимых данных:** вместо хранения всей обучающей выборки хранится только подмножество эталонных объектов.
*   **Ускорение процесса классификации:** при классификации нового объекта вычисляются расстояния только до эталонных объектов, а не до всех объектов обучающей выборки.
*   **Улучшение качества классификации:** удаление шумовых объектов и объектов, лежащих на границе классов, может улучшить обобщающую способность классификатора.

**Преимущества STOLP:**

*   **Простота реализации.**
*   **Эффективное сокращение количества эталонов.**
*   **Повышение качества классификации в некоторых случаях.**

**Недостатки STOLP:**

*   **Результат зависит от начального множества эталонов.**
*   **Возможно зацикливание алгоритма.**
*   **Не гарантирует нахождения оптимального множества эталонов.**

**Ссылки:**

*   [Обзор алгоритмов выбора эталонных объектов](https://www.researchgate.net/publication/2844367_Obzor_algoritmov_vybora_etalonnyh_obektov) (на русском)
*   [Отбор эталонов для метрических классификаторов](http://www.machinelearning.ru/wiki/index.php?title=%D0%9E%D1%82%D0%B1%D0%BE%D1%80_%D1%8D%D1%82%D0%B0%D0%BB%D0%BE%D0%BD%D0%BE%D0%B2_%D0%B4%D0%BB%D1%8F_%D0%BC%D0%B5%D1%82%D1%80%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85_%D0%BA%D0%BB%D0%B0%D1%81%D1%81%D0%B8%D1%84%D0%B8%D0%BA%D0%B0%D1%82%D0%BE%D1%80%D0%BE%D0%B2) (на русском)

**30. Алгоритм LOWESS.**

**LOWESS (Locally Weighted Scatterplot Smoothing) или LOESS (Locally Estimated Scatterplot Smoothing):** это непараметрический метод регрессии, который используется для сглаживания данных и построения нелинейных регрессионных моделей. Он основан на идее локального взвешивания наблюдений при построении регрессии в каждой точке.

**Основные шаги алгоритма LOWESS:**

1. **Для каждой точки x, в которой нужно оценить значение функции:**
    *   Определить окрестность точки x, состоящую из k ближайших соседей.
    *   Присвоить веса наблюдениям в окрестности в зависимости от их расстояния до точки x. Чем ближе наблюдение, тем больше его вес.
    *   Построить взвешенную линейную регрессию по наблюдениям в окрестности, используя присвоенные веса.
    *   Оценить значение функции в точке x как значение, предсказанное взвешенной линейной регрессией.

**Параметры LOWESS:**

*   **k (или bandwidth):** количество соседей, используемых для построения локальной регрессии, или ширина окна сглаживания.
*   **Функция весов:** определяет, как вес наблюдения зависит от его расстояния до точки, в которой оценивается функция. Примеры:
    *   **Tricube:** $w(u) = (1 - |u|^3)^3$ для $|u| < 1$, иначе 0.
    *   **Gaussian:** $w(u) = \exp(-u^2/2)$.
*   **Степень полинома:** степень полинома, используемого для построения локальной регрессии (обычно 1 или 2).

**Преимущества LOWESS:**

*   **Непараметрический метод:** не делает предположений о функциональной форме зависимости между переменными.
*   **Гибкость:** может моделировать сложные нелинейные зависимости.
*   **Устойчивость к выбросам:** выбросы оказывают меньшее влияние на оценку функции, чем в обычной линейной регрессии.

**Недостатки LOWESS:**

*   **Вычислительно затратный,** особенно при большом количестве данных.
*   **Сложность интерпретации,** так как не существует единого уравнения, описывающего зависимость между переменными.
*   **Чувствительность к выбору параметров (k и функции весов).**

**Применение LOWESS:**

*   **Сглаживание данных.**
*   **Построение нелинейных регрессионных моделей.**
*   **Визуализация данных.**
*   **Анализ временных рядов.**

**Ссылки:**

*   [Local regression - Wikipedia](https://en.wikipedia.org/wiki/Local_regression)
*   [LOWESS - A Program for Smoothing Scatterplots by Locally Weighted Regression](https://www.jstor.org/stable/2683591)
*   [Locally Weighted Linear Regression - Stanford CS229 Lecture Notes](https://see.stanford.edu/materials/aimlcs229/cs229-notes1.pdf)

**31. Жадный алгоритм построения метрики.**

**Жадный алгоритм построения метрики**- это алгоритм обучения метрики, который итеративно улучшает метрику, добавляя или изменяя признаки, основываясь на жадном критерии. Под "метрикой" в данном случае понимается функция расстояния, которая используется для измерения сходства между объектами.

**Общая схема жадного алгоритма построения метрики:**

1. **Инициализация:** начать с некоторой начальной метрики, например, евклидова расстояния.
2. **Итерации:**
    *   Оценить текущую метрику, используя некоторый критерий качества, например, точность классификации k-NN.
    *   Сгенерировать набор кандидатов на изменение метрики, например, добавить новый признак, изменить вес признака, добавить нелинейное преобразование признака.
    *   Оценить каждого кандидата, используя тот же критерий качества.
    *   Выбрать лучшего кандидата и обновить метрику.
3. **Остановка:** повторять шаг 2, пока не будет достигнуто некоторое условие остановки, например, максимальное количество итераций, отсутствие улучшения качества, достижение заданного качества.

**Примеры жадных алгоритмов построения метрики:**

*   **Large Margin Nearest Neighbor (LMNN):** алгоритм, который обучается таким образом, чтобы k ближайших соседей всегда принадлежали одному классу, а объекты из разных классов были разделены большим зазором.
*   **Information Theoretic Metric Learning (ITML):** алгоритм, который минимизирует дифференциальную относительную энтропию между двумя распределениями, при условии ограничений на попарные расстояния.
*   **Neighborhood Components Analysis (NCA):** алгоритм, который максимизирует стохастический вариант оценки точности leave-one-out (LOO) k-NN на обучающем наборе данных.

**Преимущества жадных алгоритмов:**

*   **Относительно просты в реализации.**
*   **Могут приводить к значительному улучшению качества классификации.**

**Недостатки жадных алгоритмов:**

*   **Не гарантируют нахождения глобально оптимальной метрики.**
*   **Могут переобучаться, особенно при большом количестве признаков.**
*   **Чувствительны к выбору начальной метрики и критерия качества.**

**Ссылки:**

*   [Distance metric learning - Wikipedia](https://en.wikipedia.org/wiki/Distance_metric_learning)
*   [Neighborhood Components Analysis](https://www.cs.toronto.edu/~hinton/absps/nca.pdf)
*   [Distance Metric Learning, with Application to Clustering with Side-Information](https://papers.nips.cc/paper/2002/file/feab05aa91085b7a8012516bc3533958-Paper.pdf)

**32. Типы логических методов классификации.**

**Логические методы классификации** - это методы, которые строят решающие правила в виде логических выражений. Они основаны на предположении, что данные могут быть описаны с помощью набора логических правил, которые разделяют объекты разных классов.

**Типы логических методов классификации:**

1. **Деревья решений (Decision Trees):** строят дерево, в узлах которого находятся логические предикаты, проверяющие значения признаков, а в листьях - метки классов.
    *   **Примеры алгоритмов:** ID3, C4.5, CART.
    *   **Преимущества:**
        *   Простота интерпретации.
        *   Не требуют предобработки данных.
        *   Могут работать как с числовыми, так и с категориальными признаками.
    *   **Недостатки:**
        *   Склонны к переобучению.
        *   Неустойчивы к небольшим изменениям в данных.
        *   Могут строить сложные деревья, которые трудно интерпретировать.

2. **Поиск покрытий (Covering Algorithms):** итеративно строят набор правил, покрывающих объекты одного класса и не покрывающих объекты других классов.
    *   **Примеры алгоритмов:** AQ, CN2, RIPPER.
    *   **Преимущества:**
        *   Создают более компактные модели, чем деревья решений.
        *   Могут работать с неполными данными.
    *   **Недостатки:**
        *   Менее интерпретируемы, чем деревья решений.
        *   Могут быть вычислительно затратными.

3. **Индукция логических программ (Inductive Logic Programming, ILP):** используют методы логического программирования для построения решающих правил в виде логических программ.
    *   **Примеры алгоритмов:** FOIL, Progol.
    *   **Преимущества:**
        *   Могут работать с реляционными данными (данными, описывающими отношения между объектами).
        *   Могут использовать фоновые знания (background knowledge) в процессе обучения.
    *   **Недостатки:**
        *   Вычислительно сложные.
        *   Требуют наличия фоновых знаний.

**Общие преимущества логических методов:**

*   **Интерпретируемость:** решающие правила, построенные логическими методами, легко интерпретируются человеком.
*   **Возможность работы с неполными данными.**

**Общие недостатки логических методов:**

*   **Склонность к переобучению.**
*   **Чувствительность к шуму в данных.**
*   **Не всегда высокая точность классификации по сравнению с другими методами.**

**Ссылки:**

*   [Inductive logic programming - Wikipedia](https://en.wikipedia.org/wiki/Inductive_logic_programming)
*   [Rule-based machine learning - Wikipedia](https://en.wikipedia.org/wiki/Rule-based_machine_learning)

**33. Бустинг.**

**Бустинг (Boosting)** - это ансамблевый метод машинного обучения, который последовательно строит композицию алгоритмов, каждый из которых исправляет ошибки предыдущих. Основная идея бустинга заключается в том, чтобы обучать каждый следующий алгоритм на тех объектах, на которых предыдущие алгоритмы ошибались.

**Основные принципы бустинга:**

*   **Последовательное обучение:** алгоритмы обучаются последовательно, а не независимо друг от друга.
*   **Взвешивание объектов:** объектам обучающей выборки присваиваются веса, которые изменяются на каждой итерации. Объекты, на которых предыдущие алгоритмы ошибались, получают больший вес.
*   **Комбинирование алгоритмов:** предсказания отдельных алгоритмов комбинируются в одно итоговое предсказание, например, путем взвешенного голосования.

**Общая схема алгоритма бустинга:**

1. **Инициализация:** присвоить всем объектам обучающей выборки одинаковые веса.
2. **Итерации:** для каждой итерации t:
    *   Обучить алгоритм $b_t$ на взвешенной обучающей выборке.
    *   Вычислить ошибку алгоритма $b_t$.
    *   Вычислить вес алгоритма $\alpha_t$ на основе его ошибки.
    *   Обновить веса объектов: увеличить веса объектов, на которых алгоритм $b_t$ ошибся, и уменьшить веса объектов, на которых он ошибся.
3. **Комбинирование:** итоговое предсказание получается путем взвешенного голосования алгоритмов $b_1, ..., b_T$ с весами $\alpha_1, ..., \alpha_T$.

**Преимущества бустинга:**

*   **Высокая точность классификации:** бустинг часто показывает более высокую точность, чем отдельные алгоритмы.
*   **Устойчивость к переобучению:** при правильной настройке параметров бустинг менее склонен к переобучению, чем отдельные алгоритмы.
*   **Возможность работы с различными типами данных.**

**Недостатки бустинга:**

*   **Вычислительно затратный,** особенно при большом количестве итераций.
*   **Чувствительность к шуму в данных:** шумовые объекты могут получать большие веса и негативно влиять на обучение.
*   **Сложность интерпретации,** так как итоговая модель представляет собой композицию множества алгоритмов.

**Примеры алгоритмов бустинга:**

*   **AdaBoost (Adaptive Boosting)**
*   **Gradient Boosting**
*   **XGBoost (Extreme Gradient Boosting)**
*   **LightGBM (Light Gradient Boosting Machine)**
*   **CatBoost (Categorical Boosting)**

**Ссылки:**

*   [Boosting (machine learning) - Wikipedia](https://en.wikipedia.org/wiki/Boosting_(machine_learning))
*   [A Gentle Introduction to the Gradient Boosting Algorithm for Machine Learning](https://machinelearningmastery.com/gentle-introduction-gradient-boosting-algorithm-machine-learning/)
*   [Boosting - MIT](https://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec10.pdf)

**34. Градиентный бустинг.**

**Градиентный бустинг (Gradient Boosting)** - это метод машинного обучения, который строит ансамбль моделей путем последовательной минимизации функции потерь с помощью градиентного спуска.

**Основные идеи:**

*   **Функция потерь:** определяет, насколько хорошо модель предсказывает целевую переменную.
*   **Градиент:** вектор, указывающий направление наискорейшего роста функции потерь.
*   **Последовательное добавление моделей:** на каждой итерации добавляется новая модель, которая аппроксимирует отрицательный градиент функции потерь, вычисленный по предсказаниям предыдущих моделей.
*   **Линейная комбинация моделей:** итоговое предсказание получается как линейная комбинация предсказаний отдельных моделей.

**Алгоритм градиентного бустинга:**

1. **Инициализация:** инициализировать константным значением $F_0(x) = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, \gamma)$, где L - функция потерь.
2. **Итерации:** для каждой итерации $m = 1, ..., M$:
    *   Вычислить отрицательный градиент функции потерь (псевдо-остатки):
    $r_{im} = -\left[\frac{\partial L(y_i, F(x_i))}{\partial F(x_i)}\right]_{F(x)=F_{m-1}(x)}$ для всех $i = 1, ..., n$.
    *   Обучить базовый алгоритм (например, дерево решений) $h_m(x)$ на псевдо-остатках $r_{im}$.
    *   Найти оптимальный вес $\gamma_m$ для базового алгоритма, решив задачу одномерной оптимизации:
    $\gamma_m = \arg\min_{\gamma} \sum_{i=1}^{n} L(y_i, F_{m-1}(x_i) + \gamma h_m(x_i))$.
    *   Обновить ансамбль: $F_m(x) = F_{m-1}(x) + \gamma_m h_m(x)$.
3. **Результат:** $F_M(x)$ - итоговая модель.

**Преимущества градиентного бустинга:**

*   **Высокая точность предсказания.**
*   **Гибкость:** возможность использовать различные функции потерь и базовые алгоритмы.
*   **Устойчивость к переобучению** при правильной настройке параметров.
*   **Обрабатывает пропущенные значения** в данных.

**Недостатки градиентного бустинга:**

*   **Вычислительно затратный** при большом количестве итераций и деревьев большой глубины.
*   **Сложнее в настройке**, чем, например, случайный лес.
*   **Сложность интерпретации** итоговой модели.
*   **Чувствителен к масштабированию признаков.**

**Ссылки:**

*   [Gradient boosting - Wikipedia](https://en.wikipedia.org/wiki/Gradient_boosting)
*   [Greedy Function Approximation: A Gradient Boosting Machine](https://statweb.stanford.edu/~jhf/ftp/trebst.pdf)
*   [Gradient Boosting explained - YouTube](https://www.youtube.com/watch?v=sRktKcD7 மாறு_8)

**35. Частные случаи градиентного бустинга.**

**Частные случаи градиентного бустинга** - это реализации алгоритма градиентного бустинга, которые отличаются выбором базового алгоритма, функции потерь, способа оптимизации и другими особенностями.

**Наиболее популярные реализации:**

1. **XGBoost (Extreme Gradient Boosting):**
    *   **Базовый алгоритм:** деревья решений.
    *   **Особенности:**
        *   Регуляризация (L1 и L2), чтобы избежать переобучения.
        *   Параллельная обработка деревьев.
        *   Обработка разреженных данных.
        *   Встроенная обработка пропущенных значений.
        *   Высокая производительность и эффективность.
    *   [XGBoost Documentation](https://xgboost.readthedocs.io/en/latest/)

2. **LightGBM (Light Gradient Boosting Machine):**
    *   **Базовый алгоритм:** деревья решений.
    *   **Особенности:**
        *   Градиентное одностороннее сэмплирование (Gradient-based One-Side Sampling, GOSS) для ускорения обучения.
        *   Эксклюзивное связывание признаков (Exclusive Feature Bundling, EFB) для обработки разреженных данных.
        *   Построение деревьев по листьям (leaf-wise), а не по уровням (level-wise), что позволяет строить более глубокие деревья.
        *   Очень высокая производительность, особенно на больших наборах данных.
    *   [LightGBM Documentation](https://lightgbm.readthedocs.io/en/latest/)

3. **CatBoost (Categorical Boosting):**
    *   **Базовый алгоритм:** деревья решений.
    *   **Особенности:**
        *   Специальная обработка категориальных признаков без необходимости их предварительного кодирования.
        *   Упорядоченный бустинг (Ordered Boosting) для борьбы с переобучением.
        *   Быстрый и эффективный алгоритм обучения.
        *   Встроенная визуализация процесса обучения.
    *   [CatBoost Documentation](https://catboost.ai/docs/)

4. **AdaBoost (Adaptive Boosting):**
    *   **Базовый алгоритм:** пни (stumps) - деревья решений глубины 1.
    *   **Особенности:**
        *   Веса объектов обновляются на каждой итерации в зависимости от ошибок предыдущих алгоритмов.
        *   Простая реализация.
        *   Исторически первый алгоритм бустинга.
    *   [AdaBoost - Wikipedia](https://en.wikipedia.org/wiki/AdaBoost)

**Другие реализации:**

*   **Gradient Tree Boosting:** классическая реализация градиентного бустинга с деревьями решений в качестве базовых алгоритмов.
*   **Stochastic Gradient Boosting:** на каждой итерации используется случайная подвыборка обучающих данных.
*   **LogitBoost:** градиентный бустинг с логистической функцией потерь.

**Выбор реализации зависит от:**

*   **Размера и типа данных.**
*   **Требований к производительности.**
*   **Необходимости обработки категориальных признаков.**
*   **Желаемой точности предсказания.**

**36. Бустинг над решающими деревьями.**

**Бустинг над решающими деревьями (Boosting over Decision Trees)** - это частный случай градиентного бустинга, в котором в качестве базовых алгоритмов используются деревья решений. Это наиболее распространенный вариант бустинга, так как деревья решений обладают рядом преимуществ:

*   **Не требуют масштабирования признаков.**
*   **Могут моделировать нелинейные зависимости.**
*   **Обрабатывают как числовые, так и категориальные признаки.**
*   **Относительно просты в интерпретации (особенно деревья небольшой глубины).**

**Особенности бустинга над решающими деревьями:**

*   **Глубина деревьев:** обычно используются неглубокие деревья (например, с глубиной от 3 до 8), чтобы избежать переобучения.
*   **Количество деревьев:** количество деревьев (итераций бустинга) определяет сложность модели. Чем больше деревьев, тем сложнее модель и тем выше риск переобучения.
*   **Скорость обучения (learning rate):** параметр, контролирующий вклад каждого дерева в итоговую модель. Меньшая скорость обучения обычно требует большего количества деревьев, но приводит к более устойчивым моделям.
*   **Регуляризация:** используются различные методы регуляризации, такие как ограничение глубины деревьев, минимальное количество объектов в листе, L1 и L2 регуляризация, чтобы избежать переобучения.

**Преимущества бустинга над решающими деревьями:**

*   **Высокая точность предсказания:** часто превосходит другие методы машинного обучения, особенно на табличных данных.
*   **Обработка различных типов данных:** могут работать как с числовыми, так и с категориальными признаками.
*   **Устойчивость к выбросам:** благодаря использованию неглубоких деревьев и регуляризации.

**Недостатки бустинга над решающими деревьями:**

*   **Вычислительно затратный** при большом количестве деревьев.
*   **Сложность настройки параметров.**
*   **Сложность интерпретации** итоговой модели, представляющей собой композицию множества деревьев.

**Популярные реализации:**

*   **XGBoost**
*   **LightGBM**
*   **CatBoost**
*   **Gradient Tree Boosting в scikit-learn**

**Ссылки:**

*   [Gradient Tree Boosting - scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#gradient-tree-boosting)
*   [Boosting and Additive Trees - Stanford](https://statweb.stanford.edu/~tibs/stat315a/LECTURES/em.pdf)

**37. Случайный лес.**

**Случайный лес (Random Forest)** - это ансамблевый метод машинного обучения, который строит множество решающих деревьев и объединяет их предсказания для получения более точного и устойчивого результата.

**Основные идеи:**

*   **Бэггинг (Bagging):** каждое дерево обучается на случайной подвыборке обучающих данных, сэмплированной с возвращением (bootstrap sample).
*   **Метод случайных подпространств (Random Subspace Method):** при построении каждого узла дерева рассматривается не все множество признаков, а только случайное подмножество.
*   **Агрегирование предсказаний:** предсказания отдельных деревьев объединяются путем усреднения (для задачи регрессии) или голосования (для задачи классификации).

**Алгоритм построения случайного леса:**

1. **Для каждого дерева:**
    *   Сгенерировать случайную подвыборку обучающих данных с возвращением.
    *   Построить решающее дерево, используя случайную подвыборку. При построении каждого узла дерева:
        *   Выбрать случайное подмножество признаков.
        *   Выбрать лучший признак и лучшее разбиение по нему, используя критерий информативности (например, энтропию или индекс Джини).
2. **Объединить предсказания отдельных деревьев:**
    *   **Классификация:** выбрать класс, за который проголосовало большинство деревьев.
    *   **Регрессия:** усреднить предсказания отдельных деревьев.

**Параметры случайного леса:**

*   **Количество деревьев:** чем больше деревьев, тем лучше обобщающая способность модели, но и выше вычислительные затраты.
*   **Размер случайной подвыборки:** обычно используется подвыборка размером, равным размеру исходной обучающей выборки.
*   **Количество случайных признаков:** обычно используется $\sqrt{p}$ для классификации и $p/3$ для регрессии, где $p$ - количество признаков.
*   **Максимальная глубина деревьев:** ограничение глубины деревьев позволяет избежать переобучения.
*   **Минимальное количество объектов в листе:** еще один способ регуляризации.

**Преимущества случайного леса:**

*   **Высокая точность предсказания.**
*   **Устойчивость к переобучению.**
*   **Способность обрабатывать данные с большим количеством признаков.**
*   **Обрабатывает пропущенные значения**
*   **Оценка важности признаков.**
*   **Параллелизуемость**

**Недостатки случайного леса:**

*   **Вычислительно затратный** при большом количестве деревьев и большой глубине.
*   **Сложность интерпретации** итоговой модели.
*   **Большой размер модели**
*   **Может быть неэффективным на данных с большим количеством неинформативных признаков**

**Ссылки:**

*   [Random forest - Wikipedia](https://en.wikipedia.org/wiki/Random_forest)
*   [Random Forests - scikit-learn](https://scikit-learn.org/stable/modules/ensemble.html#random-forests)
*   [Understanding Random Forests - Towards Data Science](https://towardsdatascience.com/understanding-random-forests-58381e0602d2)

**38. Метрики качества классификации.**

**Метрики качества классификации** используются для оценки производительности алгоритмов классификации. Они показывают, насколько хорошо модель умеет относить объекты к правильным классам.

**Основные метрики:**

*   **Accuracy (доля правильных ответов):** доля объектов, для которых модель предсказала правильный класс.
    $$Accuracy = \frac{TP + TN}{TP + TN + FP + FN}$$
    *   **Простая и интуитивно понятная метрика.**
    *   **Не подходит для несбалансированных классов** (когда объектов одного класса намного больше, чем другого).

*   **Precision (точность):** доля объектов, которые действительно принадлежат к данному классу, среди всех объектов, которые модель отнесла к этому классу.
    $$Precision = \frac{TP}{TP + FP}$$
    *   **Показывает, насколько можно доверять модели, когда она относит объект к определенному классу.**

*   **Recall (полнота):** доля объектов данного класса, которые модель смогла обнаружить.
    $$Recall = \frac{TP}{TP + FN}$$
    *   **Показывает, насколько хорошо модель находит объекты определенного класса.**

*   **F1-score (F-мера):** среднее гармоническое точности и полноты.
    $$F1 = 2 \cdot \frac{Precision \cdot Recall}{Precision + Recall}$$
    *   **Сбалансированная метрика, учитывающая и точность, и полноту.**
    *   **Подходит для несбалансированных классов.**

*   **ROC-AUC (Area Under the ROC Curve):** площадь под ROC-кривой, которая показывает зависимость доли истинно положительных примеров (TPR) от доли ложно положительных примеров (FPR) при различных порогах классификации.
    *   **Показывает качество работы алгоритма независимо от выбранного порога.**
    *   **Чем ближе ROC-AUC к 1, тем лучше качество классификации.**

*   **PR-AUC (Area Under the Precision-Recall Curve):** площадь под PR-кривой, которая показывает зависимость точности от полноты при различных порогах классификации.
    *   **Полезна для несбалансированных классов, когда важнее минимизировать количество ложноположительных срабатываний, чем ложноотрицательных.**

*   **Log Loss (логарифмическая функция потерь):** измеряет среднее значение логарифма вероятности правильного класса, предсказанной моделью.
    *   **Чем меньше значение Log Loss, тем лучше.**
    *   **Чувствительна к уверенности модели в своих предсказаниях.**

**Термины:**

*   **TP (True Positive):** истинно положительный результат - модель правильно отнесла объект к положительному классу.
*   **TN (True Negative):** истинно отрицательный результат - модель правильно отнесла объект к отрицательному классу.
*   **FP (False Positive):** ложно положительный результат - модель неправильно отнесла объект к положительному классу (ошибка I рода).
*   **FN (False Negative):** ложно отрицательный результат - модель неправильно отнесла объект к отрицательному классу (ошибка II рода).

**Выбор метрики зависит от:**

*   **Задачи классификации:** что важнее - точность или полнота, минимизация ложноположительных или ложноотрицательных срабатываний.
*   **Сбалансированности классов:** для несбалансированных классов лучше подходят F1-score, PR-AUC, ROC-AUC.

**Ссылки:**

*   [Evaluation metrics for classification - Wikipedia](https://en.wikipedia.org/wiki/Evaluation_of_binary_classifiers)
*   [Classification: Precision and Recall - Google Developers](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall)
*   [Accuracy, Precision, Recall or F1? - Towards Data Science](https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9)

**39. Байесовская классификация. Наивный байесовский классификатор.**

**Байесовская классификация** - это вероятностный подход к классификации, основанный на теореме Байеса. Он оценивает апостериорную вероятность принадлежности объекта к каждому классу и относит объект к классу с наибольшей вероятностью.

**Теорема Байеса:**

$$P(C_k|x) = \frac{P(x|C_k)P(C_k)}{P(x)},$$

где:

*   $P(C_k|x)$ - апостериорная вероятность принадлежности объекта $x$ к классу $C_k$.
*   $P(x|C_k)$ - функция правдоподобия, вероятность наблюдать объект $x$ при условии, что он принадлежит классу $C_k$.
*   $P(C_k)$ - априорная вероятность класса $C_k$.
*   $P(x)$ - полная вероятность, вычисляется как $\sum_{k=1}^{K} P(x|C_k)P(C_k)$.

**Наивный байесовский классификатор (Naive Bayes Classifier):** это упрощенная версия байесовского классификатора, которая предполагает, что признаки объекта статистически независимы друг от друга при условии принадлежности к классу.

**Формула для наивного байесовского классификатора:**

$$P(C_k|x) = \frac{P(C_k) \prod_{i=1}^{n} P(x_i|C_k)}{P(x)},$$

где:

*   $x = (x_1, ..., x_n)$ - вектор признаков объекта.
*   $P(x_i|C_k)$ - вероятность наблюдать значение признака $x_i$ при условии, что объект принадлежит классу $C_k$.

**Преимущества наивного байесовского классификатора:**

*   **Простота реализации.**
*   **Высокая скорость обучения и классификации.**
*   **Хорошо работает на небольших наборах данных.**
*   **Нечувствителен к нерелевантным признакам.**
*   **Может обрабатывать пропущенные значения**

**Недостатки наивного байесовского классификатора:**

*   **Предположение о независимости признаков** часто не выполняется на практике, что может приводить к снижению точности.
*   **Чувствителен к способу оценки вероятностей** $P(x_i|C_k)$, особенно при малом количестве данных.

**Типы наивного байесовского классификатора:**

*   **Multinomial Naive Bayes:** используется для дискретных признаков, например, для классификации текстов.
*   **Bernoulli Naive Bayes:** используется для бинарных признаков.
*   **Gaussian Naive Bayes:** используется для непрерывных признаков, предполагается, что признаки в каждом классе имеют нормальное распределение.

**Применение наивного байесовского классификатора:**

*   **Фильтрация спама.**
*   **Классификация текстов.**
*   **Медицинская диагностика.**
*   **Распознавание образов.**

**Ссылки:**

*   [Naive Bayes classifier - Wikipedia](https://en.wikipedia.org/wiki/Naive_Bayes_classifier)
*   [Naive Bayes Classifier - Towards Data Science](https://towardsdatascience.com/naive-bayes-classifier-81d512f50a7c)
*   [6 Easy Steps to Learn Naive Bayes Algorithm - Analytics Vidhya](https://www.analyticsvidhya.com/blog/2017/09/naive-bayes-explained/)

**40. Сеть радиальных базисных функций (RBF) и применение EM-алгоритма для её настройки.**

**Сеть радиальных базисных функций (Radial Basis Function Network, RBF Network)** - это тип искусственной нейронной сети, которая использует радиальные базисные функции в качестве функций активации скрытых нейронов.

**Структура RBF сети:**

*   **Входной слой:** принимает входные данные.
*   **Скрытый слой:** состоит из нейронов с радиальными базисными функциями активации.
*   **Выходной слой:** обычно состоит из линейных нейронов, которые комбинируют выходы скрытого слоя.

**Радиальная базисная функция (RBF):** это функция, значение которой зависит от расстояния до некоторого центра. Наиболее распространенная RBF - гауссова функция:

$$\phi(x) = \exp(-\frac{||x - c||^2}{2\sigma^2}),$$

где:

*   $x$ - входной вектор.
*   $c$ - центр RBF.
*   $\sigma$ - ширина RBF.

**Обучение RBF сети:**

Обучение RBF сети включает в себя настройку следующих параметров:

*   **Количество скрытых нейронов (RBF).**
*   **Центры RBF.**
*   **Ширины RBF.**
*   **Веса выходного слоя.**

**Методы обучения RBF сети:**

*   **Метод случайного выбора центров:** центры RBF выбираются случайным образом из обучающих данных.
*   **Кластеризация:** центры RBF определяются с помощью алгоритмов кластеризации, таких как k-средних.
*   **Градиентный спуск:** параметры RBF сети настраиваются с помощью градиентного спуска.
*   **EM-алгоритм:** итеративный алгоритм, который может использоваться для настройки центров и ширин RBF.

**Применение EM-алгоритма для настройки RBF сети:**

EM-алгоритм рассматривает RBF сеть как вероятностную модель со скрытыми переменными, где скрытые переменные - это принадлежность входных данных к RBF.

**Шаги EM-алгоритма:**

1. **Инициализация:** инициализировать центры и ширины RBF, а также веса выходного слоя.
2. **E-шаг (Expectation):** вычислить апостериорную вероятность принадлежности каждого входного объекта к каждой RBF, используя текущие значения параметров.
3. **M-шаг (Maximization):** обновить параметры RBF сети (центры, ширины и веса выходного слоя), максимизируя ожидаемое значение логарифма правдоподобия, вычисленное на E-шаге.
4. **Повторять E-шаг и M-шаг** до сходимости.

**Преимущества RBF сетей:**

*   **Быстрое обучение** по сравнению с многослойными перцептронами.
*   **Хорошая аппроксимирующая способность.**
*   **Устойчивость к шуму.**

**Недостатки RBF сетей:**

*   **Чувствительность к выбору количества скрытых нейронов.**
*   **Проблема "проклятия размерности"**: при большом количестве входных признаков требуется экспоненциально большое количество RBF для покрытия всего входного пространства.
*   **Сложность интерпретации**

**Ссылки:**

*   [Radial basis function network - Wikipedia](https://en.wikipedia.org/wiki/Radial_basis_function_network)
*   [Radial Basis Function (RBF) Networks - Towards Data Science](https://towardsdatascience.com/radial-basis-function-rbf-networks-559757957825)
*   [Training RBF Networks with EM - YouTube](https://www.youtube.com/watch?v=d9FaNF-f49E)

**41. Сравнение RBF-сети и SVM с гауссовским ядром.**

**RBF-сеть (Radial Basis Function Network) и SVM (Support Vector Machine) с гауссовским ядром** - это два тесно связанных метода машинного обучения, которые могут использоваться для решения задач классификации и регрессии. Оба метода используют идею отображения данных в пространство более высокой размерности с помощью ядерных функций, что позволяет строить нелинейные модели.

**Сходства:**

*   **Нелинейные модели:** оба метода могут моделировать нелинейные зависимости между признаками и целевой переменной.
*   **Ядерные функции:** оба метода используют ядерные функции для отображения данных в пространство более высокой размерности. Гауссовское ядро (RBF) является одним из наиболее популярных ядер для SVM и тесно связано с радиальными базисными функциями в RBF-сетях.
*   **Универсальные аппроксиматоры:** при достаточном количестве скрытых нейронов/опорных векторов оба метода могут аппроксимировать любую непрерывную функцию с произвольной точностью.

**Различия:**

| Признак | RBF-сеть | SVM с гауссовским ядром |
|---|---|---|
| **Тип модели** | Нейронная сеть | Метод опорных векторов |
| **Обучение** | Обычно обучается в два этапа: 1) определение центров и ширин RBF; 2) настройка весов выходного слоя. Может использоваться EM-алгоритм. | Обучается путем решения задачи квадратичного программирования. |
| **Скрытый слой** | Состоит из нейронов с радиальными базисными функциями активации. | Явно не присутствует, но неявное отображение в пространство высокой размерности осуществляется с помощью ядерной функции. |
| **Выходной слой** | Обычно линейный | Знак взвешенной суммы опорных векторов |
| **Разреженность** | Количество RBF обычно меньше, чем количество обучающих данных, но больше, чем количество опорных векторов в SVM. | Решение разреженное, то есть зависит только от опорных векторов. |
| **Вероятностный выход** | Может быть модифицирована для получения вероятностного выхода. | Стандартная SVM не выдает вероятностный выход, но существуют расширения, такие как Platt scaling. |
| **Чувствительность к параметрам** | Чувствительна к выбору количества скрытых нейронов, центров и ширин RBF. | Чувствительна к выбору параметра регуляризации C и параметра ширины гауссовского ядра. |
| **Вычислительная сложность** | Обучение обычно быстрее, чем SVM. | Обучение может быть медленным для больших наборов данных. |

**Когда использовать RBF-сеть:**

*   Когда требуется быстрое обучение.
*   Когда важна устойчивость к шуму.
*   Когда данных не очень много (иначе становится неэффективно)

**Когда использовать SVM с гауссовским ядром:**

*   Когда требуется высокая точность классификации.
*   Когда важна разреженность решения (меньше опорных векторов).
*   Когда данных относительно много (но не слишком много, иначе обучение может быть медленным)

**В целом, SVM с гауссовским ядром чаще используется на практике, чем RBF-сети, благодаря своей эффективности, разреженности решения и наличию хорошо развитых программных библиотек.**

**Ссылки:**

*   [Support Vector Machines vs. RBF Networks - Stack Overflow](https://stackoverflow.com/questions/14578679/support-vector-machines-vs-rbf-networks)
*   [RBF Network vs. SVM for Classification - ResearchGate](https://www.researchgate.net/post/RBF_Network_vs_SVM_for_Classification)

**42. Нейронные сети и алгоритмы их обучения. Теоретические основы. Модель нейронной сети.**

**Нейронные сети (Artificial Neural Networks, ANN)** - это вычислительные модели, вдохновленные биологическими нейронными сетями, которые способны обучаться на данных и решать сложные задачи, такие как классификация, регрессия, распознавание образов и обработка естественного языка.

**Теоретические основы:**

*   **Нейрон:** основной строительный блок нейронной сети. Он принимает входные сигналы, взвешивает их, суммирует и передает результат через функцию активации.
*   **Синапс:** связь между нейронами, характеризующаяся весом, который определяет силу связи.
*   **Функция активации:** нелинейная функция, которая вносит нелинейность в модель и позволяет нейронной сети аппроксимировать сложные зависимости. Примеры: сигмоида, гиперболический тангенс, ReLU.
*   **Слой:** группа нейронов, расположенных на одном уровне.
*   **Архитектура:** структура нейронной сети, определяющая количество слоев, количество нейронов в каждом слое и способ соединения нейронов между собой.
*   **Прямое распространение (Forward Propagation):** процесс вычисления выходных значений нейронной сети по заданным входным данным.
*   **Функция потерь:** функция, которая измеряет ошибку между предсказанными и фактическими значениями.
*   **Обратное распространение ошибки (Backpropagation):** алгоритм вычисления градиента функции потерь по весам нейронной сети, используемый для настройки весов.
*   **Обучение:** процесс настройки весов нейронной сети с целью минимизации функции потерь на обучающих данных.

**Модель нейронной сети:**

Математически, нейронную сеть можно представить как функцию $f(x, W)$, где:

*   $x$ - входной вектор.
*   $W$ - матрица весов нейронной сети.
*   $f$ - функция, определяемая архитектурой сети и функциями активации нейронов.

**Алгоритмы обучения нейронных сетей:**

*   **Градиентный спуск (Gradient Descent):** итеративный алгоритм оптимизации, который обновляет веса нейронной сети в направлении, противоположном градиенту функции потерь.
    *   **Стохастический градиентный спуск (Stochastic Gradient Descent, SGD):** обновляет веса после каждого объекта.
    *   **Пакетный градиентный спуск (Batch Gradient Descent):** обновляет веса после обработки всего набора данных.
    *   **Мини-пакетный градиентный спуск (Mini-batch Gradient Descent):** обновляет веса после обработки небольшой части данных (мини-пакета).
*   **Алгоритмы, основанные на градиентном спуске:**
    *   **Momentum:** добавляет инерцию к обновлению весов, что позволяет ускорить сходимость и преодолевать локальные минимумы.
    *   **Nesterov Accelerated Gradient (NAG):** модификация Momentum, которая сначала делает шаг в направлении инерции, а затем вычисляет градиент.
    *   **Adagrad:** адаптирует скорость обучения для каждого веса в зависимости от истории градиентов.
    *   **RMSprop:** модификация Adagrad, которая использует экспоненциально затухающее среднее квадратов градиентов.
    *   **Adam:** комбинация Momentum и RMSprop.
    *   **Nadam:** комбинация NAG и Adam.
*   **Другие алгоритмы:**
    *   **Метод сопряженных градиентов (Conjugate Gradient).**
    *   **Метод Левенберга-Марквардта (Levenberg-Marquardt).**
    *   **Генетические алгоритмы.**

**Ссылки:**

*   [Neural network - Wikipedia](https://en.wikipedia.org/wiki/Artificial_neural_network)
*   [But what is a Neural Network? - 3Blue1Brown](https://www.youtube.com/watch?v=aircAruvnKk)
*   [Neural Networks and Deep Learning - Michael Nielsen](http://neuralnetworksanddeeplearning.com/index.html)

**43. Обучение на основе коррекции ошибок.**

**Обучение на основе коррекции ошибок (Error Correction Learning)** - это общий принцип обучения нейронных сетей, при котором веса сети корректируются пропорционально ошибке, допущенной на выходном слое. Этот принцип лежит в основе многих алгоритмов обучения, включая:

*   **Правило Хебба (Hebbian Learning):** "Нейроны, которые срабатывают вместе, связываются вместе". Вес связи между двумя нейронами увеличивается, если они оба активны одновременно.
*   **Дельта-правило (Delta Rule):**  веса обновляются пропорционально разнице между желаемым выходом и фактическим выходом нейрона. Это правило является основой для алгоритма обратного распространения ошибки.
*   **Метод коррекции ошибки (Error-Correction Rule):** обобщение дельта-правила, которое учитывает производную функции активации.

**Формула для обновления весов при использовании дельта-правила:**

$$\Delta w_{ij} = \eta (t_j - y_j) x_i,$$

где:

*   $\Delta w_{ij}$ - изменение веса связи между нейроном $i$ и нейроном $j$.
*   $\eta$ - скорость обучения (learning rate).
*   $t_j$ - желаемый выход нейрона $j$.
*   $y_j$ - фактический выход нейрона $j$.
*   $x_i$ - входной сигнал от нейрона $i$.

**Алгоритм обратного распространения ошибки (Backpropagation):**

Обратное распространение ошибки является наиболее распространенным алгоритмом обучения многослойных нейронных сетей. Он основан на дельта-правиле и использует градиентный спуск для минимизации функции потерь.

**Основные шаги алгоритма обратного распространения ошибки:**

1. **Прямое распространение:** вычислить выходные значения нейронной сети для заданного входного вектора.
2. **Вычисление ошибки:** вычислить ошибку между предсказанными и фактическими значениями на выходном слое.
3. **Обратное распространение ошибки:** вычислить градиент функции потерь по весам сети, распространяя ошибку от выходного слоя к входному.
4. **Обновление весов:** обновить веса сети в направлении, противоположном градиенту, используя дельта-правило или его модификации.
5. **Повторять шаги 1-4** для всех объектов обучающей выборки или до достижения критерия остановки.

**Преимущества обучения на основе коррекции ошибок:**

*   **Эффективность:** позволяет обучать сложные нейронные сети с большим количеством слоев и нейронов.
*   **Универсальность:** может использоваться для обучения различных архитектур нейронных сетей.

**Недостатки обучения на основе коррекции ошибок:**

*   **Вычислительно затратный** для больших сетей и наборов данных.
*   **Проблема локальных минимумов:** градиентный спуск может застревать в локальных минимумах функции потерь.
*   **Чувствительность к выбору скорости обучения.**

**Ссылки:**

*   [Backpropagation - Wikipedia](https://en.wikipedia.org/wiki/Backpropagation)
*   [Backpropagation - Neural Networks and Deep Learning](http://neuralnetworksanddeeplearning.com/chap2.html)
*   [Neural Networks - Error Correction Learning](https://www.youtube.com/watch?v=x_EamfO-4Lk)

**44. Понятие нейронной сети. Синапсы. Функция активации.**

**Нейронная сеть (Artificial Neural Network, ANN)** - это вычислительная модель, вдохновленная структурой и функционированием биологических нейронных сетей. Она состоит из взаимосвязанных узлов, называемых **нейронами**, которые обрабатывают и передают информацию.

**Основные компоненты нейронной сети:**

*   **Нейрон:** искусственный нейрон является упрощенной моделью биологического нейрона. Он принимает входные сигналы, взвешивает их, суммирует и передает результат через функцию активации.
    *   **Входы:** каждый нейрон имеет несколько входов, которые получают сигналы от других нейронов или извне.
    *   **Веса (синаптические веса):** каждому входу нейрона соответствует вес, который определяет силу влияния этого входа на выход нейрона.
    *   **Сумматор:** суммирует взвешенные входные сигналы.
    *   **Функция активации:** нелинейная функция, которая применяется к сумме взвешенных входов и определяет выход нейрона.

*   **Синапс:** в контексте искусственных нейронных сетей синапс представляет собой связь между двумя нейронами, характеризующуюся весом. Вес синапса определяет, насколько сильно выход одного нейрона влияет на вход другого нейрона. **Синапсы - это, по сути, веса связей между нейронами.**

*   **Функция активации:** нелинейная функция, которая вносит нелинейность в модель нейронной сети и позволяет ей аппроксимировать сложные зависимости. Функции активации определяют выход нейрона на основе взвешенной суммы его входов.

**Распространенные функции активации:**

*   **Сигмоида (Sigmoid):**
    $$\sigma(z) = \frac{1}{1 + e^{-z}}$$
    *   Выходные значения в диапазоне от 0 до 1.
    *   Часто используется в выходном слое для задач бинарной классификации.

*   **Гиперболический тангенс (Tanh):**
    $$tanh(z) = \frac{e^z - e^{-z}}{e^z + e^{-z}}$$
    *   Выходные значения в диапазоне от -1 до 1.
    *   Часто используется в скрытых слоях.

*   **ReLU (Rectified Linear Unit):**
    $$ReLU(z) = max(0, z)$$
    *   Простая и эффективная функция активации.
    *   Часто используется в скрытых слоях.

*   **Leaky ReLU:**
    $$LeakyReLU(z) = max(\alpha z, z), \text{ где } \alpha \text{ - небольшой коэффициент, например, 0.01}$$
    *   Решает проблему "мертвых нейронов", которая может возникать при использовании ReLU.

*   **Softmax:**
    $$Softmax(z)_i = \frac{e^{z_i}}{\sum_{j=1}^{K} e^{z_j}}$$
    *   Преобразует вектор значений в вектор вероятностей.
    *   Часто используется в выходном слое для задач многоклассовой классификации.

**Роль функции активации:**

*   **Вносит нелинейность:** без нелинейных функций активации нейронная сеть была бы эквивалентна линейной модели.
*   **Определяет выход нейрона:** функция активации определяет, какой сигнал нейрон будет передавать дальше.
*   **Помогает нейронной сети обучаться:** нелинейные функции активации позволяют использовать градиентные методы обучения, такие как обратное распространение ошибки.

**Ссылки:**

*   [Artificial neural network - Wikipedia](https://en.wikipedia.org/wiki/Artificial_neural_network)
*   [Activation function - Wikipedia](https://en.wikipedia.org/wiki/Activation_function)
**Neural Networks - Function Approximation and Activation Functions**

*   [Neural Networks - A Simple Explanation](https://www.youtube.com/watch?v=gcK_l-d0-Yc)

**45. Нейронные сети с прямым распространением сигнала.**

**Нейронные сети с прямым распространением сигнала (Feedforward Neural Networks)** - это наиболее распространенный тип нейронных сетей, в которых информация передается строго в одном направлении: от входного слоя через скрытые слои (если они есть) к выходному слою. В таких сетях нет обратных связей, то есть выходные сигналы нейронов не подаются на вход нейронов из предыдущих слоев.

**Основные характеристики:**

*   **Однонаправленная передача сигнала:** информация движется только в одном направлении - от входа к выходу.
*   **Отсутствие циклов:** в сети нет циклов, то есть нейроны не могут передавать сигналы сами себе или нейронам из предыдущих слоев.
*   **Слоистая структура:** нейроны организованы в слои, причем каждый слой связан только с соседними слоями.

**Архитектура:**

*   **Входной слой:** получает входные данные и передает их на следующий слой.
*   **Скрытые слои:** промежуточные слои между входным и выходным слоями. Количество скрытых слоев и количество нейронов в них определяют сложность сети.
*   **Выходной слой:** генерирует выходные значения сети.

**Типы нейронных сетей с прямым распространением:**

*   **Однослойный перцептрон:** простейшая нейронная сеть с прямым распространением, состоящая из одного слоя нейронов, выполняющих взвешенное суммирование входов и применяющих пороговую функцию активации. Может решать только задачи, разделимые гиперплоскостью.
*   **Многослойный перцептрон (Multilayer Perceptron, MLP):** сеть с одним или несколькими скрытыми слоями, использующая нелинейные функции активации. Способен аппроксимировать сложные нелинейные зависимости.

**Применение:**

*   **Классификация:** отнесение объектов к определенным категориям.
*   **Регрессия:** предсказание числового значения.
*   **Распознавание образов:** идентификация объектов на изображениях, видео или в аудиозаписях.
*   **Аппроксимация функций:** моделирование сложных зависимостей между переменными.

**Преимущества:**

*   **Простота реализации.**
*   **Универсальность:** могут использоваться для решения широкого круга задач.
*   **Способность к обучению:** могут обучаться на данных и обобщать полученные знания на новые данные.

**Недостатки:**

*   **Не учитывают временную последовательность:** не подходят для обработки данных, где важен порядок следования элементов, например, для анализа временных рядов или обработки естественного языка. Для таких задач лучше подходят рекуррентные нейронные сети.
*   **Склонны к переобучению** при неправильном выборе количества слоев и нейронов.

**Ссылки:**

*   [Feedforward neural network - Wikipedia](https://en.wikipedia.org/wiki/Feedforward_neural_network)
*   [Multilayer Perceptron - an overview](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)
*   [Neural Network Architectures - Feed Forward Neural Networks](https://www.youtube.com/watch?v=dPWYUELwIdM)

**46. Тренировочный сет.**

**Тренировочный сет (Training Set)**, также называемый **обучающей выборкой**, - это набор данных, который используется для обучения модели машинного обучения, в частности, нейронной сети. Он состоит из пар "вход-выход", где "вход" - это набор признаков, описывающих объект, а "выход" - это соответствующее целевое значение, которое модель должна научиться предсказывать.

**Важность тренировочного сета:**

*   **Обучение модели:**  модель обучается на тренировочном сете, настраивая свои параметры (веса) таким образом, чтобы минимизировать ошибку между своими предсказаниями и фактическими целевыми значениями.
*   **Обобщающая способность:** качество модели и ее способность делать точные предсказания на новых данных (не из тренировочного сета) напрямую зависит от качества и размера тренировочного сета.

**Требования к тренировочному сету:**

*   **Репрезентативность:** тренировочный сет должен хорошо представлять все возможные варианты входных данных и целевых значений, которые модель может встретить в реальных условиях.
*   **Достаточный размер:** чем больше данных в тренировочном сете, тем лучше модель сможет обучиться и тем выше будет ее обобщающая способность. Однако слишком большой размер может привести к увеличению времени обучения.
*   **Качество данных:** данные в тренировочном сете должны быть чистыми, без ошибок, пропусков и противоречий.
*   **Сбалансированность (для задач классификации):** желательно, чтобы количество объектов каждого класса в тренировочном сете было примерно одинаковым.

**Разделение данных:**

Обычно исходный набор данных делится на три части:

*   **Тренировочный сет (Training Set):** используется для обучения модели.
*   **Валидационный сет (Validation Set):** используется для настройки гиперпараметров модели (например, количества слоев и нейронов в нейронной сети) и выбора лучшей модели.
*   **Тестовый сет (Test Set):** используется для окончательной оценки производительности обученной модели на новых данных.

**Пример:**

Допустим, мы хотим обучить нейронную сеть распознавать рукописные цифры. Тогда тренировочный сет может состоять из изображений рукописных цифр (вход) и соответствующих им меток (выход), например:

*   Вход: изображение цифры "5"
*   Выход: 5

Модель будет обучаться на множестве таких пар, настраивая свои веса, чтобы правильно классифицировать цифры.

**Ссылки:**

*   [Training, validation, and test sets - Wikipedia](https://en.wikipedia.org/wiki/Training,_validation,_and_test_sets)
*   [What is a Training Set?](https://www.ibm.com/topics/training-set)
*   [Machine Learning - Train, Test, Validation Sets - YouTube](https://www.youtube.com/watch?v=gJoEr_Ja448)

**47. Эпоха.**

**Эпоха (Epoch)** в машинном обучении, и в частности в обучении нейронных сетей, - это один полный проход по всему тренировочному набору данных. Во время эпохи модель обрабатывает каждый объект из тренировочного сета ровно один раз, обновляя свои веса после обработки каждого объекта или пакета объектов (в зависимости от используемого алгоритма оптимизации).

**Важность эпохи:**

*   **Итеративное обучение:** обучение нейронной сети - это итеративный процесс, который обычно требует многократного прохода по тренировочному сету для достижения хорошего качества модели.
*   **Настройка весов:** в течение каждой эпохи веса модели корректируются таким образом, чтобы минимизировать ошибку между предсказаниями модели и фактическими целевыми значениями.
*   **Контроль переобучения:** отслеживая производительность модели на валидационном сете после каждой эпохи, можно определить момент, когда модель начинает переобучаться (то есть запоминать тренировочные данные вместо того, чтобы обобщать их).

**Эпоха и другие понятия:**

*   **Итерация (Iteration):** одно обновление весов модели. В эпоху может быть несколько итераций, особенно при использовании мини-пакетного градиентного спуска.
*   **Пакет (Batch) / Мини-пакет (Mini-batch):**  количество объектов из тренировочного сета, обрабатываемых моделью за одну итерацию.
*   **Размер пакета (Batch Size):** количество объектов в одном пакете.

**Пример:**

Допустим, у нас есть тренировочный сет из 1000 объектов, и мы используем мини-пакетный градиентный спуск с размером пакета 100. Тогда:

*   В одной эпохе будет 10 итераций (1000 / 100 = 10).
*   В каждой итерации модель обработает 100 объектов и обновит свои веса.
*   После 10 итераций модель обработает весь тренировочный сет (1000 объектов) - это и будет одна эпоха.

**Количество эпох:**

Количество эпох, необходимое для обучения модели, зависит от:

*   **Размера тренировочного сета.**
*   **Сложности модели.**
*   **Используемого алгоритма оптимизации.**
*   **Заданного критерия остановки (например, достижение определенного уровня точности на валидационном сете).**

Обычно требуется от нескольких десятков до нескольких сотен эпох.

**Ссылки:**

*   [What is an epoch in neural networks?](https://www.quora.com/What-is-an-epoch-in-neural-networks)
*   [What is the Difference Between a Batch and an Epoch in a Neural Network?](https://machinelearningmastery.com/difference-between-a-batch-and-an-epoch/)
*   [Epoch vs Batch Size vs Iteration - Towards Data Science](https://towardsdatascience.com/epoch-vs-iterations-vs-batch-size-4dfb9c7ce9c9)

**48. Обучение с учителем и без учителя.**

**Обучение с учителем (Supervised Learning)** и **обучение без учителя (Unsupervised Learning)** - это два основных типа машинного обучения, которые различаются по типу данных, используемых для обучения модели.

**Обучение с учителем:**

*   **Данные:** используются размеченные данные, то есть пары "вход-выход", где для каждого объекта известен правильный ответ (метка).
*   **Цель:** обучить модель, которая может предсказывать правильный ответ для новых, ранее не виденных объектов.
*   **Примеры задач:**
    *   **Классификация:** отнесение объектов к определенным категориям (например, определение спама в электронной почте, распознавание изображений).
    *   **Регрессия:** предсказание числового значения (например, прогнозирование цены на недвижимость, прогнозирование спроса на товары).
*   **Примеры алгоритмов:**
    *   Линейная регрессия
    *   Логистическая регрессия
    *   Метод опорных векторов (SVM)
    *   Деревья решений
    *   Случайный лес
    *   Градиентный бустинг
    *   Нейронные сети

**Обучение без учителя:**

*   **Данные:** используются неразмеченные данные, то есть данные, для которых неизвестен правильный ответ.
*   **Цель:** выявить структуру в данных, сгруппировать похожие объекты, уменьшить размерность данных или найти аномалии.
*   **Примеры задач:**
    *   **Кластеризация:** группировка объектов по схожести (например, сегментация клиентов, группировка похожих документов).
    *   **Уменьшение размерности:** снижение количества признаков с сохранением важной информации (например, визуализация многомерных данных, сжатие данных).
    *   **Поиск аномалий:** выявление объектов, сильно отличающихся от остальных (например, обнаружение мошеннических транзакций, выявление бракованных изделий).
    *   **Ассоциативные правила:** поиск взаимосвязей между переменными.
*   **Примеры алгоритмов:**
    *   k-средних (k-Means)
    *   Иерархическая кластеризация
    *   DBSCAN
    *   Метод главных компонент (PCA)
    *   t-SNE
    *   Автоэнкодеры

**Сравнительная таблица:**

| Признак | Обучение с учителем | Обучение без учителя |
|---|---|---|
| **Данные** | Размеченные (вход-выход) | Неразмеченные |
| **Цель** | Предсказание правильного ответа | Выявление структуры в данных |
| **Примеры задач** | Классификация, регрессия | Кластеризация, уменьшение размерности, поиск аномалий |
| **Примеры алгоритмов** | Линейная регрессия, SVM, деревья решений, нейронные сети | k-средних, PCA, автоэнкодеры |

**Другие типы обучения:**

*   **Обучение с частичным привлечением учителя (Semi-supervised Learning):** комбинация обучения с учителем и без учителя, когда используется небольшое количество размеченных данных и большое количество неразмеченных данных.
*   **Обучение с подкреплением (Reinforcement Learning):** обучение агента взаимодействию с окружающей средой для максимизации вознаграждения.

**Ссылки:**

*   [Supervised learning - Wikipedia](https://en.wikipedia.org/wiki/Supervised_learning)
*   [Unsupervised learning - Wikipedia](https://en.wikipedia.org/wiki/Unsupervised_learning)
*   [Supervised vs. Unsupervised Learning - Towards Data Science](https://towardsdatascience.com/supervised-vs-unsupervised-learning-14f68e32ea8d)

**49. Быстрые методы стохастического градиента: Поляка, Нестерова, AdaGrad, RMSProp, AdaDelta, Adam, Nadam,**

**Стохастический градиентный спуск (Stochastic Gradient Descent, SGD)** - это метод оптимизации, который обновляет параметры модели (например, веса нейронной сети) на основе градиента функции потерь, вычисленного по одному или нескольким случайно выбранным объектам из обучающей выборки.

**Быстрые методы стохастического градиента** - это модификации SGD, которые направлены на ускорение сходимости и улучшение качества обучения.

**1. Метод ভারী шарика Поляка (Polyak's Heavy Ball method):**

*   **Идея:** добавляет инерцию к обновлению параметров, используя информацию о предыдущем шаге градиента.
*   **Формула:**
    $$v_{t+1} = \beta v_t + \eta \nabla L(w_t)$$
    $$w_{t+1} = w_t - v_{t+1},$$
    где:
    *   $w_t$ - вектор параметров на итерации $t$.
    *   $v_t$ - вектор скорости на итерации $t$.
    *   $\eta$ - скорость обучения.
    *   $\beta$ - коэффициент инерции (обычно 0.9 или 0.99).
    *   $\nabla L(w_t)$ - градиент функции потерь по параметрам $w_t$.

*   **Преимущества:**
    *   Ускоряет сходимость, особенно в направлениях с малой кривизной.
    *   Помогает преодолевать небольшие локальные минимумы.

**2. Ускоренный градиент Нестерова (Nesterov Accelerated Gradient, NAG):**

*   **Идея:** модификация метода ভারী шарика, которая сначала делает шаг в направлении накопленного импульса, а затем вычисляет градиент в этой новой точке.
*   **Формула:**
    $$v_{t+1} = \beta v_t + \eta \nabla L(w_t - \beta v_t)$$
    $$w_{t+1} = w_t - v_{t+1}$$

*   **Преимущества:**
    *   Более точная оценка градиента, чем у метода ভারী шарика.
    *   Часто сходится быстрее, чем метод ভারী шарика.

**3. AdaGrad (Adaptive Gradient Algorithm):**

*   **Идея:** адаптирует скорость обучения для каждого параметра в зависимости от истории градиентов. Параметры, которые обновляются редко, получают большую скорость обучения, а параметры, которые обновляются часто, - меньшую.
*   **Формула:**
    $$G_{t+1} = G_t + \nabla L(w_t) \odot \nabla L(w_t)$$
    $$w_{t+1} = w_t - \frac{\eta}{\sqrt{G_{t+1} + \epsilon}} \odot \nabla L(w_t),$$
    где:
    *   $G_t$ - диагональная матрица, каждый элемент которой равен сумме квадратов градиентов для соответствующего параметра до итерации $t$.
    *   $\epsilon$ - небольшой коэффициент, предотвращающий деление на ноль (обычно $10^{-8}$).
    *   $\odot$ - поэлементное умножение.

*   **Преимущества:**
    *   Автоматическая настройка скорости обучения для каждого параметра.
    *   Хорошо работает для разреженных данных.

*   **Недостатки:**
    *   Скорость обучения монотонно убывает, что может привести к преждевременной остановке обучения.

**4. RMSProp (Root Mean Square Propagation):**

*   **Идея:** модификация AdaGrad, которая использует экспоненциально затухающее среднее квадратов градиентов вместо накопления всех предыдущих квадратов градиентов.
*   **Формула:**
    $$E[g^2]_{t+1} = \gamma E[g^2]_t + (1 - \gamma) \nabla L(w_t) \odot \nabla L(w_t)$$
    $$w_{t+1} = w_t - \frac{\eta}{\sqrt{E[g^2]_{t+1} + \epsilon}} \odot \nabla L(w_t),$$
    где:
    *   $E[g^2]_t$ - экспоненциально затухающее среднее квадратов градиентов.
    *   $\gamma$ - коэффициент затухания (обычно 0.9).

*   **Преимущества:**
    *   Предотвращает проблему монотонного убывания скорости обучения, как в AdaGrad.
    *   Хорошо работает на практике для многих задач.

**5. AdaDelta:**

*   **Идея:** еще одна модификация AdaGrad, которая не требует ручной настройки скорости обучения. Она использует отношение среднеквадратичного обновления параметров к среднеквадратичному градиенту.
*   **Формула:**
    $$E[g^2]_{t+1} = \gamma E[g^2]_t + (1-\gamma)(\nabla L(w_t))^2$$
    $$RMS[g]_{t+1} = \sqrt{E[g^2]_{t+1} + \epsilon}$$
    $$\Delta w_{t+1} = - \frac{RMS[\Delta w]_t}{RMS[g]_{t+1}} \nabla L(w_t)$$
    $$E[\Delta w^2]_{t+1} = \gamma E[\Delta w^2]_t + (1-\gamma)(\Delta w_{t+1})^2$$
    $$RMS[\Delta w]_{t+1} = \sqrt{E[\Delta w^2]_{t+1} + \epsilon}$$
    $$w_{t+1} = w_t + \Delta w_{t+1}$$

*   **Преимущества:**
    *   Не требует ручной настройки скорости обучения.
    *   Устойчива к большим градиентам

**6. Adam (Adaptive Moment Estimation):**

*   **Идея:** комбинация идей Momentum и RMSProp. Использует экспоненциально затухающее среднее как градиентов, так и их квадратов.
*   **Формула:**
    $$m_{t+1} = \beta_1 m_t + (1 - \beta_1) \nabla L(w_t)$$
    $$v_{t+1} = \beta_2 v_t + (1 - \beta_2) \nabla L(w_t) \odot \nabla L(w_t)$$
    $$\hat{m}_{t+1} = \frac{m_{t+1}}{1 - \beta_1^{t+1}}$$
    $$\hat{v}_{t+1} = \frac{v_{t+1}}{1 - \beta_2^{t+1}}$$
    $$w_{t+1} = w_t - \frac{\eta}{\sqrt{\hat{v}_{t+1}} + \epsilon} \hat{m}_{t+1},$$
    где:
    *   $m_t$ - оценка первого момента (среднего) градиента.
    *   $v_t$ - оценка второго момента (нецентрированной дисперсии) градиента.
    *   $\beta_1$ и $\beta_2$ - коэффициенты затухания (обычно 0.9 и 0.999).
    *   $\hat{m}_{t+1}$ и $\hat{v}_{t+1}$ - скорректированные оценки моментов.

*   **Преимущества:**
    *   Один из наиболее эффективных и часто используемых методов оптимизации.
    *   Сочетает в себе преимущества Momentum и RMSProp.
    *   Обычно хорошо работает с настройками по умолчанию.

**7. Nadam (Nesterov-accelerated Adaptive Moment Estimation):**

*   **Идея:** комбинация Adam и NAG.
*   **Формула:**
  $$g_{t} = \nabla_{w_{t-1}}L(w_{t-1} - \beta_{1}\frac{m_{t-1}}{\sqrt{\hat{v}_{t-2}}})$$
  $$m_t = \beta_1 m_{t-1} + (1-\beta_1) g_t$$
  $$v_t = \beta_2 v_{t-1} + (1-\beta_2) g_t^2$$
  $$\hat{m_t} = \frac{m_t}{1-\beta_1^t}$$
  $$\hat{v_t} = \frac{v_t}{1-\beta_2^t}$$
  $$w_t = w_{t-1} - \frac{\eta}{\sqrt{\hat{v_t}}+\epsilon} (\beta_1 \hat{m_t} + \frac{(1-\beta_1)g_t}{1-\beta_1^t})$$
*   **Преимущества:**
    *   Часто сходится быстрее, чем Adam.

**Выбор метода оптимизации:**

*   **Adam** - хороший выбор по умолчанию для многих задач.
*   **RMSProp** - хорошая альтернатива Adam.
*   **Nadam** - стоит попробовать, если Adam не дает желаемых результатов.
*   **SGD с Momentum или NAG** - могут быть эффективны в некоторых случаях, но требуют более тщательной настройки скорости обучения.

**Ссылки:**

*   [An overview of gradient descent optimization algorithms](https://ruder.io/optimizing-gradient-descent/)
*   [Optimization for Deep Learning Highlights in 2017](https://ruder.io/deep-learning-optimization-2017/index.html)
*   [Why Momentum Really Works](https://distill.pub/2017/momentum/)

**50. Диагональный метод Левенберга-Марквардта.**

**Диагональный метод Левенберга-Марквардта (Levenberg-Marquardt Algorithm, LMA)** - это итерационный метод оптимизации, который используется для решения задач нелинейной регрессии, то есть для нахождения параметров модели, минимизирующих сумму квадратов ошибок между предсказанными и фактическими значениями. LMA является комбинацией метода градиентного спуска и метода Гаусса-Ньютона.

**Диагональная версия LMA** аппроксимирует матрицу Гессе (матрицу вторых производных функции потерь) диагональной матрицей, что делает его более эффективным с вычислительной точки зрения, особенно для моделей с большим количеством параметров, таких как нейронные сети.

**Основные идеи:**

*   **Аппроксимация функции потерь:** в окрестности текущего значения параметров функция потерь аппроксимируется квадратичной функцией.
*   **Комбинация градиентного спуска и метода Гаусса-Ньютона:** LMA комбинирует эти два метода, используя параметр демпфирования (damping parameter) $\lambda$.
    *   При большом значении $\lambda$ LMA ведет себя как градиентный спуск.
    *   При малом значении $\lambda$ LMA ведет себя как метод Гаусса-Ньютона.
*   **Адаптивное изменение параметра демпфирования:** $\lambda$ адаптивно изменяется на каждой итерации в зависимости от того, насколько хорошо квадратичная аппроксимация соответствует функции потерь.

**Алгоритм:**

1. **Инициализация:** выбрать начальное значение параметров $w_0$ и начальное значение параметра демпфирования $\lambda_0$.
2. **Итерации:** для каждой итерации $k$:
    *   Вычислить градиент $g_k$ и аппроксимированную диагональную матрицу Гессе $H_k$ функции потерь $L(w)$ в точке $w_k$.
    *   Вычислить изменение параметров $\Delta w_k$ как решение системы линейных уравнений:
        $$(H_k + \lambda_k I) \Delta w_k = -g_k,$$
        где $I$ - единичная матрица. В диагональной версии вместо полной матрицы $H_k$ используется ее диагональная аппроксимация.
    *   Вычислить новое значение параметров $w_{k+1} = w_k + \Delta w_k$.
    *   Вычислить значение функции потерь $L(w_{k+1})$.
    *   Вычислить коэффициент $\rho$:
        $$\rho = \frac{L(w_k) - L(w_{k+1})}{q(0) - q(\Delta w_k)},$$
        где $q(\Delta w) = L(w) + \Delta w^T \nabla_w L(w) + \frac{1}{2} \Delta w^T H \Delta w$ - квадратичная аппроксимация функции потерь.
    *   Обновить параметр демпфирования $\lambda_k$ в зависимости от значения $\rho$:
        *   Если $\rho$ большое (то есть квадратичная аппроксимация хорошо соответствует функции потерь), уменьшить $\lambda_k$ (приближаясь к методу Гаусса-Ньютона).
        *   Если $\rho$ маленькое (то есть квадратичная аппроксимация плохо соответствует функции потерь), увеличить $\lambda_k$ (приближаясь к градиентному спуску).
3. **Остановка:** повторять шаг 2, пока не будет достигнут критерий остановки, например, малое изменение параметров или малое значение градиента.

**Преимущества диагонального метода Левенберга-Марквардта:**

*   **Быстрая сходимость:** обычно сходится быстрее, чем градиентный спуск.
*   **Устойчивость:** менее чувствителен к выбору начального значения параметров, чем метод Гаусса-Ньютона.
*   **Эффективность:** диагональная аппроксимация матрицы Гессе делает его вычислительно эффективным для моделей с большим количеством параметров.

**Недостатки:**

*   **Вычислительно затратный:** требует вычисления градиента и аппроксимации матрицы Гессе на каждой итерации.
*   **Не гарантирует сходимость к глобальному минимуму.**

**Применение в нейронных сетях:**

Диагональный метод Левенберга-Марквардта может использоваться для обучения нейронных сетей, особенно когда требуется высокая точность и сеть имеет умеренное количество параметров.

**Ссылки:**

*   [Levenberg–Marquardt algorithm - Wikipedia](https://en.wikipedia.org/wiki/Levenberg%E2%80%93Marquardt_algorithm)
*   [The Levenberg-Marquardt Algorithm for Nonlinear Least Squares Curve-Fitting Problems](http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3215/pdf/imm3215.pdf)
*   [The Levenberg-Marquardt method for nonlinear parameter optimization - YouTube](https://www.youtube.com/watch?v=VlS-D9tY-vU)

**51. Проблема взрыва градиента и эвристика gradient clipping.**

**Проблема взрыва градиента (Exploding Gradient Problem)** - это явление, которое может возникать при обучении нейронных сетей, особенно глубоких и рекуррентных, когда значения градиентов становятся экспоненциально большими во время обратного распространения ошибки. Это приводит к нестабильному обучению, большим колебаниям весов и, как следствие, к невозможности схождения алгоритма к оптимальному решению.

**Причины взрыва градиента:**

*   **Большие значения весов:** если веса сети инициализированы большими значениями, то градиенты могут экспоненциально возрастать при прохождении через несколько слоев.
*   **Глубокие сети:** в глубоких сетях градиенты вычисляются путем многократного умножения матриц весов, что может приводить к их экспоненциальному росту или затуханию (проблема исчезающего градиента).
*   **Рекуррентные сети:** в рекуррентных сетях градиенты распространяются не только по слоям, но и по времени, что может усугублять проблему взрыва/исчезания градиента.
*   **Функции активации:** некоторые функции активации, например, сигмоида, могут способствовать проблеме взрыва градиента в определенных диапазонах значений.

**Последствия взрыва градиента:**

*   **Нестабильное обучение:** большие обновления весов приводят к "прыжкам" по пространству параметров и мешают сходимости.
*   **NaN или Inf в значениях весов:** градиенты могут стать настолько большими, что приведут к переполнению и получению некорректных значений (NaN или Inf) в весах.
*   **Расхождение алгоритма:** алгоритм оптимизации может не сойтись к оптимальному решению.

**Эвристика Gradient Clipping (ограничение градиента):**

**Gradient Clipping** - это техника, которая используется для борьбы с проблемой взрыва градиента путем ограничения значений градиентов во время обучения.

**Суть метода:**

*   Перед обновлением весов градиенты ограничиваются по некоторому пороговому значению.
*   Если норма градиента превышает пороговое значение, то градиент масштабируется таким образом, чтобы его норма стала равна пороговому значению.

**Варианты Gradient Clipping:**

*   **Clip by Value:** ограничение значений градиентов по абсолютной величине.
    ```
    if gradient > threshold:
        gradient = threshold
    if gradient < -threshold:
        gradient = -threshold
    ```

*   **Clip by Norm:** ограничение нормы градиента.
    ```
    if norm(gradient) > threshold:
        gradient = gradient * (threshold / norm(gradient))
    ```

**Преимущества Gradient Clipping:**

*   **Простота реализации.**
*   **Эффективность в борьбе с проблемой взрыва градиента.**
*   **Стабилизация обучения.**

**Недостатки Gradient Clipping:**

*   **Вносит искажения в направление градиента.**
*   **Не решает проблему исчезающего градиента.**
*   **Требует подбора порогового значения.**

**Рекомендации:**

*   Gradient Clipping - это эвристика, а не теоретически обоснованный метод.
*   Пороговое значение для Gradient Clipping подбирается экспериментально.
*   Clip by Norm является более предпочтительным вариантом, чем Clip by Value.

**Ссылки:**

*   [Understanding the exploding gradient problem](https://machinelearningmastery.com/exploding-gradient-problem/)
*   [What is gradient clipping?](https://www.quora.com/What-is-gradient-clipping)
*   [Gradient Clipping - Deep Learning basics - YouTube](https://www.youtube.com/watch?v=hCOIMm7qG_g)

**52. Метод случайных отключений нейронов (Dropout). Интерпретации Dropout.**

**Метод случайных отключений нейронов (Dropout)** - это метод регуляризации, используемый при обучении нейронных сетей для предотвращения переобучения. Во время обучения случайным образом "отключается" (обнуляется) часть нейронов в каждом слое с заданной вероятностью.

**Как работает Dropout:**

1. **Во время обучения:**
    *   Для каждого слоя, к которому применяется Dropout, задается вероятность *p* (обычно от 0.2 до 0.5) отключения нейронов.
    *   На каждой итерации обучения для каждого нейрона в слое генерируется случайное число от 0 до 1.
    *   Если сгенерированное число меньше *p*, то нейрон "отключается" - его выходное значение обнуляется, и он не участвует в прямом и обратном распространении ошибки на данной итерации.
    *   Остальные нейроны продолжают работать как обычно.
    *   Веса "отключенных" нейронов не обновляются на данной итерации.
2. **Во время тестирования (инференса):**
    *   Все нейроны активны.
    *   Выходные значения нейронов, к которым применялся Dropout, умножаются на *p* (или, что эквивалентно, во время обучения веса масштабируются на 1/(1-p)), чтобы компенсировать тот факт, что во время обучения было активно меньше нейронов.

**Интерпретации Dropout:**

1. **Ансамблирование:** Dropout можно рассматривать как способ обучения ансамбля нейронных сетей. Каждая итерация с разным набором отключенных нейронов эквивалентна обучению отдельной модели с другой архитектурой. Во время тестирования происходит усреднение предсказаний этих моделей.
2. **Предотвращение коадаптации:** Dropout заставляет нейроны учиться работать независимо друг от друга, а не полагаться на конкретные комбинации других нейронов. Это предотвращает коадаптацию нейронов, когда они становятся слишком зависимыми друг от друга и переобучаются на тренировочных данных.
3. **Разреживание:** Dropout делает сеть разреженной, то есть в ней активно только небольшое количество нейронов на каждой итерации. Это может способствовать лучшему обобщению.
4. **Добавление шума:** Dropout можно рассматривать как способ добавления шума в процесс обучения, что делает модель более устойчивой к небольшим изменениям во входных данных.
5. **Аппроксимация байесовского вывода:** Dropout с фиксированным значением p на этапе инференса можно интерпретировать как приближенный байесовский вывод в глубокой гауссовской модели.

**Преимущества Dropout:**

*   **Эффективная регуляризация:** предотвращает переобучение и улучшает обобщающую способность модели.
*   **Простота реализации.**
*   **Улучшение устойчивости модели к шуму.**
*   **Ускорение обучения** в некоторых случаях, так как на каждой итерации обрабатывается меньше нейронов.

**Недостатки Dropout:**

*   **Увеличивает время обучения,** так как требуется больше итераций для сходимости.
*   **Требует подбора вероятности отключения нейронов *p*.**
*   **Может ухудшить производительность на небольших наборах данных.**

**Рекомендации:**

*   Dropout обычно применяется к скрытым слоям нейронной сети.
*   Типичные значения вероятности отключения нейронов *p* находятся в диапазоне от 0.2 до 0.5.
*   При использовании Dropout может потребоваться увеличение количества эпох обучения.
*   Существуют различные модификации Dropout, такие как DropConnect (отключение весов, а не нейронов) и Spatial Dropout (отключение целых карт признаков в сверточных сетях).

**Ссылки:**

*   [Dropout: A Simple Way to Prevent Neural Networks from Overfitting](https://www.cs.toronto.edu/~hinton/absps/JMLRdropout.pdf)
*   [Dropout - Wikipedia](https://en.wikipedia.org/wiki/Dropout_(neural_networks))
*   [Understanding Dropout - Towards Data Science](https://towardsdatascience.com/understanding-dropout-dd26a2d935f5)

**53. Обратный Dropout и L2-регуляризация.**

**Обратный Dropout (Inverted Dropout):**

*   **Стандартный Dropout** во время обучения обнуляет выходы нейронов с вероятностью *p*, а во время тестирования умножает выходы на *p*.
*   **Обратный Dropout** масштабирует выходы **оставшихся** нейронов на коэффициент **1/(1-p)** во время обучения, а во время тестирования не производит никаких действий.

**Преимущества обратного Dropout:**

*   **Упрощение инференса:** не нужно изменять сеть во время тестирования.
*   **Более эффективная реализация** на некоторых платформах.

**L2-регуляризация (Weight Decay):**

*   **Метод регуляризации,** который штрафует большие значения весов, добавляя к функции потерь сумму квадратов весов, умноженную на коэффициент регуляризации $\lambda$.
*   **Формула:**
    $$L_{reg}(w) = L(w) + \frac{\lambda}{2} \sum_{i=1}^{n} w_i^2,$$
    где:
    *   $L(w)$ - исходная функция потерь.
    *   $w_i$ - веса сети.
    *   $\lambda$ - коэффициент регуляризации.

*   **Эффект:**
    *   Веса стремятся к меньшим значениям.
    *   Модель становится менее сложной и менее склонной к переобучению.

**Связь между Dropout и L2-регуляризацией:**

*   Существует теоретическая связь между Dropout и L2-регуляризацией.
*   **Dropout** можно рассматривать как **адаптивную L2-регуляризацию**, где коэффициент регуляризации для каждого веса зависит от частоты его обновления (то есть от того, насколько часто нейрон не был отключен).
*   **Веса, которые обновляются реже, штрафуются сильнее.**

**Отличия Dropout и L2-регуляризации:**

*   **Механизм действия:** Dropout обнуляет выходы нейронов, а L2-регуляризация штрафует большие значения весов.
*   **Влияние на обучение:** Dropout вносит шум в процесс обучения, а L2-регуляризация - нет.
*   **Настройка:** Dropout требует настройки вероятности отключения нейронов *p*, а L2-регуляризация - коэффициента регуляризации $\lambda$.

**Совместное использование Dropout и L2-регуляризации:**

*   Dropout и L2-регуляризацию можно использовать совместно для достижения лучшего результата.
*   Обычно при использовании Dropout коэффициент L2-регуляризации делают меньше, чем при использовании только L2-регуляризации.

**Ссылки:**

*   [Dropout Regularization vs L2 Regularization - Stack Overflow](https://stackoverflow.com/questions/45574670/dropout-regularization-vs-l2-regularization)
*   [Relationship between Dropout and L2-Regularization - Reddit](https://www.reddit.com/r/MachineLearning/comments/9w5x5c/d_relationship_between_dropout_and_l2regularization/)

**54. Функции активации ReLU и PReLU.**

**ReLU (Rectified Linear Unit):**

*   **Формула:**
    $$ReLU(z) = max(0, z)$$
*   **График:**
    ![ReLU](https://upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/1280px-Activation_rectified_linear.svg.png)
*   **Преимущества:**
    *   **Простота и эффективность:** вычисляется очень быстро.
    *   **Ускоряет сходимость** по сравнению с сигмоидой и гиперболическим тангенсом.
    *   **Разреженность:** часть нейронов имеет нулевой выход, что делает сеть разреженной.
*   **Недостатки:**
    *   **Проблема "мертвых нейронов" ("Dying ReLU")**: если нейрон "застрял" в отрицательной области, его выход всегда равен нулю, и он перестает обучаться.
    *   **Не дифференцируема в нуле:** на практике это не является большой проблемой, так как используется субградиент.
    *   **Не центрирована вокруг нуля:** среднее значение выхода ReLU всегда положительно, что может замедлять обучение.

**PReLU (Parametric Rectified Linear Unit):**

*   **Формула:**
    $$PReLU(z) = max(\alpha z, z),$$
    где $\alpha$ - обучаемый параметр.
*   **График:**
    ![PReLU](https://qph.cf2.quoracdn.net/main-qimg-777547db977d7e7d396d95d9b3896d69)
*   **Преимущества:**
    *   **Решает проблему "мертвых нейронов",** так как даже при отрицательных входах есть небольшой наклон.
    *   **Более гибкая,** чем ReLU, так как параметр $\alpha$ может обучаться.
*   **Недостатки:**
    *   **Дополнительный параметр** для обучения.
    *   **Может привести к переобучению,** если $\alpha$ станет слишком большим.

**Leaky ReLU:**

*   **Формула:**
    $$LeakyReLU(z) = max(\alpha z, z), \text{ где } \alpha \text{ - небольшой коэффициент, например, 0.01}$$
    Это частный случай PReLU, где $\alpha$ является фиксированным значением, а не обучаемым параметром.

**Сравнение:**

| Признак | ReLU | PReLU | Leaky ReLU |
|---|---|---|---|
| **Формула** | $max(0, z)$ | $max(\alpha z, z)$ | $max(\alpha z, z)$, $\alpha$ - фиксированное |
| **Параметры** | Нет | $\alpha$ | $\alpha$ (фиксированное) |
| **"Мертвые нейроны"** | Да | Нет | Нет |
| **Производительность** | Высокая | Может быть выше, чем ReLU | Обычно немного выше, чем ReLU |
| **Сложность** | Низкая | Выше, чем ReLU | Немного выше, чем ReLU |

**Когда использовать:**

*   **ReLU:** хороший выбор по умолчанию, особенно для глубоких сетей.
*   **PReLU или Leaky ReLU:** стоит попробовать, если наблюдается проблема "мертвых нейронов" или хочется получить более высокую точность.

**Ссылки:**

*   [Rectifier (neural networks) - Wikipedia](https://en.wikipedia.org/wiki/Rectifier_(neural_networks))
*   [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
*   [Understanding and Using ReLU, Leaky ReLU, and PReLU Activation Functions - YouTube](https://www.youtube.com/watch?v=LFXk-c9w-h4)

**55. Проблема «паралича» сети.**

**Проблема "паралича" сети (Network Paralysis)**, также известная как **проблема "мертвых нейронов" ("Dying ReLU")**, возникает при использовании функции активации ReLU (Rectified Linear Unit) в нейронных сетях. Она заключается в том, что некоторые нейроны могут "застрять" в неактивном состоянии, когда их выход всегда равен нулю, независимо от входных данных.

**Причины "паралича" сети:**

*   **Большое отрицательное смещение (bias):** если вес смещения нейрона слишком большой и отрицательный, то взвешенная сумма входов нейрона может быть всегда отрицательной, даже при положительных значениях весов.
*   **Большая скорость обучения:** большие обновления весов могут привести к тому, что веса станут слишком большими и отрицательными, "выталкивая" нейрон в неактивную область.
*   **Неудачная инициализация весов:** если веса инициализированы таким образом, что большинство нейронов оказываются в неактивной области, то сеть может не обучаться.
*   **Слишком много "мертвых" нейронов:** Если много нейронов "умирает", то сеть теряет свою выразительную способность.

**Последствия "паралича" сети:**

*   **Снижение производительности:** "мертвые" нейроны не вносят вклад в обучение и предсказание, что снижает производительность сети.
*   **Замедление обучения:** градиенты для "мертвых" нейронов равны нулю, поэтому их веса не обновляются, что замедляет обучение.
*   **Невозможность обучения:** в крайних случаях, когда большинство нейронов "мертвые", сеть вообще не может обучаться.

**Способы борьбы с "параличом" сети:**

*   **Использование Leaky ReLU или PReLU:** эти функции активации имеют небольшой наклон в отрицательной области, что позволяет нейронам "выбираться" из неактивного состояния.
*   **Уменьшение скорости обучения:** меньшая скорость обучения снижает вероятность "выталкивания" нейронов в неактивную область.
*   **Использование других методов инициализации весов:** например, инициализация He или Xavier.
*   **Добавление L1 или L2 регуляризации:** штрафует большие значения весов.
*   **Использование пакетной нормализации (Batch Normalization):** нормализует выходы нейронов, что помогает избежать слишком больших или слишком малых значений.
*   **Уменьшение количества нейронов в слое:**

**Диагностика "паралича" сети:**

*   **Отслеживание доли "мертвых" нейронов:** во время обучения можно отслеживать долю нейронов, выход которых равен нулю.
*   **Визуализация активаций:** можно визуализировать распределение активаций нейронов, чтобы увидеть, есть ли много нейронов с нулевым выходом.

**Ссылки:**

*   [The "dying ReLU" problem - Towards Data Science](https://towardsdatascience.com/the-dying-relu-problem-e6f7dd3b132)
*   [What is the "dying ReLU" problem in neural networks?](https://www.quora.com/What-is-the-dying-ReLU-problem-in-neural-networks)
*   [Dying ReLU and Initialization - YouTube](https://www.youtube.com/watch?v=gG-v_vkTp0M)

**56. Эвристики для формирования начального приближения.**

**Формирование начального приближения** весов нейронной сети (инициализация весов) - это важный этап, который может существенно влиять на скорость сходимости и качество обучения.

**Проблемы неудачной инициализации:**

*   **Исчезающий градиент (Vanishing Gradient):** градиенты становятся экспоненциально малыми при обратном распространении через несколько слоев, что замедляет или останавливает обучение.
*   **Взрыв градиента (Exploding Gradient):** градиенты становятся экспоненциально большими, что приводит к нестабильному обучению и расхождению алгоритма.
*   **"Паралич" сети ("Dying ReLU"):** нейроны "застревают" в неактивном состоянии с нулевым выходом.

**Эвристики для формирования начального приближения:**

1. **Случайная инициализация (Random Initialization):**
    *   Веса инициализируются случайными значениями из некоторого распределения, например, равномерного или нормального.
    *   **Проблема:** может привести к исчезающему или взрывающемуся градиенту, если не контролировать диапазон значений.

2. **Инициализация Ксавье (Xavier Initialization) / Glorot Initialization:**
    *   **Идея:** масштабировать случайные значения весов в зависимости от количества входных и выходных соединений нейрона.
    *   **Формула для равномерного распределения:**
        $$W \sim U[-\frac{\sqrt{6}}{\sqrt{n_{in} + n_{out}}}, \frac{\sqrt{6}}{\sqrt{n_{in} + n_{out}}}] $$
    *   **Формула для нормального распределения:**
        $$W \sim N(0, \frac{2}{n_{in} + n_{out}})$$
        где $n_{in}$ - количество входных соединений, $n_{out}$ - количество выходных соединений.
    *   **Преимущества:**
        *   Помогает избежать проблем исчезающего и взрывающегося градиента.
        *   Хорошо работает для сигмоиды и гиперболического тангенса.

3. **Инициализация Хе (He Initialization):**
    *   **Идея:** модификация инициализации Ксавье для функций активации ReLU и ее вариаций.
    *   **Формула для равномерного распределения:**
        $$W \sim U[-\frac{\sqrt{6}}{\sqrt{n_{in}}}, \frac{\sqrt{6}}{\sqrt{n_{in}}}] $$
    *   **Формула для нормального распределения:**
        $$W \sim N(0, \frac{2}{n_{in}})$$
    *   **Преимущества:**
        *   Хорошо работает для ReLU и ее вариаций.

4. **Инициализация нулями или константами:**
    *   **Не рекомендуется**, так как приводит к симметрии: все нейроны в слое будут иметь одинаковые градиенты и обновляться одинаково, что эквивалентно уменьшению количества нейронов.

**Рекомендации:**

*   **Инициализация Ксавье:** подходит для сигмоиды и гиперболического тангенса.
*   **Инициализация Хе:** подходит для ReLU и ее вариаций (Leaky ReLU, PReLU).
*   **Использовать правильную функцию активации:** выбор функции активации и метода инициализации должны соответствовать друг другу.

**Ссылки:**

*   [Understanding the difficulty of training deep feedforward neural networks](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf)
*   [Delving Deep into Rectifiers: Surpassing Human-Level Performance on ImageNet Classification](https://arxiv.org/abs/1502.01852)
*   [Initialization of deep networks - deeplearning.ai](https://www.deeplearning.ai/ai-notes/initialization/)

**57. Метод послойной настройки сети.**

**Метод послойной настройки сети (Layer-wise Pre-training)** - это техника обучения глубоких нейронных сетей, которая заключается в предварительном обучении каждого слоя по отдельности, а затем дообучении всей сети целиком. Этот метод был особенно популярен до появления эффективных методов инициализации весов и алгоритмов оптимизации, таких как Adam.

**Основные идеи:**

*   **Жадное послойное обучение:** каждый слой обучается независимо, пытаясь реконструировать входные данные предыдущего слоя или выучить полезное представление данных.
*   **Неконтролируемое обучение:** на этапе предварительного обучения обычно используются методы обучения без учителя, такие как автоэнкодеры или ограниченные машины Больцмана (Restricted Boltzmann Machines, RBM).
*   **Тонкая настройка (Fine-tuning):** после предварительного обучения всех слоев, вся сеть дообучается с учителем, используя размеченные данные.

**Алгоритм:**

1. **Для каждого слоя, начиная с первого:**
    *   Обучить модель без учителя (например, автоэнкодер) на входных данных текущего слоя.
    *   Использовать веса обученной модели для инициализации весов текущего слоя.
2. **Добавить выходной слой** (например, полносвязный слой для классификации).
3. **Дообучить всю сеть** с учителем, используя размеченные данные и алгоритм обратного распространения ошибки.

**Типы моделей для послойного обучения:**

*   **Автоэнкодеры (Autoencoders):** нейронные сети, которые пытаются реконструировать входные данные на выходном слое. Скрытый слой автоэнкодера обычно имеет меньшую размерность, чем входной, что заставляет сеть учиться сжатому представлению данных.
*   **Ограниченные машины Больцмана (Restricted Boltzmann Machines, RBM):** вероятностные графические модели, которые могут использоваться для обучения представлений данных.

**Преимущества послойной настройки:**

*   **Улучшение инициализации:** послойное обучение позволяет получить хорошее начальное приближение весов, что может улучшить сходимость и качество обучения.
*   **Предотвращение исчезающего градиента:** в глубоких сетях послойное обучение может помочь избежать проблемы исчезающего градиента.
*   **Эффективно при малом количестве размеченных данных:** послойное обучение без учителя позволяет использовать неразмеченные данные для предварительного обучения сети.

**Недостатки послойной настройки:**

*   **Вычислительно затратный:** требует обучения нескольких моделей.
*   **Не всегда приводит к улучшению производительности** по сравнению с обучением сети с нуля с хорошей инициализацией.
*   **Менее актуален** в настоящее время благодаря появлению более эффективных методов инициализации и алгоритмов оптимизации.

**Применение:**

*   В настоящее время послойная настройка **используется реже**, чем раньше.
*   Может быть полезна при **очень малом количестве размеченных данных** или при обучении **очень глубоких сетей**.
*   Используется в некоторых специфических архитектурах, например, в **Deep Belief Networks (DBN)**.

**Ссылки:**

*   [Greedy Layer-Wise Training of Deep Networks](https://papers.nips.cc/paper/2006/file/5da7125e8c0676ee780acef7d4476685-Paper.pdf)
*   [Layer-wise training of deep neural networks - Towards Data Science](https://towardsdatascience.com/layer-wise-training-of-deep-neural-networks-d68bc55755f5)
*   [Why does unsupervised pre-training help deep learning?](https://www.jmlr.org/papers/volume11/erhan10a/erhan10a.pdf)

**58. Генетически алгоритмы и обучение нейросетей. Введение в генетические алгоритмы.**

**Генетические алгоритмы (Genetic Algorithms, GA)** - это метод оптимизации и поиска, основанный на принципах естественного отбора и генетики. Они моделируют процесс эволюции, используя такие механизмы, как селекция, скрещивание и мутация, для поиска оптимальных решений в пространстве поиска.

**Основные понятия генетических алгоритмов:**

*   **Популяция (Population):** набор особей (возможных решений).
*   **Особь (Individual) / Хромосома (Chromosome):** одно возможное решение, закодированное в виде строки (обычно бинарной).
*   **Ген (Gene):** отдельный элемент хромосомы.
*   **Функция приспособленности (Fitness Function):** функция, которая оценивает качество особи (решения).
*   **Селекция (Selection):** выбор наиболее приспособленных особей для размножения.
*   **Скрещивание (Crossover) / Рекомбинация:** создание новых особей (потомков) путем комбинирования частей хромосом родительских особей.
*   **Мутация (Mutation):** случайное изменение одного или нескольких генов в хромосоме.

**Алгоритм работы генетического алгоритма:**

1. **Инициализация:** создать начальную популяцию случайных особей.
2. **Оценка:** оценить приспособленность каждой особи в популяции с помощью функции приспособленности.
3. **Селекция:** выбрать особи для размножения на основе их приспособленности (например, турнирный отбор, рулетка).
4. **Скрещивание:** создать потомков путем скрещивания выбранных особей.
5. **Мутация:** внести случайные изменения в хромосомы потомков.
6. **Формирование новой популяции:** заменить старую популяцию новым поколением, состоящим из потомков и, возможно, части лучших особей из предыдущего поколения.
7. **Повторять шаги 2-6** до тех пор, пока не будет выполнен критерий остановки (например, достигнуто максимальное количество поколений или найдено решение с приемлемой приспособленностью).

**Применение генетических алгоритмов для обучения нейросетей:**

Генетические алгоритмы могут использоваться для оптимизации различных аспектов нейронных сетей:

*   **Обучение весов:** вместо градиентного спуска можно использовать GA для поиска оптимальных весов нейронной сети.
*   **Подбор архитектуры:** GA может использоваться для автоматического подбора количества слоев, количества нейронов в каждом слое, типов функций активации и других параметров архитектуры.
*   **Подбор гиперпараметров:** GA может использоваться для оптимизации гиперпараметров, таких как скорость обучения, коэффициент регуляризации и т.д.

**Преимущества использования GA для обучения нейросетей:**

*   **Глобальный поиск:** GA менее склонен к попаданию в локальные минимумы, чем градиентные методы.
*   **Не требует вычисления градиентов:** GA не требует, чтобы функция приспособленности была дифференцируемой, что позволяет использовать его для оптимизации негладких и невыпуклых функций.
*   **Параллелизуемость:** GA легко распараллеливается, что позволяет ускорить процесс обучения.
*   **Устойчивость к шуму** в данных

**Недостатки использования GA для обучения нейросетей:**

*   **Вычислительно затратный:** GA обычно требует больше вычислений, чем градиентные методы.
*   **Сложность настройки:** GA имеет много параметров, которые нужно настраивать (размер популяции, вероятность скрещивания и мутации и т.д.).
*   **Не гарантирует сходимость к оптимальному решению.**
*   **Сложно интерпретировать** найденные решения

**Ссылки:**

*   [Genetic algorithm - Wikipedia](https://en.wikipedia.org/wiki/Genetic_algorithm)
*   [A Gentle Introduction to Genetic Algorithms - Towards Data Science](https://towardsdatascience.com/introduction-to-genetic-algorithms-including-example-code-e396e98d8bf3)
*   [Introduction to Genetic Algorithms - YouTube](https://www.youtube.com/watch?v=uQj5UNhCPuo)

**59. Применение генетических алгоритмов в сочетании с нейросетями.**

Генетические алгоритмы (GA) могут эффективно сочетаться с нейронными сетями, дополняя и улучшая их возможности. Вот несколько основных способов применения GA в нейросетях:

**1. Обучение весов нейронной сети:**

*   Вместо традиционных методов, основанных на градиентном спуске (например, обратное распространение ошибки), GA может использоваться для поиска оптимальных весов нейронной сети.
*   Каждая особь в популяции GA представляет собой набор весов нейронной сети.
*   Функция приспособленности оценивает качество работы нейронной сети с данными весами (например, точность классификации на тестовом наборе).
*   GA итеративно улучшает популяцию, используя операторы селекции, скрещивания и мутации, пока не будет найдено решение с приемлемой приспособленностью.

**Преимущества:**

*   Глобальный поиск, менее подверженный локальным минимумам.
*   Не требует дифференцируемости функции потерь.

**Недостатки:**

*   Вычислительно более затратный, чем градиентный спуск.
*   Сложнее в настройке.

**2. Подбор архитектуры нейронной сети (Neuroevolution):**

*   GA может использоваться для автоматического определения оптимальной архитектуры нейронной сети, включая:
    *   Количество слоев.
    *   Количество нейронов в каждом слое.
    *   Типы функций активации.
    *   Наличие или отсутствие связей между слоями (например, skip connections).
*   Каждая особь в популяции представляет собой описание архитектуры нейронной сети.
*   Функция приспособленности оценивает производительность нейронной сети с данной архитектурой.

**Преимущества:**

*   Автоматизация процесса проектирования нейронных сетей.
*   Поиск нестандартных и эффективных архитектур.

**Недостатки:**

*   Очень вычислительно затратный процесс.
*   Сложность кодирования архитектуры в виде хромосомы.

**3. Оптимизация гиперпараметров:**

*   GA может использоваться для подбора оптимальных значений гиперпараметров нейронной сети, таких как:
    *   Скорость обучения.
    *   Коэффициенты регуляризации.
    *   Размер пакета.
    *   Параметры функций активации (например, $\alpha$ для PReLU).
*   Каждая особь представляет собой набор значений гиперпараметров.
*   Функция приспособленности оценивает производительность нейронной сети с данными гиперпараметрами.

**Преимущества:**

*   Автоматизация процесса настройки гиперпараметров.
*   Более эффективный поиск оптимальных значений по сравнению с простым перебором.

**Недостатки:**

*   Вычислительно затратный процесс.

**4. Обучение с подкреплением (Reinforcement Learning):**

*   GA может использоваться для обучения агентов в задачах обучения с подкреплением.
*   Каждая особь представляет собой стратегию поведения агента (например, веса нейронной сети, управляющей агентом).
*   Функция приспособленности оценивает суммарное вознаграждение, полученное агентом за определенный период времени.

**Преимущества:**

*   Возможность обучения в средах со сложной динамикой и недифференцируемой функцией вознаграждения.

**Недостатки:**

*   Вычислительно затратный процесс.
*   Сложность кодирования стратегии поведения в виде хромосомы.

**Примеры:**

*   **NEAT (NeuroEvolution of Augmenting Topologies):** алгоритм, который эволюционирует как веса, так и архитектуру нейронных сетей.
*   **HyperNEAT:** расширение NEAT, которое использует Compositional Pattern Producing Networks (CPPNs) для представления связей между нейронами.

**Ссылки:**

*   [Neuroevolution - Wikipedia](https://en.wikipedia.org/wiki/Neuroevolution)
*   [Neuroevolution: A different kind of deep learning - Towards Data Science](https://towardsdatascience.com/neuroevolution-a-different-kind-of-deep-learning-294d770d3456)
*   [Using Genetic Algorithms to Train Neural Networks - YouTube](https://www.youtube.com/watch?v=dDZt60cR-s8)

**60. Использование генетических алгоритмов в развитии архитектуры нейросети и в процессе обучения нейросети.**

**1. Развитие архитектуры нейросети (Neuroevolution):**

*   **Кодирование архитектуры:**
    *   **Прямое кодирование:** архитектура кодируется непосредственно в хромосоме, например, в виде матрицы смежности, где каждый элемент определяет наличие или отсутствие связи между нейронами.
    *   **Непрямое кодирование:** хромосома кодирует правила построения архитектуры, а не саму архитектуру напрямую. Примеры: грамматическая эволюция, клеточные автоматы, L-системы.
*   **Операторы:**
    *   **Мутация:**
        *   Добавление/удаление нейрона.
        *   Добавление/удаление связи.
        *   Изменение функции активации нейрона.
        *   Изменение веса связи (если веса также кодируются в хромосоме).
    *   **Скрещивание:**
        *   Обмен частями хромосом между родительскими особями.
        *   Специальные операторы скрещивания, учитывающие структуру нейронной сети.
*   **Функция приспособленности:**
    *   Обычно оценивается производительность нейронной сети с данной архитектурой на обучающей или валидационной выборке.
    *   Могут учитываться дополнительные факторы, такие как сложность архитектуры (количество нейронов и связей) или время обучения.
*   **Алгоритмы:**
    *   **NEAT (NeuroEvolution of Augmenting Topologies):**  эволюционирует как веса, так и структуру сети, начиная с простых сетей и постепенно усложняя их.
    *   **HyperNEAT:** использует косвенное кодирование на основе CPPN (Compositional Pattern Producing Networks) для представления связей между нейронами, что позволяет эволюционировать сети с регулярными и повторяющимися структурами.
    *   **EANT/EANT2 (Evolutionary Acquisition of Neural Topologies):** использует непрямое кодирование и специальные операторы мутации и скрещивания.

**2. Обучение весов нейросети:**

*   **Кодирование весов:**
    *   Каждая особь в популяции представляет собой вектор, содержащий все веса нейронной сети.
    *   Вещественные значения весов обычно кодируются с помощью вещественного кодирования (real-valued encoding).
*   **Операторы:**
    *   **Мутация:** случайное изменение одного или нескольких весов.
    *   **Скрещивание:** обмен частями векторов весов между родительскими особями.
*   **Функция приспособленности:**
    *   Оценивается производительность нейронной сети с данными весами на обучающей выборке (например, ошибка предсказания).
*   **Преимущества перед градиентным спуском:**
    *   Глобальный поиск оптимума.
    *   Не требует дифференцируемости функции потерь.
    *   Меньше подвержен проблеме застревания в локальных минимумах.
*   **Недостатки:**
    *   Вычислительно более затратный.
    *   Требует большего количества вычислений функции приспособленности (то есть прогонов обучения нейронной сети).

**Совместное использование:**

*   Можно использовать GA как для эволюции архитектуры, так и для обучения весов.
*   Другой подход - использовать GA для поиска оптимальной архитектуры, а затем обучать веса с помощью градиентного спуска.

**Ссылки:**

*   [Neuroevolution: A different kind of deep learning - Towards Data Science](https://towardsdatascience.com/neuroevolution-a-different-kind-of-deep-learning-294d770d3456)
*   [Evolving Neural Networks through Augmenting Topologies](http://nn.cs.utexas.edu/downloads/papers/stanley.ec02.pdf)
*   [A Hypercube-Based Encoding for Evolving Large-Scale Neural Networks](https://dl.acm.org/doi/10.1145/1569901.1569912)

**61. Нейронная сеть Кохонена.**

**Сеть Кохонена (Self-Organizing Map, SOM)**, также известная как **самоорганизующаяся карта признаков (Self-Organizing Feature Map, SOFM)**, - это тип искусственной нейронной сети, которая обучается без учителя и используется для кластеризации, визуализации и уменьшения размерности данных.

**Основные идеи:**

*   **Соревновательное обучение:** нейроны соревнуются друг с другом за право стать "победителем" для каждого входного вектора.
*   **Топологическое упорядочивание:** сеть Кохонена представляет собой двумерную (обычно) решетку нейронов, и при обучении она стремится сохранить топологические отношения между входными данными, то есть близкие входные векторы активируют близко расположенные нейроны на карте.
*   **Латеральное взаимодействие:** при обновлении весов нейрона-победителя обновляются также веса его соседей, но в меньшей степени.

**Архитектура:**

*   **Входной слой:** принимает входные векторы.
*   **Слой Кохонена (карта):** двумерная решетка нейронов, каждый из которых имеет вектор весов той же размерности, что и входные векторы.

**Алгоритм обучения:**

1. **Инициализация:** веса нейронов инициализируются случайными значениями.
2. **Подача входного вектора:** на вход сети подается случайный вектор из обучающей выборки.
3. **Определение нейрона-победителя:** для каждого нейрона вычисляется расстояние между его вектором весов и входным вектором. Нейрон с минимальным расстоянием объявляется победителем.
4. **Обновление весов:** веса нейрона-победителя и его соседей обновляются в соответствии с формулой:
    $$w_{ij}(t+1) = w_{ij}(t) + \alpha(t) \cdot h_{cj}(t) \cdot (x_i - w_{ij}(t)),$$
    где:
    *   $w_{ij}(t)$ - вес связи между входным узлом $i$ и нейроном $j$ на итерации $t$.
    *   $x_i$ - $i$-й компонент входного вектора.
    *   $\alpha(t)$ - скорость обучения, которая обычно уменьшается с течением времени.
    *   $h_{cj}(t)$ - функция соседства, которая определяет степень влияния нейрона-победителя $c$ на нейрон $j$. Обычно используется гауссова функция:
        $$h_{cj}(t) = \exp(-\frac{||r_j - r_c||^2}{2\sigma^2(t)}),$$
        где $r_j$ и $r_c$ - координаты нейрона $j$ и нейрона-победителя $c$ на карте, а $\sigma(t)$ - радиус соседства, который обычно уменьшается с течением времени.
5. **Повторение шагов 2-4** до тех пор, пока не будет выполнен критерий остановки (например, достигнуто максимальное количество эпох или веса перестали существенно изменяться).

**Параметры:**

*   **Размер карты:** количество нейронов в каждом измерении карты.
*   **Начальная скорость обучения $\alpha(0)$:** определяет, насколько сильно обновляются веса на начальных этапах обучения.
*   **Начальный радиус соседства $\sigma(0)$:** определяет размер области вокруг нейрона-победителя, веса которой обновляются.
*   **Функция соседства:** определяет, как степень влияния нейрона-победителя зависит от расстояния до него.

**Визуализация:**

Карта Кохонена позволяет визуализировать многомерные данные в двумерном пространстве. Каждый нейрон карты представляет собой прототип кластера, а его положение на карте отражает близость к другим кластерам.

**Применение:**

*   **Кластеризация данных.**
*   **Визуализация многомерных данных.**
*   **Уменьшение размерности данных.**
*   **Выявление аномалий.**
*   **Анализ данных в различных областях,** таких как финансы, маркетинг, биология, медицина и др.

**Преимущества:**

*   **Простота реализации.**
*   **Наглядность результатов.**
*   **Способность к самоорганизации.**
*   **Устойчивость к шуму.**

**Недостатки:**

*   **Чувствительность к выбору параметров.**
*   **Не всегда четко определены границы кластеров.**
*   **Вычислительно затратный при большом количестве нейронов.**

**Ссылки:**

*   [Self-organizing map - Wikipedia](https://en.wikipedia.org/wiki/Self-organizing_map)
*   [Kohonen's Self Organizing Feature Maps - Towards Data Science](https://towardsdatascience.com/kohonens-self-organizing-feature-maps-neural-networks-for-data-visualization-c97270669914)
*   [Self-Organizing Maps (Kohonen Maps) - YouTube](https://www.youtube.com/watch?v=QVKj3LADCnA)

**62. Конкурентное обучение, стратегии WTA и WTM.**

**Конкурентное обучение (Competitive Learning)** - это принцип обучения нейронных сетей, при котором нейроны соревнуются друг с другом за право быть активированными. Этот принцип лежит в основе самоорганизующихся карт Кохонена и других нейросетевых архитектур.

**Основные идеи:**

*   **Соревнование:** нейроны соревнуются за право стать "победителем" для каждого входного вектора.
*   **Победитель получает все (Winner-Takes-All, WTA):** только один нейрон, наиболее близкий к входному вектору, активируется и обновляет свои веса.
*   **Латеральное взаимодействие:** в некоторых моделях (например, в картах Кохонена) соседние нейроны также могут обновлять свои веса, но в меньшей степени, чем победитель.

**Стратегии:**

*   **Winner-Takes-All (WTA):**
    *   Только один нейрон-победитель активируется и обновляет свои веса.
    *   Остальные нейроны неактивны и не обновляют свои веса.
    *   **Формула:**
        $$y_j = \begin{cases} 1, & \text{если } j = \arg\min_k ||x - w_k|| \\ 0, & \text{иначе} \end{cases}$$
        где $y_j$ - выход нейрона $j$, $x$ - входной вектор, $w_k$ - вектор весов нейрона $k$.

*   **Winner-Takes-Most (WTM):**
    *   Несколько нейронов, наиболее близких к входному вектору, активируются и обновляют свои веса.
    *   Степень активации и обновления весов зависит от расстояния до входного вектора.
    *   **Пример:**
        $$y_j = \begin{cases} f(||x - w_j||), & \text{если } ||x - w_j|| < \theta \\ 0, & \text{иначе} \end{cases}$$
        где $f$ - некоторая функция, убывающая с увеличением расстояния, $\theta$ - порог расстояния.

**Отличия WTA и WTM:**

*   **WTA:** более строгая стратегия, приводит к более четкому разделению пространства признаков между нейронами.
*   **WTM:** более мягкая стратегия, позволяет соседним нейронам также участвовать в обучении, что может способствовать формированию топологически упорядоченных карт.

**Применение:**

*   **Самоорганизующиеся карты Кохонена:** WTM используется для формирования топологически упорядоченной карты признаков.
*   **Векторное квантование (Vector Quantization):** WTA используется для кластеризации данных и сжатия информации.
*   **Нейросетевые архитектуры с локальной обработкой информации:** WTA и WTM могут использоваться для создания разреженных и эффективных нейронных сетей.

**Преимущества конкурентного обучения:**

*   **Простота реализации.**
*   **Способность к самоорганизации.**
*   **Устойчивость к шуму.**
*   **Эффективность в задачах кластеризации и сжатия данных.**

**Недостатки:**

*   **Чувствительность к выбору параметров (например, порога расстояния в WTM).**
*   **Проблема "мертвых" нейронов:** в WTA некоторые нейроны могут никогда не выигрывать и, следовательно, не обучаться.
*   **Не всегда четко определены границы кластеров.**

**Ссылки:**

*   [Competitive learning - Wikipedia](https://en.wikipedia.org/wiki/Competitive_learning)
*   [Competitive Learning - an overview](https://www.sciencedirect.com/topics/computer-science/competitive-learning)
*   [Neural Networks - Competitive Learning - YouTube](https://www.youtube.com/watch?v=O-WdDM6-nEE)

**63. Самоорганизующаяся карта Кохонена.**

Этот вопрос уже был подробно рассмотрен в ответе на **вопрос 61**. Пожалуйста, обратитесь к нему за информацией.

**64. Применение для визуального анализа данных. Искусство интерпретации карт Кохонена.**

**Самоорганизующиеся карты Кохонена (SOM)** являются мощным инструментом для **визуального анализа данных**, позволяя представлять многомерные данные в двумерном пространстве, сохраняя при этом, насколько это возможно, топологические отношения между объектами.

**Основные принципы визуализации с помощью SOM:**

*   **Проекция на плоскость:** многомерные данные проецируются на двумерную карту нейронов.
*   **Топологическое упорядочивание:** близкие объекты в исходном пространстве данных отображаются в близко расположенные нейроны на карте.
*   **Цветовое кодирование:** нейроны на карте раскрашиваются в соответствии с различными характеристиками данных, что позволяет визуально выявлять кластеры, паттерны и взаимосвязи.

**Способы визуализации и интерпретации карт Кохонена:**

1. **U-Matrix (Unified Distance Matrix):**
    *   Отображает расстояния между соседними нейронами на карте.
    *   Светлые области соответствуют близко расположенным нейронам (кластерам), темные области - большому расстоянию между нейронами (границам кластеров).
    *   Позволяет выявлять кластерную структуру данных.

2. **Карты компонент (Component Planes):**
    *   Каждая карта отображает значения одного признака для всех нейронов.
    *   Позволяет анализировать распределение каждого признака по карте и выявлять взаимосвязи между признаками.
    *   Например, если две карты компонент похожи, то соответствующие признаки, вероятно, коррелируют.

3. **Карты кластеров:**
    *   Нейроны на карте раскрашиваются в соответствии с их принадлежностью к кластерам, определенным с помощью какого-либо алгоритма кластеризации (например, k-средних).
    *   Позволяет визуально оценить результаты кластеризации.

4. **Траектории:**
    *   На карте отображаются траектории движения отдельных объектов.
    *   Полезно для анализа временных рядов или данных, изменяющихся во времени.

5. **Раскрашивание по значениям целевой переменной:**
    *   Если для данных известна целевая переменная, то нейроны можно раскрасить в соответствии с ее значениями.
    *   Позволяет выявлять взаимосвязи между признаками и целевой переменной.

6. **Гистограммы:**
    *   Для каждого нейрона можно построить гистограмму распределения значений признаков объектов, попадающих в этот нейрон.
    *   Позволяет получить более детальную информацию о кластерах.

**Искусство интерпретации карт Кохонена:**

*   Интерпретация карт Кохонена - это **итеративный процесс**, требующий **внимания к деталям** и **знания предметной области**.
*   Важно **анализировать карты в комплексе**, сопоставляя различные способы визуализации.
*   Необходимо **учитывать параметры обучения карты**, такие как размер карты, функция соседства и количество эпох обучения.
*   **Субъективность:** интерпретация карт Кохонена может быть субъективной, поэтому важно проверять полученные выводы другими методами анализа данных.

**Примеры применения:**

*   **Маркетинг:** сегментация клиентов, анализ потребительского поведения.
*   **Финансы:** анализ кредитных рисков, выявление мошенничества.
*   **Биология:** анализ геномных данных, классификация белков.
*   **Медицина:** диагностика заболеваний, анализ медицинских изображений.
*   **Экология:** анализ загрязнения окружающей среды, классификация экосистем.

**Ссылки:**

*   [Self-Organizing Maps for Data Visualization](https://www.cs.bham.ac.uk/~jxb/NN/l16.pdf)
*   [Data Visualization using SOM - YouTube](https://www.youtube.com/watch?v=J8Ase-TiAbo)
*   [Visualizations with Self-Organizing Maps - Towards Data Science](https://towardsdatascience.com/visualizations-with-self-organizing-maps-som-fe1d85d7d925)

**65. Сети Хопфилда**

**Сеть Хопфилда (Hopfield Network)** - это тип рекуррентной искусственной нейронной сети, предложенный Джоном Хопфилдом в 1982 году. Она относится к классу сетей с обратными связями, где выходные сигналы нейронов могут подаваться на вход других нейронов, создавая динамическую систему.

**Основные характеристики:**

*   **Полностью связная сеть:** каждый нейрон связан со всеми другими нейронами, включая самого себя.
*   **Симметричные веса:** вес связи от нейрона *i* к нейрону *j* равен весу связи от нейрона *j* к нейрону *i* ($w_{ij} = w_{ji}$).
*   **Бинарные нейроны:** нейроны могут находиться в двух состояниях: +1 (активен) или -1 (неактивен).
*   **Асинхронное обновление:** на каждой итерации обновляется состояние только одного случайно выбранного нейрона.
*   **Энергетическая функция:** сеть Хопфилда имеет энергетическую функцию, которая уменьшается при каждом обновлении состояния нейрона.
*   **Сходимость к устойчивым состояниям:** сеть сходится к одному из устойчивых состояний, которые являются локальными минимумами энергетической функции.

**Архитектура:**

Сеть Хопфилда состоит из одного слоя нейронов, полностью связанных друг с другом. Веса связей образуют симметричную матрицу весов *W*.

**Алгоритм работы:**

1. **Инициализация:** веса сети устанавливаются в соответствии с обучающими образами (см. ниже "Обучение").
2. **Подача входного вектора:** начальное состояние сети устанавливается равным входному вектору.
3. **Асинхронное обновление:**
    *   Случайным образом выбирается нейрон *i*.
    *   Вычисляется взвешенная сумма входов нейрона *i*:
        $$h_i = \sum_{j} w_{ij} s_j,$$
        где $s_j$ - состояние нейрона *j*.
    *   Состояние нейрона *i* обновляется в соответствии с правилом:
        $$s_i = \begin{cases} +1, & \text{если } h_i \ge \theta_i \\ -1, & \text{если } h_i < \theta_i \end{cases},$$
        где $\theta_i$ - порог активации нейрона *i$ (часто полагается равным нулю).
4. **Повторение шага 3** до тех пор, пока сеть не сойдется к устойчивому состоянию (то есть состояния нейронов перестанут изменяться).

**Энергетическая функция:**

$$E = -\frac{1}{2} \sum_{i} \sum_{j} w_{ij} s_i s_j + \sum_{i} \theta_i s_i$$

Сеть Хопфилда сходится к локальному минимуму этой функции.

**Обучение (запоминание образов):**

Сеть Хопфилда может использоваться для хранения и извлечения бинарных образов. Обучение заключается в настройке весов таким образом, чтобы запоминаемые образы были устойчивыми состояниями сети.

*   **Правило Хебба:** простейший способ обучения, при котором веса устанавливаются в соответствии с формулой:
    $$w_{ij} = \sum_{p=1}^{P} (2x_i^p - 1)(2x_j^p - 1),$$
    где $x^p$ - *p*-й обучающий образ, $x_i^p$ - *i*-й компонент *p*-го образа, $P$ - количество обучающих образов.

**Применение:**

*   **Ассоциативная память:** сеть может восстанавливать запомненные образы по их искаженным или неполным версиям.
*   **Решение задач оптимизации:** сеть может использоваться для поиска приближенных решений задач комбинаторной оптимизации, таких как задача коммивояжера.
*   **Распознавание образов.**

**Ограничения:**

*   **Ограниченная емкость:** сеть может хранить ограниченное количество образов (примерно 0.138N для сети из N нейронов при использовании правила Хебба).
*   **Ложные минимумы:** сеть может сходиться к ложным минимумам энергетической функции, которые не соответствуют запомненным образам.
*   **Чувствительность к шуму:** при сильном зашумлении входного образа сеть может не восстановить правильный образ.

**Ссылки:**

*   [Hopfield network - Wikipedia](https://en.wikipedia.org/wiki/Hopfield_network)
*   [Hopfield Networks is All You Need](https://arxiv.org/abs/2008.02217)
*   [Hopfield Network - an overview](https://www.sciencedirect.com/topics/computer-science/hopfield-network)

**66. Сети Хемминга,**

**Сеть Хемминга (Hamming Network)** - это тип искусственной нейронной сети, используемый для классификации бинарных векторов. Она основана на вычислении расстояния Хемминга между входным вектором и эталонными векторами, хранящимися в памяти сети.

**Расстояние Хемминга:**

Расстояние Хемминга между двумя бинарными векторами - это количество позиций, в которых они различаются.

**Архитектура:**

Сеть Хемминга состоит из двух слоев:

*   **Слой распознавания (F1):**
    *   Состоит из *m* нейронов, где *m* - количество классов (эталонных векторов).
    *   Каждый нейрон *j* связан со всеми входными узлами *i* весами $w_{ij}$, равными компонентам эталонного вектора $x^j$ (значения 0 заменяются на -1):
        $$w_{ij} = \begin{cases} +1, & \text{если } x_i^j = 1 \\ -1, & \text{если } x_i^j = 0 \end{cases}$$
    *   Каждый нейрон имеет смещение, равное *n/2*, где *n* - размерность входного вектора.
    *   Выход каждого нейрона $y_j$ вычисляется как:
        $$y_j = \sum_{i=1}^{n} w_{ij} s_i + \frac{n}{2},$$
        где $s_i$ - состояние входного узла *i* (+1 или -1).
    *   Выход нейрона $y_j$ равен *n* минус удвоенное расстояние Хемминга между входным вектором и эталонным вектором $x^j$.

*   **Слой сравнения (F2):**
    *   Состоит из *m* нейронов, по одному на каждый класс.
    *   Использует механизм **WTA (Winner-Takes-All)** для выбора нейрона с наибольшим значением на выходе слоя F1.
    *   Выход нейрона-победителя равен 1, остальные - 0.

**Алгоритм работы:**

1. **Инициализация:** веса сети устанавливаются равными компонентам эталонных векторов.
2. **Подача входного вектора:** на вход сети подается бинарный вектор (0 и 1 заменяются на -1 и +1).
3. **Вычисление выходов слоя F1:** для каждого нейрона *j* слоя F1 вычисляется его выход $y_j$.
4. **Выбор победителя в слое F2:** определяется нейрон с максимальным значением $y_j$ в слое F1.
5. **Классификация:** входной вектор относится к тому классу, которому соответствует нейрон-победитель в слое F2.

**Преимущества:**

*   **Простота реализации.**
*   **Быстрая классификация.**
*   **Гарантированная сходимость.**
*   **Способность обнаруживать новые классы** (если максимальный выход слоя F1 ниже определенного порога, то входной вектор не относится ни к одному из известных классов).

**Недостатки:**

*   **Работает только с бинарными векторами.**
*   **Чувствительность к шуму:** небольшие искажения входного вектора могут привести к неправильной классификации.
*   **Ограниченная емкость:** количество эталонных векторов ограничено.
*   **Не обобщает** на новые, неизвестные ранее образы

**Применение:**

*   **Распознавание образов:** классификация бинарных изображений, символов и т.д.
*   **Контроль ошибок:** обнаружение и исправление ошибок в цифровых данных.
*   **Ассоциативная память:** хранение и извлечение бинарных данных.

**Ссылки:**

*   [The Hamming Network - Towards Data Science](https://towardsdatascience.com/the-hamming-network-2d978997977d)
*   [Hamming Neural Network - YouTube](https://www.youtube.com/watch?v=Lp-gwR5UsFs)

**67. Сети Элмана.**

**Сеть Элмана (Elman Network)**, также известная как **простая рекуррентная сеть (Simple Recurrent Network, SRN)**, - это тип рекуррентной нейронной сети, предложенный Джеффом Элманом в 1990 году. Она является одной из первых и наиболее простых рекуррентных архитектур.

**Основные характеристики:**

*   **Рекуррентность:** сеть имеет обратные связи, позволяющие ей сохранять информацию о предыдущих состояниях.
*   **Контекстный слой:** сеть Элмана имеет специальный слой, называемый контекстным, который хранит копию активаций скрытого слоя с предыдущего такта времени.
*   **Обучение с учителем:** сеть обучается с учителем, используя алгоритм обратного распространения ошибки во времени (Backpropagation Through Time, BPTT).

**Архитектура:**

Сеть Элмана состоит из трех слоев:

*   **Входной слой:** получает входные данные.
*   **Скрытый слой:** обрабатывает входные данные и передает их на выходной слой и в контекстный слой.
*   **Выходной слой:** генерирует выходные значения сети.
*   **Контекстный слой:** хранит копию активаций скрытого слоя с предыдущего такта времени.

**Алгоритм работы:**

1. **Инициализация:** веса сети инициализируются случайными значениями.
2. **Прямое распространение:**
    *   На каждом такте времени $t$:
        *   Входной вектор $x(t)$ подается на входной слой.
        *   Скрытый слой $h(t)$ вычисляет свои активации на основе взвешенной суммы входных данных и активаций контекстного слоя $h(t-1)$:
            $$h(t) = f(W_{xh}x(t) + W_{hh}h(t-1) + b_h),$$
            где $W_{xh}$ - матрица весов между входным и скрытым слоями, $W_{hh}$ - матрица весов между контекстным и скрытым слоями, $b_h$ - вектор смещений скрытого слоя, $f$ - функция активации (обычно сигмоида или гиперболический тангенс).
        *   Выходной слой $y(t)$ вычисляет свои активации на основе взвешенной суммы активаций скрытого слоя:
            $$y(t) = g(W_{hy}h(t) + b_y),$$
            где $W_{hy}$ - матрица весов между скрытым и выходным слоями, $b_y$ - вектор смещений выходного слоя, $g$ - функция активации выходного слоя.
        *   Активации скрытого слоя $h(t)$ копируются в контекстный слой.
3. **Вычисление ошибки:** вычисляется ошибка между предсказанными значениями $y(t)$ и целевыми значениями $d(t)$.
4. **Обратное распространение ошибки:** ошибка распространяется обратно по сети, и веса обновляются с помощью алгоритма обратного распространения ошибки во времени (BPTT).
5. **Повторение шагов 2-4** для всех тактов времени и всех обучающих примеров.

**Преимущества:**

*   **Простота реализации.**
*   **Способность обрабатывать последовательности данных.**
*   **Возможность моделировать временные зависимости.**

**Недостатки:**

*   **Проблема исчезающего/взрывающегося градиента:** при обучении на длинных последовательностях градиенты могут становиться экспоненциально малыми или большими, что затрудняет обучение.
*   **Ограниченная память:** сеть Элмана хранит информацию только об одном предыдущем такте времени, что ограничивает ее способность моделировать долгосрочные зависимости.

**Применение:**

*   **Обработка естественного языка:** машинный перевод, распознавание речи, генерация текста.
*   **Анализ временных рядов:** прогнозирование временных рядов, обнаружение аномалий.
*   **Управление роботами.**

**Ссылки:**

*   [Elman network - Wikipedia](https://en.wikipedia.org/wiki/Elman_network)
*   [Finding Structure in Time](https://crl.ucsd.edu/~elman/Papers/fsit.pdf)
*   [Recurrent Neural Networks (RNN) - Elman Network - YouTube](https://www.youtube.com/watch?v=0s-Zv_nGMWU)

**68. Сети Хопфилда и Хемминга в задачах распознавания образов.**

**Сети Хопфилда и Хемминга** - это две классические нейросетевые архитектуры, которые исторически использовались для задач распознавания образов, особенно для **бинарных образов**.

**Сеть Хопфилда:**

*   **Принцип работы:** сеть Хопфилда - это **ассоциативная память**, которая хранит набор эталонных образов и может восстанавливать их по искаженным или неполным версиям.
*   **Распознавание образов:**
    1. **Обучение:** веса сети настраиваются таким образом, чтобы эталонные образы были устойчивыми состояниями сети (локальными минимумами энергетической функции). Обычно используется правило Хебба.
    2. **Распознавание:** искаженный или неполный образ подается на вход сети. Сеть итеративно обновляет свои состояния, пока не сойдется к устойчивому состоянию. Если это устойчивое состояние совпадает с одним из эталонных образов, то образ считается распознанным.
*   **Преимущества:**
    *   Способность восстанавливать образы по неполной или искаженной информации.
    *   Простота реализации (для бинарных образов).
*   **Недостатки:**
    *   Ограниченная емкость памяти.
    *   Чувствительность к шуму.
    *   Возможность сходимости к ложным минимумам, не соответствующим эталонным образам.
    *   Работает в основном с бинарными образами

**Сеть Хемминга:**

*   **Принцип работы:** сеть Хемминга вычисляет расстояние Хемминга между входным образом и каждым из эталонных образов и выбирает тот, который находится на наименьшем расстоянии.
*   **Распознавание образов:**
    1. **Обучение:** веса сети устанавливаются равными компонентам эталонных образов (0 заменяется на -1).
    2. **Распознавание:** входной образ подается на вход сети. Сеть вычисляет расстояние Хемминга до каждого эталонного образа и выбирает тот, который находится на наименьшем расстоянии.
*   **Преимущества:**
    *   Простота реализации.
    *   Быстрая классификация.
    *   Гарантированная сходимость.
*   **Недостатки:**
    *   Работает только с бинарными образами.
    *   Чувствительность к шуму: даже небольшие искажения могут привести к неправильной классификации.
    *   Не обобщает, то есть не может распознавать образы, которые не похожи на эталонные.

**Сравнение:**

| Признак | Сеть Хопфилда | Сеть Хемминга |
|---|---|---|
| **Тип сети** | Рекуррентная, ассоциативная память | Прямого распространения, классификатор |
| **Принцип работы** | Сходится к устойчивому состоянию, соответствующему ближайшему эталонному образу | Вычисляет расстояние Хемминга до эталонных образов |
| **Обучение** | Правило Хебба | Установка весов по эталонным образам |
| **Распознавание** | Итеративное обновление состояний | Однопроходное вычисление |
| **Преимущества** | Восстановление образов | Быстрая классификация |
| **Недостатки** | Ограниченная емкость, чувствительность к шуму, ложные минимумы | Чувствительность к шуму, работает только с бинарными образами, не обобщает |

**Заключение:**

*   Сети Хопфилда и Хемминга - это **простые нейросетевые модели**, которые могут использоваться для распознавания бинарных образов.
*   **Сеть Хопфилда** лучше подходит для задач, где требуется **восстановление образов по неполной или искаженной информации**.
*   **Сеть Хемминга** лучше подходит для задач, где требуется **быстрая классификация бинарных образов**.
*   В настоящее время эти сети **используются редко**, так как существуют более мощные и гибкие нейросетевые архитектуры, такие как сверточные нейронные сети (CNN) и рекуррентные нейронные сети (RNN), которые показывают гораздо лучшие результаты в задачах распознавания образов.

**Ссылки:**

*   [Hopfield network - Wikipedia](https://en.wikipedia.org/wiki/Hopfield_network)
*   [The Hamming Network - Towards Data Science](https://towardsdatascience.com/the-hamming-network-2d978997977d)

**69. Концепция глубокого обучения.**

**Глубокое обучение (Deep Learning)** - это класс методов машинного обучения, основанных на обучении **глубоких нейронных сетей** (Deep Neural Networks, DNN). Глубокими называются нейронные сети с **большим количеством скрытых слоев**.

**Основные идеи:**

*   **Иерархическое представление данных:** глубокие сети учатся извлекать иерархические представления данных, где каждый слой извлекает все более абстрактные признаки из выходных данных предыдущего слоя.
*   **Автоматическое извлечение признаков:** в отличие от традиционных методов машинного обучения, где признаки обычно извлекаются вручную, глубокие сети учатся извлекать признаки автоматически из сырых данных.
*   **Обучение представлений (Representation Learning):** глубокое обучение фокусируется на обучении представлений данных, которые являются полезными для решения конкретной задачи.
*   **Сквозное обучение (End-to-End Learning):** глубокие сети обучаются непосредственно на сырых данных, без необходимости промежуточных этапов обработки, таких как ручное извлечение признаков.

**Отличия от традиционных нейронных сетей:**

*   **Глубина:** глубокие сети имеют много скрытых слоев, в то время как традиционные нейронные сети обычно имеют один или два скрытых слоя.
*   **Автоматическое извлечение признаков:** глубокие сети учатся извлекать признаки автоматически, в то время как в традиционных методах признаки обычно создаются вручную.
*   **Типы архитектур:** в глубоком обучении используются различные архитектуры, такие как сверточные нейронные сети (CNN), рекуррентные нейронные сети (RNN) и автоэнкодеры, которые лучше подходят для обработки различных типов данных (изображения, текст, временные ряды).

**Преимущества глубокого обучения:**

*   **Высокая точность:** глубокие сети достигают высокой точности в различных задачах, часто превосходя другие методы машинного обучения.
*   **Способность к обучению на больших объемах данных:** глубокие сети хорошо масштабируются и могут обучаться на огромных наборах данных.
*   **Автоматическое извлечение признаков:** избавляет от необходимости ручного создания признаков, что является трудоемким и требующим специальных знаний процессом.
*   **Гибкость:** глубокие сети могут использоваться для решения широкого круга задач.

**Недостатки глубокого обучения:**

*   **Вычислительно затратный:** обучение глубоких сетей требует больших вычислительных ресурсов, особенно графических процессоров (GPU).
*   **Требует большого количества данных:** для обучения глубоких сетей обычно требуется много размеченных данных.
*   **Сложность интерпретации:** глубокие сети являются "черными ящиками", и понять, как они принимают решения, бывает сложно.
*   **Склонность к переобучению:** глубокие сети могут переобучаться на тренировочных данных, что ухудшает их обобщающую способность.
*   **Сложность в настройке и подборе гиперпараметров**

**Применение:**

*   **Компьютерное зрение:** распознавание изображений, обнаружение объектов, сегментация изображений.
*   **Обработка естественного языка:** машинный перевод, анализ тональности текста, генерация текста.
*   **Распознавание речи:** преобразование речи в текст, идентификация диктора.
*   **Рекомендательные системы:** рекомендации товаров, фильмов, музыки.
*   **Игры:** обучение агентов для игры в сложные игры, такие как Go и Dota 2.
*   **Медицина:** диагностика заболеваний, анализ медицинских изображений.
*   **Финансы:** прогнозирование цен на акции, обнаружение мошенничества.

**Ссылки:**

*   [Deep learning - Wikipedia](https://en.wikipedia.org/wiki/Deep_learning)
*   [Deep Learning - An MIT Press book](https://www.deeplearningbook.org/)
*   [Deep Learning - 3Blue1Brown](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJ
**70. Сверточные нейронные сети (Convolutional NN).**

**Сверточные нейронные сети (Convolutional Neural Networks, CNN)** - это тип глубоких нейронных сетей, বিশেষভাবে разработанный для обработки данных, имеющих **структуру сетки**, таких как изображения (2D-сетка пикселей) или временные ряды (1D-сетка значений).

**Основные идеи:**

*   **Свертка (Convolution):** основная операция в CNN, которая заключается в применении фильтра (ядра свертки) к входным данным для извлечения признаков.
*   **Локальные рецептивные поля (Local Receptive Fields):** нейроны в сверточном слое связаны только с небольшой областью входных данных, называемой локальным рецептивным полем.
*   **Разделение весов (Shared Weights):** один и тот же фильтр применяется ко всем областям входных данных, что значительно сокращает количество параметров и делает сеть более устойчивой к сдвигам.
*   **Субдискретизация (Pooling):** операция, которая уменьшает размерность карт признаков, сохраняя при этом наиболее важную информацию.

**Архитектура CNN:**

Типичная CNN состоит из следующих типов слоев:

1. **Сверточный слой (Convolutional Layer):**
    *   Применяет набор фильтров к входным данным.
    *   Каждый фильтр генерирует карту признаков (feature map).
    *   Использует нелинейную функцию активации (обычно ReLU).
    *   **Гиперпараметры:**
        *   Количество фильтров.
        *   Размер фильтра (kernel size).
        *   Шаг (stride) - на сколько пикселей сдвигается фильтр при применении к входным данным.
        *   Дополнение (padding) - добавление пикселей по краям входных данных для сохранения размерности.

2. **Слой субдискретизации (Pooling Layer):**
    *   Уменьшает размерность карт признаков.
    *   Наиболее распространенные типы субдискретизации:
        *   **Max Pooling:** выбирает максимальное значение из области.
        *   **Average Pooling:** вычисляет среднее значение из области.
    *   **Гиперпараметры:**
        *   Размер окна субдискретизации.
        *   Шаг (stride).

3. **Полносвязный слой (Fully Connected Layer):**
    *   Обычный слой нейронной сети, где каждый нейрон связан со всеми нейронами предыдущего слоя.
    *   Обычно используется в конце CNN для классификации или регрессии.

**Процесс работы CNN:**

1. **Входные данные:** подаются на вход сети (например, изображение).
2. **Сверточные слои:** извлекают иерархические признаки из входных данных.
3. **Слои субдискретизации:** уменьшают размерность карт признаков и делают сеть более устойчивой к небольшим сдвигам и искажениям.
4. **Полносвязные слои:** объединяют извлеченные признаки и генерируют выходные значения сети.

**Преимущества CNN:**

*   **Эффективны для обработки изображений и других структурированных данных.**
*   **Автоматически извлекают признаки.**
*   **Устойчивы к сдвигам и небольшим искажениям.**
*   **Меньшее количество параметров** по сравнению с полносвязными сетями для обработки изображений.

**Недостатки CNN:**

*   **Требуют большого количества данных для обучения.**
*   **Вычислительно затратные.**
*   **Сложность интерпретации.**

**Применение:**

*   **Распознавание изображений:** классификация изображений, обнаружение объектов, сегментация изображений.
*   **Обработка видео:** анализ видео, распознавание действий.
*   **Обработка естественного языка:** анализ тональности текста, машинный перевод (в сочетании с рекуррентными сетями).
*   **Медицинская диагностика:** анализ медицинских изображений.

**Ссылки:**

*   [Convolutional neural network - Wikipedia](https://en.wikipedia.org/wiki/Convolutional_neural_network)
*   [A Beginner's Guide To Understanding Convolutional Neural Networks](https://towardsdatascience.com/a-beginners-guide-to-understanding-convolutional-neural-networks-part-i-d55f580044d)
*   [CS231n Convolutional Neural Networks for Visual Recognition - Stanford](http://cs231n.github.io/convolutional-networks/)

**71. Идея обобщения CNN на любые структурированные данные.**

**Основная идея обобщения CNN на любые структурированные данные** заключается в том, чтобы определить аналоги операций **свертки** и **субдискретизации** для данных, имеющих структуру, отличную от изображений.

**Ключевые принципы:**

*   **Локальность:** операция свертки должна учитывать локальные взаимосвязи между элементами данных.
*   **Стационарность (разделение весов):** одни и те же операции (фильтры) должны применяться к разным частям данных.
*   **Иерархичность:** признаки должны извлекаться на разных уровнях абстракции.

**Способы обобщения:**

1. **Графовые сверточные сети (Graph Convolutional Networks, GCN):**
    *   Данные представляются в виде графа, где узлы - это элементы данных, а ребра - связи между ними.
    *   Операция свертки определяется как агрегация информации от соседних узлов.
    *   Примеры:
        *   **Spectral-based GCN:** используют спектральное разложение графа для определения свертки.
        *   **Spatial-based GCN:** определяют свертку непосредственно в пространстве графа, агрегируя информацию от соседей.

2. **Свертки на многообразиях (Manifold Convolution):**
    *   Данные рассматриваются как точки на многообразии.
    *   Операция свертки определяется с помощью геодезического расстояния на многообразии.
    *   Примеры:
        *   **Geodesic CNN:** использует геодезическое расстояние для определения локальных областей на многообразии.
        *   **MoNet (Mixture Model Networks):** использует смесь гауссиан для моделирования локальных областей на многообразии.

3. **Свертки на последовательностях:**
    *   Для одномерных последовательностей (например, временных рядов) можно использовать 1D-свертки.
    *   Для последовательностей произвольной структуры можно использовать рекуррентные сети или трансформеры.

4. **Свертки на множествах:**
    *   Deep Sets предлагает архитектуру, инвариантную к перестановкам элементов в множестве.
    *   PointNet использует симметричные функции для агрегации информации от элементов множества.

**Примеры применения:**

*   **Рекомендательные системы:** графовые сверточные сети могут использоваться для моделирования взаимодействий между пользователями и товарами.
*   **Молекулярная биология:** графовые сверточные сети могут использоваться для предсказания свойств молекул, представленных в виде графов.
*   **Социальные сети:** графовые сверточные сети могут использоваться для анализа социальных графов и прогнозирования поведения пользователей.
*   **Обработка 3D-данных:** свертки на многообразиях могут использоваться для обработки облаков точек и 3D-моделей.
*   **Физика:** моделирование взаимодействия частиц

**Трудности обобщения:**

*   **Определение подходящего аналога операции свертки** для конкретного типа данных.
*   **Вычислительная сложность** для некоторых типов данных.
*   **Недостаток теоретической базы** для некоторых обобщений CNN.

**Ссылки:**

*   [Graph Convolutional Networks - Thomas Kipf](https://tkipf.github.io/graph-convolutional-networks/)
*   [Geometric Deep Learning - Bronstein et al.](https://arxiv.org/abs/1611.08097)
*   [A Gentle Introduction to Graph Neural Networks - Distill](https://distill.pub/2021/gnn-intro/)

**72. Архитектуры сверочные нейронные сети для анализа изображений. (AlexNet, ZF Net, VGG Net, Inception. ResNet и др).**

Рассмотрим несколько классических архитектур сверточных нейронных сетей (CNN), которые оказали значительное влияние на развитие глубокого обучения в области компьютерного зрения:

**1. AlexNet (2012):**

*   **Авторы:** Alex Krizhevsky, Ilya Sutskever, Geoffrey Hinton.
*   **Достижение:** Победила в соревновании ImageNet Large Scale Visual Recognition Challenge (ILSVRC) 2012 года, значительно превзойдя другие методы.
*   **Архитектура:**
    *   8 слоев: 5 сверточных и 3 полносвязных.
    *   Функция активации ReLU.
    *   Max Pooling.
    *   Dropout.
    *   Два параллельных потока обработки на двух GPU.
*   **Особенности:**
    *   Первая глубокая CNN, показавшая значительное преимущество на ImageNet.
    *   Использование ReLU вместо сигмоиды/гиперболического тангенса.
    *   Применение Dropout для регуляризации.
*   **Ссылка:** [ImageNet Classification with Deep Convolutional Neural Networks](https://papers.nips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)

**2. ZF Net (2013):**

*   **Авторы:** Matthew Zeiler, Rob Fergus.
*   **Достижение:** Победила в ILSVRC 2013 года.
*   **Архитектура:**
    *   Похожа на AlexNet, но с некоторыми изменениями в размерах фильтров и количестве карт признаков.
*   **Особенности:**
    *   Визуализация работы CNN с помощью техники Deconvolutional Network.
    *   Лучшее понимание того, как CNN извлекают признаки.
*   **Ссылка:** [Visualizing and Understanding Convolutional Networks](https://arxiv.org/abs/1311.2901)

**3. VGG Net (2014):**

*   **Авторы:** Karen Simonyan, Andrew Zisserman.
*   **Достижение:** Заняла второе место в ILSVRC 2014 года.
*   **Архитектура:**
    *   Более глубокая сеть, чем AlexNet (16 или 19 слоев).
    *   Использование только фильтров 3x3 с шагом 1.
    *   Max Pooling 2x2 с шагом 2.
    *   Несколько сверточных слоев подряд перед Pooling'ом.
*   **Особенности:**
    *   Простая и единообразная архитектура.
    *   Показала, что глубина сети играет важную роль в повышении точности.
    *   Предварительно обученные модели VGG Net широко используются для переноса обучения (transfer learning).
*   **Ссылка:** [Very Deep Convolutional Networks for Large-Scale Image Recognition](https://arxiv.org/abs/1409.1556)

**4. Inception (GoogLeNet) (2014):**

*   **Авторы:** Christian Szegedy et al. (Google).
*   **Достижение:** Победила в ILSVRC 2014 года.
*   **Архитектура:**
    *   22 слоя.
    *   Использование "Inception модулей", которые применяют несколько фильтров разных размеров (1x1, 3x3, 5x5) параллельно, а затем объединяют результаты.
    *   1x1 свертки для уменьшения размерности.
    *   Вспомогательные классификаторы (auxiliary classifiers) для борьбы с исчезающим градиентом.
*   **Особенности:**
    *   Более эффективное использование параметров по сравнению с VGG Net.
    *   Меньше параметров, чем у AlexNet, но более высокая точность.
*   **Ссылка:** [Going Deeper with Convolutions](https://arxiv.org/abs/1409.4842)

**5. ResNet (Residual Network) (2015):**

*   **Авторы:** Kaiming He et al. (Microsoft Research).
*   **Достижение:** Победила в ILSVRC 2015 года.
*   **Архитектура:**
    *   Очень глубокие сети (до 152 слоев и более).
    *   Использование "остаточных блоков" (residual blocks), которые добавляют вход блока к его выходу после нескольких сверточных слоев.
    *   Skip connections (обходные соединения), позволяющие градиенту проходить через несколько слоев без затухания.
*   **Особенности:**
    *   Решает проблему исчезающего градиента в очень глубоких сетях.
    *   Позволяет обучать очень глубокие сети, что приводит к повышению точности.
    *   Стала основой для многих современных архитектур CNN.
*   **Ссылка:** [Deep Residual Learning for Image Recognition](https://arxiv.org/abs/1512.03385)

**Другие важные архитектуры:**

*   **Inception-v3, Inception-v4:** улучшения Inception.
*   **ResNeXt:** улучшение ResNet с использованием групповых сверток.
*   **DenseNet:** сеть с плотными связями между слоями.
*   **MobileNet:** архитектура, оптимизированная для мобильных устройств.
*   **EfficientNet:** семейство архитектур, полученных с помощью нейроархитектурного поиска (Neural Architecture Search, NAS).

**Ссылки:**

*   [An overview of different CNN architectures](https://medium.com/analytics-vidhya/cnns-architectures-lenet-alexnet-vgg-googlenet-resnet-and-more-666091488df5)
*   [Review: AlexNet, CaffeNet — Winner of ILSVRC 2012 (Image Classification)](https://towardsdatascience.com/review-alexnet-caffenet-winner-in-ilsvrc-2012-image-classification-b93598314160)
*   [CNN Architectures: VGG, ResNet, Inception, and Xception - Towards Data Science](https://towardsdatascience.com/cnn-architectures-vgg-resnet-inception-and-xception-a799f8692d3)

**73. Соревнующиеся нейронные сети.**

**Соревнующиеся нейронные сети (Generative Adversarial Networks, GAN)** - это класс нейросетевых архитектур, предложенный Яном Гудфеллоу и его коллегами в 2014 году. GAN состоят из двух нейронных сетей, которые обучаются в соревновательном режиме:

*   **Генератор (Generator):** пытается создать данные, похожие на реальные данные из обучающего набора.
*   **Дискриминатор (Discriminator):** пытается отличить реальные данные от данных, созданных генератором.

**Основные идеи:**

*   **Соревновательное обучение:** генератор и дискриминатор обучаются одновременно, соревнуясь друг с другом.
*   **Минимаксная игра:** обучение GAN можно рассматривать как минимаксную игру, где генератор стремится минимизировать функцию потерь, а дискриминатор - максимизировать ее.
*   **Генерация данных:** генератор учится создавать новые данные, похожие на реальные данные.
*   **Распознавание образов:** дискриминатор учится отличать реальные данные от поддельных.

**Алгоритм обучения:**

1. **Инициализация:** инициализировать генератор и дискриминатор случайными весами.
2. **Итерации:**
    *   **Шаг дискриминатора:**
        *   Сгенерировать пакет поддельных данных с помощью генератора.
        *   Подать на вход дискриминатора пакет реальных данных и пакет поддельных данных.
        *   Обновить веса дискриминатора, чтобы он лучше отличал реальные данные от поддельных.
    *   **Шаг генератора:**
        *   Сгенерировать пакет поддельных данных с помощью генератора.
        *   Подать эти данные на вход дискриминатора.
        *   Обновить веса генератора, чтобы он создавал данные, которые дискриминатор с большей вероятностью примет за реальные.

**Функция потерь:**

Обучение GAN можно сформулировать как минимаксную игру с функцией потерь:

$$ \min_G \max_D V(D, G) = \mathbb{E}_{x \sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z \sim p_z(z)}[\log(1 - D(G(z)))],$$

где:

*   $G$ - генератор.
*   $D$ - дискриминатор.
*   $x$ - реальные данные.
*   $z$ - случайный шум, подаваемый на вход генератора.
*   $p_{data}(x)$ - распределение реальных данных.
*   $p_z(z)$ - распределение случайного шума.
*   $D(x)$ - вероятность того, что $x$ является реальными данными, по мнению дискриминатора.
*   $G(z)$ - данные, сгенерированные генератором из случайного шума $z$.

**Проблемы обучения GAN:**

*   **Нестабильность обучения:** трудно достичь равновесия между генератором и дискриминатором.
*   **Схлопывание мод (Mode Collapse):** генератор может научиться создавать только ограниченный набор данных, игнорируя другие моды распределения реальных данных.
*   **Исчезающий градиент:** дискриминатор может стать слишком хорошим, и градиент для генератора станет очень маленьким, что затруднит его обучение.
*   **Сложность оценки:** трудно оценить качество сгенерированных данных.

**Разновидности GAN:**

*   **DCGAN (Deep Convolutional GAN):** использует сверточные слои в генераторе и дискриминаторе.
*   **WGAN (Wasserstein GAN):** использует расстояние Вассерштейна вместо дивергенции Дженсена-Шеннона для обучения, что делает обучение более стабильным.
*   **CycleGAN:** для перевода изображений из одного домена в другой без парного обучения.
*   **StyleGAN:** для генерации высококачественных изображений лиц.
*   **BigGAN:** для генерации изображений с высоким разрешением.

**Применение:**

*   **Генерация изображений:** создание новых изображений, похожих на реальные.
*   **Редактирование изображений:** изменение стиля, атрибутов или содержания изображений.
*   **Перевод изображений из одного домена в другой (Image-to-Image Translation).**
*   **Повышение разрешения изображений (Super-Resolution).**
*   **Генерация текста, музыки и других типов данных.**
*   **Обнаружение аномалий.**
*   **Обучение с подкреплением.**